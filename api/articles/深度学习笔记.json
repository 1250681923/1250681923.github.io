{"title":"DLNotes","uid":"939229761d9e9e6b8785ea116cde36b3","slug":"深度学习笔记","date":"2022-08-01T14:10:05.000Z","updated":"2024-11-05T09:14:22.880Z","comments":true,"path":"api/articles/深度学习笔记.json","keywords":null,"cover":"/img/IMG_1267.JPG","content":"<h1 id=\"iris-鸢尾花\"><a href=\"#iris-鸢尾花\" class=\"headerlink\" title=\"iris-鸢尾花\"></a>iris-鸢尾花</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入相关的库\nimport seaborn as sns\nimport numpy as np</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 机器学习：sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegressionCV</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 深度学习：tf.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import utils</code></pre>\n\n<h2 id=\"数据处理\"><a href=\"#数据处理\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 加载数据\niris &#x3D; sns.load_dataset(&#39;iris&#39;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">iris.shape</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(150, 5)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">iris.head()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">sns.pairplot(iris,hue&#x3D;&quot;species&quot;)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;seaborn.axisgrid.PairGrid at 0x11fcb1240&gt;</code></pre>\n\n\n<p><img src=\"/DLNotes/2-1.png\" alt=\"2-1\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获得数据集的特征值和目标值\nX &#x3D; iris.values[:,:4]\ny &#x3D; iris.values[:,4]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 数据集划分\ntrain_x,test_x,train_y,test_y &#x3D; train_test_split(X,y,test_size &#x3D; 0.5,random_state&#x3D;0)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train_x.shape</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(75, 4)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_x.shape</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(75, 4)</code></pre>\n\n\n\n<h2 id=\"sklearn-实现鸢尾花\"><a href=\"#sklearn-实现鸢尾花\" class=\"headerlink\" title=\"sklearn 实现鸢尾花\"></a>sklearn 实现鸢尾花</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 使用逻辑回归\n# 实例化估计器\nlr &#x3D; LogisticRegressionCV()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型训练\nlr.fit(train_x,train_y)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression\n  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression\n  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression\n  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression\n  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression\n  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)</code></pre>\n\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">LogisticRegressionCV()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型评估\nlr.score(test_x,test_y)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.9333333333333333</code></pre>\n\n\n\n<h2 id=\"tf-keras实现\"><a href=\"#tf-keras实现\" class=\"headerlink\" title=\"tf,keras实现\"></a>tf,keras实现</h2><h3 id=\"数据处理-1\"><a href=\"#数据处理-1\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 目标值的热编码\ndef one_hot_encode(arr):\n    # 获取目标值中的所有类别斌进行热编码\n    uniques,ids &#x3D; np.unique(arr,return_inverse&#x3D;True)\n    return utils.to_categorical(ids,len(uniques))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 对目标值进行编码\ntrain_y_ohe &#x3D; one_hot_encode(train_y)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_y_ohe &#x3D; one_hot_encode(test_y)</code></pre>\n\n<h3 id=\"模型构建\"><a href=\"#模型构建\" class=\"headerlink\" title=\"模型构建\"></a>模型构建</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 通过squential进行构建\nmodel &#x3D; Sequential([\n    # 隐藏层\n    Dense(10,activation&#x3D;&quot;relu&quot;,input_shape&#x3D;(4,)),\n    # 隐藏层\n    Dense(10,activation&#x3D;&quot;relu&quot;),\n    # 输出层\n    Dense(3,activation&#x3D;&quot;softmax&quot;)\n])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\ndense (Dense)                (None, 10)                50        \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                110       \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 33        \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 193\nTrainable params: 193\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">utils.plot_model(model,show_shapes&#x3D;True)</code></pre>\n\n<p><img src=\"/DLNotes/2-2.png\" alt=\"2-1\"></p>\n<h3 id=\"模型预测与评估\"><a href=\"#模型预测与评估\" class=\"headerlink\" title=\"模型预测与评估\"></a>模型预测与评估</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型编译\nmodel.compile(optimizer&#x3D;&quot;adam&quot;,loss&#x3D;&quot;categorical_crossentropy&quot;,metrics&#x3D;[&quot;accuracy&quot;])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 类型准换\ntrain_x &#x3D; np.array(train_x,dtype&#x3D; np.float32)\ntest_x &#x3D; np.array(test_x,dtype&#x3D;np.float32)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型训练\nmodel.fit(train_x,train_y_ohe,epochs&#x3D;10,batch_size&#x3D;1,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 582us&#x2F;step - loss: 1.6949 - accuracy: 0.2667\nEpoch 2&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 498us&#x2F;step - loss: 1.0696 - accuracy: 0.3867\nEpoch 3&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 523us&#x2F;step - loss: 0.7988 - accuracy: 0.7200\nEpoch 4&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 516us&#x2F;step - loss: 0.6704 - accuracy: 0.7467\nEpoch 5&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 480us&#x2F;step - loss: 0.5823 - accuracy: 0.7733\nEpoch 6&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 478us&#x2F;step - loss: 0.5058 - accuracy: 0.8000\nEpoch 7&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 468us&#x2F;step - loss: 0.4638 - accuracy: 0.8667\nEpoch 8&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 489us&#x2F;step - loss: 0.4091 - accuracy: 0.8533\nEpoch 9&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 472us&#x2F;step - loss: 0.3607 - accuracy: 0.9067\nEpoch 10&#x2F;10\n75&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 478us&#x2F;step - loss: 0.3224 - accuracy: 0.9467</code></pre>\n\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x14329a400&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型评估\nloss,accuracy &#x3D; model.evaluate(test_x,test_y_ohe,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">3&#x2F;3 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 702us&#x2F;step - loss: 0.4016 - accuracy: 0.7467</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">loss</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.4016245901584625</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">accuracy</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.746666669845581</code></pre>\n\n\n\n\n<h1 id=\"深度学习基础\"><a href=\"#深度学习基础\" class=\"headerlink\" title=\"深度学习基础\"></a>深度学习基础</h1><h2 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a>激活函数</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入所需要的库\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt</code></pre>\n\n<h3 id=\"sigmoid\"><a href=\"#sigmoid\" class=\"headerlink\" title=\"sigmoid\"></a>sigmoid</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x &#x3D; np.linspace(-10,10,1000)\ny &#x3D; tf.nn.sigmoid(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.plot(x,y)\nplt.grid()</code></pre>\n\n\n<p><img src=\"/DLNotes/3-1.png\" alt=\"3-1\"></p>\n<h3 id=\"tanh\"><a href=\"#tanh\" class=\"headerlink\" title=\"tanh\"></a>tanh</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x &#x3D; np.linspace(-10,10,100)\ny &#x3D; tf.nn.tanh(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.plot(x,y)\nplt.grid()</code></pre>\n\n\n<p><img src=\"/DLNotes/3-2.png\" alt=\"3-2\"></p>\n<h3 id=\"relu\"><a href=\"#relu\" class=\"headerlink\" title=\"relu\"></a>relu</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x &#x3D; np.linspace(-10,10,100)\ny &#x3D; tf.nn.relu(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.plot(x,y)\nplt.grid()</code></pre>\n\n\n<p><img src=\"/DLNotes/3-3.png\" alt=\"3-3\"></p>\n<h3 id=\"leakyrelu\"><a href=\"#leakyrelu\" class=\"headerlink\" title=\"leakyrelu\"></a>leakyrelu</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x &#x3D; np.linspace(-10,10,100)\ny &#x3D; tf.nn.leaky_relu(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.plot(x,y)\nplt.grid()</code></pre>\n\n<p> <img src=\"/DLNotes/3-4.png\" alt=\"3-4\"></p>\n<h3 id=\"softmax\"><a href=\"#softmax\" class=\"headerlink\" title=\"softmax\"></a>softmax</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x &#x3D; tf.constant([0.2,0.02,0.15,1.3,0.5,0.06,1.1,0.05,3.75])\ny &#x3D; tf.nn.softmax(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">y</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(9,), dtype&#x3D;float32, numpy&#x3D;\narray([0.02167152, 0.01810158, 0.02061459, 0.06510484, 0.02925349,\n       0.01884031, 0.05330333, 0.01865285, 0.75445753], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n<h2 id=\"参数初始化\"><a href=\"#参数初始化\" class=\"headerlink\" title=\"参数初始化\"></a>参数初始化</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf</code></pre>\n\n<h3 id=\"Xavizer初始化\"><a href=\"#Xavizer初始化\" class=\"headerlink\" title=\"Xavizer初始化\"></a>Xavizer初始化</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 正态分布的\n# 实例化\ninitializer &#x3D; tf.keras.initializers.glorot_normal()\nvalues &#x3D; initializer((9,1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">values</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;\narray([[-0.24432576],\n       [-0.14220025],\n       [ 0.03321752],\n       [ 0.56275785],\n       [ 0.17512582],\n       [-0.18233004],\n       [-0.44970375],\n       [-0.2163621 ],\n       [ 0.37192827]], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 标准化：均匀分布\ninitializern &#x3D; tf.keras.initializers.glorot_uniform()\nvalues &#x3D; initializern((9,1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">values</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;\narray([[ 0.5761199 ],\n       [-0.42968088],\n       [ 0.5325227 ],\n       [-0.18232065],\n       [-0.59441626],\n       [ 0.7678894 ],\n       [-0.6589678 ],\n       [-0.75305176],\n       [-0.24894887]], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n<h3 id=\"He初始化\"><a href=\"#He初始化\" class=\"headerlink\" title=\"He初始化\"></a>He初始化</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 正态分布\n# 实例化\ninitializer &#x3D; tf.keras.initializers.he_normal()\n# 采样得到权重\nvalues &#x3D; initializer((9,1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">values</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;\narray([[ 0.64234483],\n       [ 0.8432255 ],\n       [ 0.56904906],\n       [ 0.2679259 ],\n       [ 0.06764679],\n       [-0.36957997],\n       [ 0.27991033],\n       [ 0.51744246],\n       [-0.15655899]], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 标准化：均匀分布\ninitializer &#x3D; tf.keras.initializers.he_uniform()\nvalues &#x3D; initializer((9,1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">values</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;\narray([[ 0.1383363 ],\n       [ 0.5817473 ],\n       [-0.24477297],\n       [-0.4477986 ],\n       [ 0.6623007 ],\n       [-0.60182106],\n       [-0.6880068 ],\n       [-0.5368612 ],\n       [-0.04563677]], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n<h2 id=\"神经网络的搭建\"><a href=\"#神经网络的搭建\" class=\"headerlink\" title=\"神经网络的搭建\"></a>神经网络的搭建</h2><h3 id=\"sequential方式\"><a href=\"#sequential方式\" class=\"headerlink\" title=\"sequential方式\"></a>sequential方式</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入工具包\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义model,构建模型\nmodel &#x3D; keras.Sequential([\n    # 第一个隐层\n    layers.Dense(3, activation&#x3D;&quot;relu&quot;, kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer1&quot;,input_shape&#x3D;(3,)),\n    # 第二个隐层\n    layers.Dense(2, activation&#x3D;&quot;relu&quot;,\n                 kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer2&quot;),\n    # 输出层\n    layers.Dense(2, activation&#x3D;&quot;sigmoid&quot;,\n                 kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer3&quot;)\n    ],\n    name&#x3D;&quot;sequential&quot;\n)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nlayer1 (Dense)               (None, 3)                 12        \n_________________________________________________________________\nlayer2 (Dense)               (None, 2)                 8         \n_________________________________________________________________\nlayer3 (Dense)               (None, 2)                 6         \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 26\nTrainable params: 26\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">keras.utils.plot_model(model)</code></pre>\n\n\n\n\n<p><img src=\"/DLNotes/3-5.png\" alt=\"3-5\"></p>\n<h3 id=\"利用functional-API构建模型\"><a href=\"#利用functional-API构建模型\" class=\"headerlink\" title=\"利用functional API构建模型\"></a>利用functional API构建模型</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义模型的输入\ninputs &#x3D; keras.Input(shape&#x3D;(3,), name&#x3D;&#39;input&#39;)\n# 第一个隐层\nx &#x3D; layers.Dense(3, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer1&quot;)(inputs)\n# 第二个隐层\nx &#x3D; layers.Dense(2, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer2&quot;)(x)\n# 输出层\noutputs &#x3D; layers.Dense(2, activation&#x3D;&quot;sigmoid&quot;, name&#x3D;&quot;output&quot;)(x)\n# 创建模型\nmodel &#x3D; keras.Model(inputs&#x3D;inputs, outputs&#x3D;outputs,\n                    name&#x3D;&quot;Functional API Model&quot;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;Functional API Model&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\ninput (InputLayer)           [(None, 3)]               0         \n_________________________________________________________________\nlayer1 (Dense)               (None, 3)                 12        \n_________________________________________________________________\nlayer2 (Dense)               (None, 2)                 8         \n_________________________________________________________________\noutput (Dense)               (None, 2)                 6         \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 26\nTrainable params: 26\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">keras.utils.plot_model(model,show_shapes&#x3D;True)</code></pre>\n\n<p><img src=\"/DLNotes/3-6.png\" alt=\"3-6\"></p>\n<h3 id=\"通过model子类构建模型\"><a href=\"#通过model子类构建模型\" class=\"headerlink\" title=\"通过model子类构建模型\"></a>通过model子类构建模型</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义一个model的子类\nclass MyModel(keras.Model):\n    # 定义网络的层结构\n    def __init__(self):\n        super(MyModel,self).__init__()\n        # 第一层隐层\n        self.layer1 &#x3D; layers.Dense(3,activation&#x3D;&quot;relu&quot;,name&#x3D;&quot;layer1&quot;)\n        # 第二个隐层\n        self.layer2 &#x3D; layers.Dense(2,activation&#x3D;&quot;relu&quot;,name&#x3D;&quot;layer2&quot;)\n        # 输出层\n        self.layer3 &#x3D; layers.Dense(2,activation&#x3D;&quot;sigmoid&quot;,name &#x3D; &quot;layer3&quot;)\n    # 定义网络的前向传播\n    def call(self,inputs):\n        x &#x3D; self.layer1(inputs)\n        x &#x3D; self.layer2(x)\n        outputs &#x3D; self.layer3(x)\n        return outputs</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化moxing\nmodel &#x3D; MyModel()\n# 设置输入\nx &#x3D; tf.ones((1,3))\ny &#x3D; model(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">y</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(1, 2), dtype&#x3D;float32, numpy&#x3D;array([[0.5810978, 0.5847459]], dtype&#x3D;float32)&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;my_model&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nlayer1 (Dense)               multiple                  12        \n_________________________________________________________________\nlayer2 (Dense)               multiple                  8         \n_________________________________________________________________\nlayer3 (Dense)               multiple                  6         \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 26\nTrainable params: 26\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">keras.utils.plot_model(model)</code></pre>\n\n\n\n<p><img src=\"/DLNotes/3-7.png\" alt=\"3-7\"></p>\n<h2 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a>损失函数</h2><h3 id=\"交叉熵损失\"><a href=\"#交叉熵损失\" class=\"headerlink\" title=\"交叉熵损失\"></a>交叉熵损失</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置真实值和预测值\ny_true &#x3D; [[0,1,0],[0,0,1]]\ny_pre &#x3D; [[0.05,0.9,0.05],[0.05,0.05,0.9]]\n# 实例化交叉熵损失\ncce &#x3D; tf.keras.losses.CategoricalCrossentropy()\n# 计算损失结果\ncce(y_true,y_pre)</code></pre>\n\n<h3 id=\"二分类的交叉熵损失函数\"><a href=\"#二分类的交叉熵损失函数\" class=\"headerlink\" title=\"二分类的交叉熵损失函数\"></a>二分类的交叉熵损失函数</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置真实值和预测值\ny_true &#x3D; [[0],[1]]\ny_pre &#x3D; [[0.1],[0.9]]\n# 实例化\nbce &#x3D; tf.keras.losses.BinaryCrossentropy()\n# 计算损失函数\nbce(y_true,y_pre).numpy()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.10536041</code></pre>\n\n\n\n<h3 id=\"MAE-L1-LOSS\"><a href=\"#MAE-L1-LOSS\" class=\"headerlink\" title=\"MAE(L1 LOSS)\"></a>MAE(L1 LOSS)</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置真实值和预测值\ny_true &#x3D; [[0.],[1.]]\ny_pre &#x3D; [[0.],[1.]]\n# 实例化MAE损失\nmae &#x3D; tf.keras.losses.MeanAbsoluteError()\nmae(y_true,y_pre)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.0&gt;</code></pre>\n\n\n\n<h3 id=\"MSE-L2-loss\"><a href=\"#MSE-L2-loss\" class=\"headerlink\" title=\"MSE(L2 loss)\"></a>MSE(L2 loss)</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置真实值和预测值\ny_true &#x3D; [[0.],[1.]]\ny_pre &#x3D; [[0.],[1.]]\n# 实例化MSE\nmse &#x3D; tf.keras.losses.MeanSquaredError()\nmse(y_true,y_pre)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.0&gt;</code></pre>\n\n\n\n<h3 id=\"smoothL1\"><a href=\"#smoothL1\" class=\"headerlink\" title=\"smoothL1\"></a>smoothL1</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置真实值和预测值\ny_true &#x3D; [[0.2],[1.]]\ny_pre &#x3D; [[0.2],[0.6]]\n# 实例化损失\nsmooth &#x3D; tf.keras.losses.Huber()\nsmooth(y_true,y_pre)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.039999995&gt;</code></pre>\n\n\n<h1 id=\"优化方法\"><a href=\"#优化方法\" class=\"headerlink\" title=\"优化方法\"></a>优化方法</h1><h2 id=\"梯度下降算法\"><a href=\"#梯度下降算法\" class=\"headerlink\" title=\"梯度下降算法\"></a>梯度下降算法</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入工具包\nimport tensorflow as tf</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化SGD\nopt &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.1)\n# 定义要更新的参数\nvar &#x3D; tf.Variable(1.0)\n# 定义损失函数\nloss &#x3D; lambda:(var**2)&#x2F;2.0\n# 计算损失梯度，并进行参数更新\nopt.minimize(loss,[var]).numpy()\n# 参数更新结果\nvar.numpy()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.9</code></pre>\n\n<h2 id=\"momentum\"><a href=\"#momentum\" class=\"headerlink\" title=\"momentum\"></a>momentum</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\nopt &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.1,momentum&#x3D;0.9)\n# 定义要更新的参数\nvar &#x3D; tf.Variable(1.0)\nval0&#x3D; var.value()\n# 定义损失函数\nloss &#x3D; lambda:(var**2)&#x2F;2.0\n# 第一次更新\nopt.minimize(loss,[var]).numpy()\nval1 &#x3D; var.value()\n# 第二次更新\nopt.minimize(loss,[var]).numpy()\nval2 &#x3D; var.value()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">val0</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;1.0&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">val1</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.9&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">val2</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.71999997&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">val0-val1</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.100000024&gt;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">val1-val2</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.18&gt;</code></pre>\n\n\n\n<h2 id=\"adagrad\"><a href=\"#adagrad\" class=\"headerlink\" title=\"adagrad\"></a>adagrad</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\nopt &#x3D; tf.keras.optimizers.Adagrad(learning_rate&#x3D;0.1,initial_accumulator_value&#x3D;0.1,epsilon&#x3D;1e-06)\n# 定义要更新的参数\nvar &#x3D; tf.Variable(1.0)\n# 定义损失函数\ndef loss():\n    return (var**2)&#x2F;2.0\n# 进行更新\nopt.minimize(loss,[var]).numpy()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">1</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">var</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tf.Variable &#39;Variable:0&#39; shape&#x3D;() dtype&#x3D;float32, numpy&#x3D;0.90465385&gt;</code></pre>\n\n\n\n<h2 id=\"RMSprop\"><a href=\"#RMSprop\" class=\"headerlink\" title=\"RMSprop\"></a>RMSprop</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\nopt &#x3D; tf.keras.optimizers.RMSprop(learning_rate&#x3D;0.1,rho&#x3D;0.1)\n# 定义要更新的参数\nvar &#x3D; tf.Variable(1.0)\n# 定义损失函数\ndef loss():\n    return (var**2)&#x2F;2.0\n# 进行更新\nopt.minimize(loss,[var]).numpy()\nvar.numpy()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.89459074</code></pre>\n\n\n\n<h2 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\nopt &#x3D; tf.keras.optimizers.Adam(learning_rate&#x3D;0.1)\n# 定义要调整的参数\nvar &#x3D; tf.Variable(1.0)\n# 定义损失函数\ndef loss():\n    return (var**2)&#x2F;2.0\n# 进行更新\nopt.minimize(loss,[var])\n# 显示结果\nvar.numpy()</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">0.90000033</code></pre>\n\n\n\n\n<h1 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a>正则化</h1><h2 id=\"dropout\"><a href=\"#dropout\" class=\"headerlink\" title=\"dropout\"></a>dropout</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入工具包\nimport tensorflow as tf\nimport numpy as np</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义dropout层\nlayer &#x3D; tf.keras.layers.Dropout(0,input_shape&#x3D;(2,))\n# 定义输入数据\ndata &#x3D; np.arange(1,11).reshape(5,2).astype(np.float32)\nprint(data)\n# 对输入数据进行随机失活\noutputs &#x3D; layer(data,training&#x3D;True)\nprint(outputs)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[[ 1.  2.]\n [ 3.  4.]\n [ 5.  6.]\n [ 7.  8.]\n [ 9. 10.]]\ntf.Tensor(\n[[ 1.  2.]\n [ 3.  4.]\n [ 5.  6.]\n [ 7.  8.]\n [ 9. 10.]], shape&#x3D;(5, 2), dtype&#x3D;float32)</code></pre>\n\n\n<h2 id=\"提前停止\"><a href=\"#提前停止\" class=\"headerlink\" title=\"提前停止\"></a>提前停止</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义回调函数\ncallback &#x3D; tf.keras.callbacks.EarlyStopping(monitor&#x3D;&quot;loss&quot;,patience&#x3D;3)\n# 定义一层的网络\nmodel &#x3D; tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n# 模型编译\nmodel.compile(tf.keras.optimizers.SGD(),loss&#x3D;&#39;mse&#39;)\n# 模型训练\nhistory &#x3D; model.fit(np.arange(100).reshape(5,20),np.array([0,1,0,1,0]),epochs&#x3D;10,batch_size&#x3D;1,verbose&#x3D;1)\nlen(history.history[&#39;loss&#39;])</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 645us&#x2F;step - loss: 56302425635553280.0000\nEpoch 2&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 3809886121814745262099957060468736.0000\nEpoch 3&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 868us&#x2F;step - loss: inf\nEpoch 4&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 964us&#x2F;step - loss: inf\nEpoch 5&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 761us&#x2F;step - loss: nan\nEpoch 6&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 709us&#x2F;step - loss: nan\nEpoch 7&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 805us&#x2F;step - loss: nan\nEpoch 8&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 746us&#x2F;step - loss: nan\nEpoch 9&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 801us&#x2F;step - loss: nan\nEpoch 10&#x2F;10\n5&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 555us&#x2F;step - loss: nan</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">10</code></pre>\n\n\n<h1 id=\"minist数据集\"><a href=\"#minist数据集\" class=\"headerlink\" title=\"minist数据集\"></a>minist数据集</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 导入所需的工具包\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# tf中使用工具包\nimport tensorflow as tf\n# 构建模型\nfrom tensorflow.keras.models import Sequential\n# 相关的网络层，所有神经元在Dense层里，Dropout随机失活（最常用的正则化方法），激活函数，BN层\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,BatchNormalization\n# 导入辅助工具包\nfrom tensorflow.keras import utils\n# 正则化\nfrom tensorflow.keras import regularizers\n# 数据集\nfrom tensorflow.keras.datasets import mnist</code></pre>\n\n<h2 id=\"数据加载\"><a href=\"#数据加载\" class=\"headerlink\" title=\"数据加载\"></a>数据加载</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 加载数据集\n(x_train,y_train),(x_test,y_test) &#x3D; mnist.load_data()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x_train.shape</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(60000, 28, 28)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">x_test.shape</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(10000, 28, 28)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">y_train</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">array([5, 0, 4, ..., 5, 6, 8], dtype&#x3D;uint8)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 显示数据\n#创建画布\nplt.figure()\n#输出\nplt.imshow(x_train[10000],cmap&#x3D;&quot;gray&quot;)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;matplotlib.image.AxesImage at 0x182df7f6be0&gt;</code></pre>\n\n\n\n<p><img src=\"/DLNotes/6-1.png\" alt=\"6-1\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">y_train[10000]</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">3</code></pre>\n\n\n\n<h2 id=\"数据处理-2\"><a href=\"#数据处理-2\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 数据维度的调整\nx_train &#x3D; x_train.reshape(60000,784)\nx_test &#x3D; x_test.reshape(10000,784)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 数据类型调整\nx_train &#x3D; x_train.astype(&#39;float32&#39;)\nx_test &#x3D; x_test.astype(&quot;float32&quot;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 归一化\nx_train &#x3D; x_train&#x2F;255\nx_test &#x3D; x_test&#x2F;255</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 将目标值转换成热编码的形式\ny_train &#x3D; utils.to_categorical(y_train,10)\ny_test &#x3D; utils.to_categorical(y_test,10)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">y_train.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(60000, 10)</code></pre>\n\n\n\n<h2 id=\"模型构建-1\"><a href=\"#模型构建-1\" class=\"headerlink\" title=\"模型构建\"></a>模型构建</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 使用序列模型进行构建\nmodel &#x3D; Sequential()\n# 全连接层：2个隐层，一个输出层\n# 第一个隐层:512个神经元，先激活后BN，随机失活\nmodel.add(Dense(512,activation &#x3D; &quot;relu&quot;,input_shape&#x3D;(784,)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# 第二个隐层：512个神经元，先BN后激活，随机失活\nmodel.add(Dense(512,kernel_regularizer&#x3D;regularizers.l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(&quot;relu&quot;))\nmodel.add(Dropout(0.2))\n# 输出层\nmodel.add(Dense(10,activation&#x3D;&quot;softmax&quot;))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential_1&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\ndense_2 (Dense)              (None, 512)               401920    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 512)               2048      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 512)               2048      \n_________________________________________________________________\nactivation (Activation)      (None, 512)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                5130      \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 673,802\nTrainable params: 671,754\nNon-trainable params: 2,048\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">utils.plot_model(model)</code></pre>\n\n\n\n<p><img src=\"/DLNotes/6-2.png\" alt=\"6-2\"></p>\n<h2 id=\"模型编译\"><a href=\"#模型编译\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 损失函数，优化器，评价指标\nmodel.compile(loss&#x3D; tf.keras.losses.categorical_crossentropy,optimizer &#x3D; tf.keras.optimizers.Adam(),\n              metrics&#x3D;tf.keras.metrics.Accuracy())</code></pre>\n\n<h2 id=\"模型训练\"><a href=\"#模型训练\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 使用fit,指定训练集，epochs,batch_size,val,verbose\nhistory &#x3D; model.fit(x_train,y_train,epochs&#x3D;4,batch_size&#x3D;128,validation_data&#x3D;(x_test,y_test),verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1235 - accuracy: 0.0088 - val_loss: 0.1619 - val_accuracy: 0.0124\nEpoch 2&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1225 - accuracy: 0.0084 - val_loss: 0.1584 - val_accuracy: 0.0093\nEpoch 3&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1179 - accuracy: 0.0084 - val_loss: 0.1595 - val_accuracy: 0.0120\nEpoch 4&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1113 - accuracy: 0.0091 - val_loss: 0.1399 - val_accuracy: 0.0057</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">history.history</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&#123;&#39;loss&#39;: [0.12347722053527832,\n  0.1224995031952858,\n  0.11792848259210587,\n  0.11130338907241821],\n &#39;accuracy&#39;: [0.008786666207015514,\n  0.00840499997138977,\n  0.008430000394582748,\n  0.009065000340342522],\n &#39;val_loss&#39;: [0.16186854243278503,\n  0.15844473242759705,\n  0.15949705243110657,\n  0.13993136584758759],\n &#39;val_accuracy&#39;: [0.012380000203847885,\n  0.009259999729692936,\n  0.011950000189244747,\n  0.0056500001810491085]&#125;</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 损失函数\nplt.figure()\nplt.plot(history.history[&#39;loss&#39;],label&#x3D;&quot;train&quot;)\nplt.plot(history.history[&quot;val_loss&quot;],label&#x3D;&quot;val&quot;)\nplt.legend()\nplt.grid()</code></pre>\n\n\n<p><img src=\"/DLNotes/6-3.png\" alt=\"6-3\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 准确率\nplt.figure()\nplt.plot(history.history[&#39;accuracy&#39;],label&#x3D;&quot;train&quot;)\nplt.plot(history.history[&quot;val_accuracy&quot;],label&#x3D;&quot;val&quot;)\nplt.legend()\nplt.grid()</code></pre>\n\n\n<p><img src=\"/DLNotes/6-4.png\" alt=\"6-4\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 回调函数\ntensorboard &#x3D; tf.keras.callbacks.TensorBoard(log_dir &#x3D; &quot;.&#x2F;graph&quot;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 训练\nhistory &#x3D; model.fit(x_train,y_train,epochs&#x3D;4,validation_data&#x3D;(x_test,y_test),batch_size&#x3D;128,\n                    verbose&#x3D;1,callbacks&#x3D;[tensorboard])</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;4\n  1&#x2F;469 [..............................] - ETA: 0s - loss: 0.1043 - accuracy: 0.0109WARNING:tensorflow:From &#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;python&#x2F;ops&#x2F;summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\nInstructions for updating:\nuse &#96;tf.profiler.experimental.stop&#96; instead.\nWARNING:tensorflow:Callbacks method &#96;on_train_batch_end&#96; is slow compared to the batch time (batch time: 0.0062s vs &#96;on_train_batch_end&#96; time: 0.0188s). Check your callbacks.\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1092 - accuracy: 0.0093 - val_loss: 0.1541 - val_accuracy: 0.0091\nEpoch 2&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1070 - accuracy: 0.0096 - val_loss: 0.1400 - val_accuracy: 0.0076\nEpoch 3&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1059 - accuracy: 0.0097 - val_loss: 0.1472 - val_accuracy: 0.0090\nEpoch 4&#x2F;4\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1018 - accuracy: 0.0111 - val_loss: 0.1462 - val_accuracy: 0.0136</code></pre>\n\n\n<h2 id=\"模型评估\"><a href=\"#模型评估\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.evaluate(x_test,y_test,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 0.1462 - accuracy: 0.0136</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[0.1461515724658966, 0.013629999943077564]</code></pre>\n\n\n\n<h2 id=\"模型保存\"><a href=\"#模型保存\" class=\"headerlink\" title=\"模型保存\"></a>模型保存</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 保存\nmodel.save(&quot;model.h5&quot;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 记载\nloadmodel &#x3D; tf.keras.models.load_model(&quot;model.h5&quot;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">loadmodel.evaluate(x_test,y_test,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 0.1462 - accuracy: 0.0136</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[0.1461515724658966, 0.013629999943077564]</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"></code></pre>\n\n\n<h1 id=\"LeNet-5\"><a href=\"#LeNet-5\" class=\"headerlink\" title=\"LeNet-5\"></a>LeNet-5</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf\nfrom tensorflow.keras.datasets import mnist</code></pre>\n\n<h2 id=\"数据集加载\"><a href=\"#数据集加载\" class=\"headerlink\" title=\"数据集加载\"></a>数据集加载</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(train_images,train_labels),(test_images,test_labels) &#x3D; mnist.load_data()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(60000, 28, 28)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(10000, 28, 28)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train_labels.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(60000,)</code></pre>\n\n\n\n<h2 id=\"数据处理-3\"><a href=\"#数据处理-3\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 维度调整\ntrain_images &#x3D; tf.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">TensorShape([60000, 28, 28, 1])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_images &#x3D; tf.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">TensorShape([10000, 28, 28, 1])</code></pre>\n\n\n\n<h2 id=\"模型构建-2\"><a href=\"#模型构建-2\" class=\"headerlink\" title=\"模型构建\"></a>模型构建</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net &#x3D; tf.keras.models.Sequential([\n    # 卷积层：6个5*5的卷积 sigmoid\n    tf.keras.layers.Conv2D(filters&#x3D;6, kernel_size&#x3D;5,\n                           activation&#x3D;&quot;sigmoid&quot;, input_shape&#x3D;(28, 28, 1)),\n    # max pooling\n    tf.keras.layers.MaxPool2D(pool_size&#x3D;2, strides&#x3D;2),\n    # 卷积层：16 5*5 sigmoid\n    tf.keras.layers.Conv2D(filters&#x3D;16, kernel_size&#x3D;5, activation&#x3D;&quot;sigmoid&quot;),\n    # max pooling\n    tf.keras.layers.MaxPool2D(pool_size&#x3D;2, strides&#x3D;2),\n    # 维度调整\n    tf.keras.layers.Flatten(),\n    # 全连接层，sigmoid\n    tf.keras.layers.Dense(120, activation&#x3D;&quot;sigmoid&quot;),\n    # 全连接层，sigmoid\n    tf.keras.layers.Dense(84, activation&#x3D;&quot;sigmoid&quot;),\n    # 输出层 softmax\n    tf.keras.layers.Dense(10, activation&#x3D;&quot;softmax&quot;)\n])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nconv2d (Conv2D)              (None, 24, 24, 6)         156       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 12, 12, 6)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 8, 8, 16)          2416      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 4, 4, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 256)               0         \n_________________________________________________________________\ndense (Dense)                (None, 120)               30840     \n_________________________________________________________________\ndense_1 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                850       \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 44,426\nTrainable params: 44,426\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">tf.keras.utils.plot_model(net)</code></pre>\n\n\n\n<p><img src=\"/DLNotes/7-1.png\" alt=\"7-1\"></p>\n<h2 id=\"模型编译-1\"><a href=\"#模型编译-1\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 设置优化器，损失函数 评价指标\nnet.compile(optimizer&#x3D;tf.keras.optimizers.SGD(learning_rate&#x3D;0.9),\n           loss &#x3D; tf.keras.losses.sparse_categorical_crossentropy,\n           metrics&#x3D;[&quot;accuracy&quot;])</code></pre>\n\n<h2 id=\"模型训练-1\"><a href=\"#模型训练-1\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net.fit(train_images,train_labels,epochs&#x3D;5,batch_size&#x3D;128,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;5\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 17ms&#x2F;step - loss: 0.0752 - accuracy: 0.9762\nEpoch 2&#x2F;5\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 18ms&#x2F;step - loss: 0.0664 - accuracy: 0.9793\nEpoch 3&#x2F;5\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 18ms&#x2F;step - loss: 0.0651 - accuracy: 0.9790\nEpoch 4&#x2F;5\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 9s 18ms&#x2F;step - loss: 0.0580 - accuracy: 0.9817\nEpoch 5&#x2F;5\n469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 9s 18ms&#x2F;step - loss: 0.0534 - accuracy: 0.9834</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x111d30940&gt;</code></pre>\n\n\n\n<h2 id=\"模型评估-1\"><a href=\"#模型评估-1\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 2ms&#x2F;step - loss: 0.0579 - accuracy: 0.9806</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[0.05785652995109558, 0.9805999994277954]</code></pre>\n\n\n\n<h1 id=\"cifar数据集\"><a href=\"#cifar数据集\" class=\"headerlink\" title=\"cifar数据集\"></a>cifar数据集</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k个图像，图像大小32×32×3。\n# CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32×32×3。\n# 随后了解下 ImageNet，目前主流的数据集\nfrom tensorflow.keras.datasets import cifar10</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(train_images,train_labels),(test_images,test_labels) &#x3D; cifar10.load_data()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(10000, 32, 32, 3)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train_images.shape</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(50000, 32, 32, 3)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import matplotlib.pyplot as plt</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.figure(figsize&#x3D;(3,3))\nplt.imshow(train_images[4])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;matplotlib.image.AxesImage at 0x14f8c5ef0&gt;</code></pre>\n\n<p><img src=\"/DLNotes/8-1.png\" alt=\"8-1\"></p>\n<h1 id=\"AlexNet\"><a href=\"#AlexNet\" class=\"headerlink\" title=\"AlexNet\"></a>AlexNet</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf</code></pre>\n\n\n\n<p><img src=\"/DLNotes/9-3.png\" alt=\"9-3\"></p>\n<h2 id=\"模型构建-3\"><a href=\"#模型构建-3\" class=\"headerlink\" title=\"模型构建\"></a>模型构建</h2><p><img src=\"/DLNotes/9-2.png\" alt=\"9-2\"></p>\n<p>该网络的特点是：</p>\n<ul>\n<li>AlexNet包含8层变换，有5层卷积和2层全连接隐藏层，以及1个全连接输出层</li>\n<li>AlexNet第一层中的卷积核形状是11×1111×11。第二层中的卷积核形状减小到5×55×5，之后全采用3×33×3。所有的池化层窗口大小为3×33×3、步幅为2的最大池化。</li>\n<li>AlexNet将sigmoid激活函数改成了ReLU激活函数，使计算更简单，网络更容易训练</li>\n<li>AlexNet通过dropOut来控制全连接层的模型复杂度。</li>\n<li>AlexNet引入了大量的图像增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</li>\n</ul>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net &#x3D; tf.keras.models.Sequential([\n    # 卷积层：96 11*11 4 relu\n    tf.keras.layers.Conv2D(filters&#x3D;96, kernel_size&#x3D;11,\n                           strides&#x3D;4, activation&#x3D;&quot;relu&quot;),\n    # 池化：3*3 2\n    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),\n    # 卷积：256 5*5 1 RELU same\n    tf.keras.layers.Conv2D(filters&#x3D;256, kernel_size&#x3D;5,\n                           padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),\n    # 池化： 3*3 2\n    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),\n    # 卷积：384 3*3 1 RELU same\n    tf.keras.layers.Conv2D(filters&#x3D;384, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),\n    # 卷积：384 3*3 1 RELU same\n    tf.keras.layers.Conv2D(filters&#x3D;384, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),\n    # 卷积：256 3*3 1 RELU same\n    tf.keras.layers.Conv2D(filters&#x3D;256, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),\n    # 池化：3*3 2\n    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),\n    # 展开\n    tf.keras.layers.Flatten(),\n    # 全连接层：4096 relu\n    tf.keras.layers.Dense(4096, activation&#x3D;&quot;relu&quot;),\n    # 随机失活\n    tf.keras.layers.Dropout(0.5),\n    # 全连接层：4096 relu\n    tf.keras.layers.Dense(4096, activation&#x3D;&quot;relu&quot;),\n    # 随机失活\n    tf.keras.layers.Dropout(0.5),\n    # 输出层：\n    tf.keras.layers.Dense(10, activation&#x3D;&quot;softmax&quot;)\n\n])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">X &#x3D; tf.random.uniform((1,227,227,1))\ny &#x3D; net(X)\nnet.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nconv2d (Conv2D)              (1, 55, 55, 96)           11712     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (1, 27, 27, 96)           0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (1, 27, 27, 256)          614656    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (1, 13, 13, 256)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (1, 13, 13, 384)          885120    \n_________________________________________________________________\nconv2d_3 (Conv2D)            (1, 13, 13, 384)          1327488   \n_________________________________________________________________\nconv2d_4 (Conv2D)            (1, 13, 13, 256)          884992    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (1, 6, 6, 256)            0         \n_________________________________________________________________\nflatten (Flatten)            (1, 9216)                 0         \n_________________________________________________________________\ndense (Dense)                (1, 4096)                 37752832  \n_________________________________________________________________\ndropout (Dropout)            (1, 4096)                 0         \n_________________________________________________________________\ndense_1 (Dense)              (1, 4096)                 16781312  \n_________________________________________________________________\ndropout_1 (Dropout)          (1, 4096)                 0         \n_________________________________________________________________\ndense_2 (Dense)              (1, 10)                   40970     \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 58,299,082\nTrainable params: 58,299,082\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n<h2 id=\"数据读取\"><a href=\"#数据读取\" class=\"headerlink\" title=\"数据读取\"></a>数据读取</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">from tensorflow.keras.datasets import mnist\nimport numpy as np</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">(train_images,train_label),(test_images,test_labels)&#x3D;mnist.load_data()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 维度调整\ntrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))\ntest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 对训练数据进行抽样\ndef get_train(size):\n    # 随机生成index\n    index &#x3D; np.random.randint(0,train_images.shape[0],size)\n    # 选择图像并进行resize\n    resized_image &#x3D; tf.image.resize_with_pad(train_images[index],227,227)\n    return resized_image.numpy(),train_label[index]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 对测试数据进行抽样\ndef get_test(size):\n    # 随机生成index\n    index &#x3D; np.random.randint(0,test_images.shape[0],size)\n    # 选择图像并进行resize\n    resized_image &#x3D; tf.image.resize_with_pad(test_images[index],227,227)\n    return resized_image.numpy(),test_labels[index]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 抽样结果\ntrain_images,train_label &#x3D; get_train(256)\ntest_images,test_labels &#x3D; get_test(128)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import matplotlib.pyplot as plt</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.imshow(train_images[4].astype(np.int8).squeeze(),cmap&#x3D;&#39;gray&#39;)</code></pre>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;matplotlib.image.AxesImage at 0x146de3f60&gt;</code></pre>\n\n\n\n\n<p><img src=\"/DLNotes/9-1.png\" alt=\"9-1\"></p>\n<h2 id=\"模型编译-2\"><a href=\"#模型编译-2\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 优化器,损失函数,评价指标\nnet.compile(optimizer&#x3D;tf.keras.optimizers.SGD(learning_rate&#x3D;0.01),loss&#x3D;tf.keras.losses.sparse_categorical_crossentropy\n           ,metrics&#x3D;[&#39;accuracy&#39;])</code></pre>\n\n<h2 id=\"模型训练-2\"><a href=\"#模型训练-2\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net.fit(train_images,train_label,batch_size&#x3D;128,epochs&#x3D;3,validation_split&#x3D;0.1,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: 197.2379 - accuracy: 0.1000 - val_loss: 15641.0518 - val_accuracy: 0.1538\nEpoch 2&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: 630482274353152.0000 - accuracy: 0.1478 - val_loss: nan - val_accuracy: 0.0385\nEpoch 3&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: nan - accuracy: 0.1435 - val_loss: nan - val_accuracy: 0.0385</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x1498ac278&gt;</code></pre>\n\n\n\n<h2 id=\"模型评估-2\"><a href=\"#模型评估-2\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 168ms&#x2F;step - loss: nan - accuracy: 0.0938</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[nan, 0.09375]</code></pre>\n\n\n<h1 id=\"VGG\"><a href=\"#VGG\" class=\"headerlink\" title=\"VGG\"></a>VGG</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf </code></pre>\n\n<h2 id=\"模型构建-4\"><a href=\"#模型构建-4\" class=\"headerlink\" title=\"模型构建\"></a>模型构建</h2><h3 id=\"VGG块的构建\"><a href=\"#VGG块的构建\" class=\"headerlink\" title=\"VGG块的构建\"></a>VGG块的构建</h3><p>VGG可以看成是加深版的AlexNet，整个网络由卷积层和全连接层叠加而成，和AlexNet不同的是，VGG中使用的都是小尺寸的卷积核(3×3)，其网络架构如下图所示：</p>\n<p><img src=\"/DLNotes/10-1.png\" alt=\"10-1\"></p>\n<p>VGGNet使用的全部都是3x3的小卷积核和2x2的池化核，通过不断加深网络来提升性能。VGG可以通过重复使用简单的基础块来构建深度模型。</p>\n<p><img src=\"/DLNotes/10-2.png\" alt=\"10-2\"></p>\n<p>在tf.keras中实现VGG模型，首先来实现VGG块，它的组成规律是：连续使用多个相同的填充为1、卷积核大小为3×33×3的卷积层后接上一个步幅为2、窗口形状为2×22×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用<code>vgg_block</code>函数来实现这个基础的VGG块，它可以指定卷积层的数量<code>num_convs</code>和每层的卷积核个数num_filters：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def vgg_block(num_conv,num_filters):\n    # 序列模型\n    blk &#x3D; tf.keras.models.Sequential()\n    # 遍历卷积层\n    for _ in range(num_conv):\n        # 设置卷积层\n        blk.add(tf.keras.layers.Conv2D(num_filters,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;,activation&#x3D;&quot;relu&quot;))\n    # 池化层\n    blk.add(tf.keras.layers.MaxPool2D(pool_size&#x3D;2,strides&#x3D;2))\n    return blk</code></pre>\n\n<h3 id=\"构建模型\"><a href=\"#构建模型\" class=\"headerlink\" title=\"构建模型\"></a>构建模型</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def vgg(conv_arch):\n    # 序列模型\n    net &#x3D; tf.keras.models.Sequential()\n    # 生成卷积部分\n    for (num_convs,num_filters) in conv_arch:\n        net.add(vgg_block(num_convs,num_filters))\n    # 全连接层\n    net.add(tf.keras.models.Sequential([\n        # 展评\n        tf.keras.layers.Flatten(),\n        # 全连接层\n        tf.keras.layers.Dense(4096,activation&#x3D;&quot;relu&quot;),\n        # 随机失活\n        tf.keras.layers.Dropout(0.5),\n        # 全连接层\n        tf.keras.layers.Dense(4096,activation&#x3D;&quot;relu&quot;),\n        # 随机失活\n        tf.keras.layers.Dropout(0.5),\n        # 输出层\n        tf.keras.layers.Dense(10,activation&#x3D;&quot;softmax&quot;)\n    ]))\n    return net</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 卷积块的参数\nconv_arch &#x3D; ((2,64),(2,128),(3,256),(3,512),(3,512))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">net &#x3D; vgg(conv_arch)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">X &#x3D; tf.random.uniform((1,224,224,1))\ny &#x3D; net(X)\nnet.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nsequential_1 (Sequential)    (1, 112, 112, 64)         37568     \n_________________________________________________________________\nsequential_2 (Sequential)    (1, 56, 56, 128)          221440    \n_________________________________________________________________\nsequential_3 (Sequential)    (1, 28, 28, 256)          1475328   \n_________________________________________________________________\nsequential_4 (Sequential)    (1, 14, 14, 512)          5899776   \n_________________________________________________________________\nsequential_5 (Sequential)    (1, 7, 7, 512)            7079424   \n_________________________________________________________________\nsequential_6 (Sequential)    (1, 10)                   119586826 \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 134,300,362\nTrainable params: 134,300,362\nNon-trainable params: 0\n_________________________________________________________________</code></pre>\n\n\n<h2 id=\"数据读取-1\"><a href=\"#数据读取-1\" class=\"headerlink\" title=\"数据读取\"></a>数据读取</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import numpy as np\nfrom tensorflow.keras.datasets import mnist\n# 获取手写数字数据集\n(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()\n# 训练集数据维度的调整：N H W C\ntrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))\n# 测试集数据维度的调整：N H W C\ntest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义两个方法随机抽取部分样本演示\n# 获取训练集数据\ndef get_train(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)\n    # 将这些数据resize成22*227大小\n    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)\n    # 返回抽取的\n    return resized_images.numpy(), train_labels[index]\n# 获取测试集数据 \ndef get_test(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)\n    # 将这些数据resize成224*224大小\n    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)\n    # 返回抽样的测试样本\n    return resized_images.numpy(), test_labels[index]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取训练样本和测试样本\ntrain_images,train_labels &#x3D; get_train(256)\ntest_images,test_labels &#x3D; get_test(128)</code></pre>\n\n<h2 id=\"模型编译-3\"><a href=\"#模型编译-3\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定优化器，损失函数和评价指标\noptimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)\n\nnet.compile(optimizer&#x3D;optimizer,\n              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,\n              metrics&#x3D;[&#39;accuracy&#39;])</code></pre>\n\n<h2 id=\"模型训练-3\"><a href=\"#模型训练-3\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型训练：指定训练数据，batchsize,epoch,验证集\nnet.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 65s 32s&#x2F;step - loss: 2.3255 - accuracy: 0.0783 - val_loss: 2.1876 - val_accuracy: 0.3462\nEpoch 2&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 52s 26s&#x2F;step - loss: 2.2593 - accuracy: 0.1435 - val_loss: 2.1084 - val_accuracy: 0.4231\nEpoch 3&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 51s 26s&#x2F;step - loss: 2.1924 - accuracy: 0.2348 - val_loss: 2.0070 - val_accuracy: 0.2308</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x12d95bd68&gt;</code></pre>\n\n\n\n<h2 id=\"模型评估-3\"><a href=\"#模型评估-3\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定测试数据\nnet.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 11s 3s&#x2F;step - loss: 2.1049 - accuracy: 0.1484</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[2.1049132347106934, 0.1484375]</code></pre>\n\n<h1 id=\"GoogleNet\"><a href=\"#GoogleNet\" class=\"headerlink\" title=\"GoogleNet\"></a>GoogleNet</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf</code></pre>\n\n<p>GoogLeNet的名字不是GoogleNet，而是GoogLeNet，这是为了致敬LeNet。GoogLeNet和AlexNet&#x2F;VGGNet这类依靠加深网络结构的深度的思想不完全一样。GoogLeNet在加深度的同时做了结构上的创新，引入了一个叫做Inception的结构来代替之前的卷积加激活的经典组件。GoogLeNet在ImageNet分类比赛上的Top-5错误率降低到了6.7%。</p>\n<h2 id=\"Inception模块\"><a href=\"#Inception模块\" class=\"headerlink\" title=\"Inception模块\"></a>Inception模块</h2><p>GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。Inception块在结构比较复杂，如下图所示：</p>\n<p><img src=\"/DLNotes/11-1.png\" alt=\"11-1\"></p>\n<p>Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1×11×1、3×33×3和5×55×5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1×11×1卷积来减少输入通道数，以降低模型复杂度。第4条线路则使用3×33×3最大池化层，后接1×11×1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结,并向后进行传输。</p>\n<p><strong>1×11×1卷积</strong>：</p>\n<p>它的计算方法和其他卷积核一样，唯一不同的是它的大小是1×11×1，没有考虑在特征图局部信息之间的关系。</p>\n<p><img src=\"/DLNotes/11-2.png\" alt=\"11-2\"></p>\n<p>它的作用主要是：</p>\n<ul>\n<li>实现跨通道的交互和信息整合</li>\n<li>卷积核通道数的降维和升维，减少网络参数</li>\n</ul>\n<p>在tf.keras中实现Inception模块，各个卷积层卷积核的个数通过输入参数来控制，如下所示：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">class Inception(tf.keras.layers.Layer):\n    # 设置模块的构成\n    def __init__(self,c1,c2,c3,c4):\n        super().__init__()\n        # 线路1:1*1 RELU same c1\n        self.p1_1 &#x3D; tf.keras.layers.Conv2D(c1,kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding &#x3D;&quot;same&quot;)\n        # 线路2:1*1 RELU same c2[0]\n        self.p2_1 &#x3D; tf.keras.layers.Conv2D(c2[0],kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)\n        # 线路2:3*3 RELU same c2[1]\n        self.p2_2 &#x3D; tf.keras.layers.Conv2D(c2[1],kernel_size&#x3D;3,activation&#x3D;&quot;relu&quot;,padding&#x3D;&#39;same&#39;)\n        # 线路3:1*1 RELU same c3[0]\n        self.p3_1 &#x3D; tf.keras.layers.Conv2D(c3[0],kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)\n        # 线路3:5*5 RELU same c3[1]\n        self.p3_2 &#x3D; tf.keras.layers.Conv2D(c3[1],kernel_size&#x3D;5,activation&#x3D;&quot;relu&quot;,padding&#x3D;&#39;same&#39;)\n        # 线路4: max-pool \n        self.p4_1 &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,padding&#x3D;&quot;same&quot;,strides&#x3D;1)\n        # 线路4:1*1\n        self.p4_2 &#x3D; tf.keras.layers.Conv2D(c4,kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)\n    # 前行传播过程\n    def call(self,x):\n        # 线路1\n        p1 &#x3D; self.p1_1(x)\n        # 线路2\n        p2 &#x3D; self.p2_2(self.p2_1(x))\n        # 线路3\n        p3 &#x3D; self.p3_2(self.p3_1(x))\n        # 线路4\n        p4 &#x3D; self.p4_2(self.p4_1(x))\n        # concat\n        outputs &#x3D; tf.concat([p1,p2,p3,p4],axis&#x3D;-1)\n        return outputs\n    </code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Inception(64,(96,128),(16,32),32)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;__main__.Inception at 0x1048a6828&gt;</code></pre>\n\n\n\n<h2 id=\"GoogLeNet构建\"><a href=\"#GoogLeNet构建\" class=\"headerlink\" title=\"GoogLeNet构建\"></a>GoogLeNet构建</h2><p><img src=\"/DLNotes/11-3.png\" alt=\"11-3\"></p>\n<p>整个网络架构我们分为五个模块，每个模块之间使用步幅为2的3×33×3最大池化层来减小输出高宽。</p>\n<p><img src=\"/DLNotes/11-4.png\" alt=\"11-4\"></p>\n<h3 id=\"B1模块\"><a href=\"#B1模块\" class=\"headerlink\" title=\"B1模块\"></a>B1模块</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">inputs &#x3D; tf.keras.Input(shape&#x3D;(224,224,1),name&#x3D;&quot;input&quot;)\n# 卷积:7*7 64 \nx &#x3D; tf.keras.layers.Conv2D(64,kernel_size&#x3D;7,strides &#x3D; 2,padding&#x3D;&quot;same&quot;,activation&#x3D;&quot;relu&quot;)(inputs)\n# 池化层\nx &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre>\n\n<h3 id=\"B2模块\"><a href=\"#B2模块\" class=\"headerlink\" title=\"B2模块\"></a>B2模块</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 卷积层:1*1\nx &#x3D; tf.keras.layers.Conv2D(64,kernel_size &#x3D; 1,padding&#x3D;&#39;same&#39;,activation&#x3D;&quot;relu&quot;)(x)\n# 卷积:3*3\nx &#x3D; tf.keras.layers.Conv2D(192,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;,activation&#x3D;&#39;relu&#39;)(x)\n# 池化层\nx &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre>\n\n<h3 id=\"B3模块\"><a href=\"#B3模块\" class=\"headerlink\" title=\"B3模块\"></a>B3模块</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># inception\nx &#x3D; Inception(64,(96,128),(16,32),32)(x)\n# inception\nx &#x3D; Inception(128,(128,192),(32,96),64)(x)\n# 池化\nx &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre>\n\n<h3 id=\"B4模块\"><a href=\"#B4模块\" class=\"headerlink\" title=\"B4模块\"></a>B4模块</h3><p>第四模块更加复杂。它串联了5个Inception块，其输出通道数分别是192+208+48+64&#x3D;512192+208+48+64&#x3D;512、160+224+64+64&#x3D;512160+224+64+64&#x3D;512、128+256+64+64&#x3D;512128+256+64+64&#x3D;512、112+288+64+64&#x3D;528112+288+64+64&#x3D;528和256+320+128+128&#x3D;832256+320+128+128&#x3D;832。并且增加了辅助分类器，根据实验发现网络的中间层具有很强的识别能力，为了利用中间层抽象的特征，在某些中间层中添加含有多层的分类器，如下图所示：</p>\n<p><img src=\"/DLNotes/11-5.png\" alt=\"11-5\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 辅助分类器\ndef aux_classifier(x,filter_size):\n    # 池化层\n    x &#x3D; tf.keras.layers.AveragePooling2D(pool_size&#x3D;5,strides &#x3D; 3,padding&#x3D;&#39;same&#39;)(x)\n    # 卷积层\n    x &#x3D; tf.keras.layers.Conv2D(filters &#x3D; filter_size[0],kernel_size&#x3D;1,strides&#x3D;1,padding &#x3D;&quot;valid&quot;,activation&#x3D;&quot;relu&quot;)(x)\n    # 展评\n    x &#x3D; tf.keras.layers.Flatten()(x)\n    # 全连接\n    x &#x3D; tf.keras.layers.Dense(units &#x3D; filter_size[1],activation&#x3D;&quot;relu&quot;)(x)\n    # 输出层:\n    x &#x3D; tf.keras.layers.Dense(units&#x3D;10,activation&#x3D;&quot;softmax&quot;)(x)\n    return x</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># Inception\nx &#x3D; Inception(192,(96,208),(16,48),64)(x)\n# 辅助输出\naux_output1 &#x3D; aux_classifier(x,[128,1024])\n# Inception\nx &#x3D; Inception(160,(112,224),(24,64),64)(x)\n# Inception\nx &#x3D; Inception(128,(128,256),(24,64),64)(x)\n# Inception\nx &#x3D; Inception(112,(144,288),(32,64),64)(x)\n# 辅助输出2\naux_output2 &#x3D; aux_classifier(x,[128,1024])\n# Inception\nx &#x3D;Inception(256,(160,320),(32,128),128)(x)\n# 最大池化\nx &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&#39;same&#39;)(x)</code></pre>\n\n<h3 id=\"b5模块\"><a href=\"#b5模块\" class=\"headerlink\" title=\"b5模块\"></a>b5模块</h3><p>第五模块有输出通道数为256+320+128+128&#x3D;832256+320+128+128&#x3D;832和384+384+128+128&#x3D;1024384+384+128+128&#x3D;1024的两个Inception块。后面紧跟输出层，该模块使用全局平均池化层（GAP）来将每个通道的高和宽变成1。最后输出变成二维数组后接输出个数为标签类别数的全连接层。</p>\n<p><strong>全局平均池化层（GAP）</strong></p>\n<p>用来替代全连接层，将特征图每一通道中所有像素值相加后求平均，得到就是GAP的结果，在将其送入后续网络中进行计算</p>\n<p><img src=\"/DLNotes/11-6.png\" alt=\"11-6\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># inception\nx &#x3D; Inception(256,(160,320),(32,128),128)(x)\nx &#x3D; Inception(384,(192,384),(48,128),128)(x)\n# GAP\nx &#x3D; tf.keras.layers.GlobalAvgPool2D()(x)\n# 输出层\noutput &#x3D; tf.keras.layers.Dense(10,activation&#x3D;&quot;softmax&quot;)(x)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型\nmodel &#x3D; tf.keras.Model(inputs&#x3D;inputs,outputs&#x3D;[output,aux_output1,aux_output2])</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">model.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;functional_1&quot;\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\ninput (InputLayer)              [(None, 224, 224, 1) 0                                            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 112, 112, 64) 3200        input[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 56, 56, 192)  110784      conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 192)  0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\ninception_1 (Inception)         (None, 28, 28, 256)  163696      max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\ninception_2 (Inception)         (None, 28, 28, 480)  388736      inception_1[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 480)  0           inception_2[0][0]                \n__________________________________________________________________________________________________\ninception_3 (Inception)         (None, 14, 14, 512)  376176      max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\ninception_4 (Inception)         (None, 14, 14, 512)  449160      inception_3[0][0]                \n__________________________________________________________________________________________________\ninception_5 (Inception)         (None, 14, 14, 512)  510104      inception_4[0][0]                \n__________________________________________________________________________________________________\ninception_6 (Inception)         (None, 14, 14, 528)  605376      inception_5[0][0]                \n__________________________________________________________________________________________________\ninception_7 (Inception)         (None, 14, 14, 832)  868352      inception_6[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_11 (MaxPooling2D) (None, 7, 7, 832)    0           inception_7[0][0]                \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 5, 5, 512)    0           inception_3[0][0]                \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 5, 5, 528)    0           inception_6[0][0]                \n__________________________________________________________________________________________________\ninception_8 (Inception)         (None, 7, 7, 832)    1043456     max_pooling2d_11[0][0]           \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 5, 5, 128)    65664       average_pooling2d[0][0]          \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 5, 5, 128)    67712       average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\ninception_9 (Inception)         (None, 7, 7, 1024)   1444080     inception_8[0][0]                \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 3200)         0           conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 3200)         0           conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 1024)         0           inception_9[0][0]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1024)         3277824     flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1024)         3277824     flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10)           10250       global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10)           10250       dense_2[0][0]                    \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 12,687,054\nTrainable params: 12,687,054\nNon-trainable params: 0\n__________________________________________________________________________________________________</code></pre>\n\n\n<h2 id=\"数据读取-2\"><a href=\"#数据读取-2\" class=\"headerlink\" title=\"数据读取\"></a>数据读取</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import numpy as np\nfrom tensorflow.keras.datasets import mnist\n# 获取手写数字数据集\n(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()\n# 训练集数据维度的调整：N H W C\ntrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))\n# 测试集数据维度的调整：N H W C\ntest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义两个方法随机抽取部分样本演示\n# 获取训练集数据\ndef get_train(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)\n    # 将这些数据resize成22*227大小\n    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)\n    # 返回抽取的\n    return resized_images.numpy(), train_labels[index]\n# 获取测试集数据 \ndef get_test(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)\n    # 将这些数据resize成224*224大小\n    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)\n    # 返回抽样的测试样本\n    return resized_images.numpy(), test_labels[index]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取训练样本和测试样本\ntrain_images,train_labels &#x3D; get_train(256)\ntest_images,test_labels &#x3D; get_test(128)</code></pre>\n\n<h2 id=\"模型编译-4\"><a href=\"#模型编译-4\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定优化器，损失函数和评价指标\noptimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)\n# 模型有3个输出，所以指定损失函数对应的权重系数\nmodel.compile(optimizer&#x3D;optimizer,\n              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,\n              metrics&#x3D;[&#39;accuracy&#39;],loss_weights&#x3D;[1,0.3,0.3])</code></pre>\n\n<h2 id=\"模型训练-4\"><a href=\"#模型训练-4\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型训练：指定训练数据，batchsize,epoch,验证集\nmodel.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 5.0465 - dense_4_loss: 2.5478 - dense_1_loss: 5.5701 - dense_3_loss: 2.7589 - dense_4_accuracy: 0.1174 - dense_1_accuracy: 0.0696 - dense_3_accuracy: 0.0739 - val_loss: 3.8758 - val_dense_4_loss: 2.2874 - val_dense_1_loss: 2.9486 - val_dense_3_loss: 2.3461 - val_dense_4_accuracy: 0.1538 - val_dense_1_accuracy: 0.1154 - val_dense_3_accuracy: 0.0769\nEpoch 2&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 3s&#x2F;step - loss: 3.8362 - dense_4_loss: 2.3122 - dense_1_loss: 2.7749 - dense_3_loss: 2.3050 - dense_4_accuracy: 0.1087 - dense_1_accuracy: 0.1043 - dense_3_accuracy: 0.1000 - val_loss: 3.7066 - val_dense_4_loss: 2.3002 - val_dense_1_loss: 2.3821 - val_dense_3_loss: 2.3059 - val_dense_4_accuracy: 0.1154 - val_dense_1_accuracy: 0.0769 - val_dense_3_accuracy: 0.0385\nEpoch 3&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 4s&#x2F;step - loss: 3.6779 - dense_4_loss: 2.3000 - dense_1_loss: 2.3131 - dense_3_loss: 2.2799 - dense_4_accuracy: 0.1043 - dense_1_accuracy: 0.1522 - dense_3_accuracy: 0.1522 - val_loss: 3.6978 - val_dense_4_loss: 2.3022 - val_dense_1_loss: 2.3475 - val_dense_3_loss: 2.3045 - val_dense_4_accuracy: 0.1154 - val_dense_1_accuracy: 0.0769 - val_dense_3_accuracy: 0.0385</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x141bf7f60&gt;</code></pre>\n\n<h2 id=\"模型评估-4\"><a href=\"#模型评估-4\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定测试数据\nmodel.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 325ms&#x2F;step - loss: 3.6632 - dense_4_loss: 2.2931 - dense_1_loss: 2.2922 - dense_3_loss: 2.2749 - dense_4_accuracy: 0.1484 - dense_1_accuracy: 0.1719 - dense_3_accuracy: 0.1328</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[3.663177967071533,\n 2.2930545806884766,\n 2.2921969890594482,\n 2.274880886077881,\n 0.1484375,\n 0.171875,\n 0.1328125]</code></pre>\n\n\n\n<h1 id=\"ResNet\"><a href=\"#ResNet\" class=\"headerlink\" title=\"ResNet\"></a>ResNet</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf\nfrom tensorflow.keras import layers,activations</code></pre>\n\n\n\n<p>网络越深，获取的信息就越多，特征也越丰富。但是在实践中，随着网络的加深，优化效果反而越差，测试数据和训练数据的准确率反而降低了。</p>\n<p>针对这一问题，何恺明等人提出了残差网络（ResNet）在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。</p>\n<h2 id=\"残差块\"><a href=\"#残差块\" class=\"headerlink\" title=\"残差块\"></a>残差块</h2><p>假设 F(x) 代表某个只包含有两层的映射函数， x 是输入， F(x)是输出。假设他们具有相同的维度。在训练的过程中我们希望能够通过修改网络中的 w和b去拟合一个理想的 H(x)(从输入到输出的一个理想的映射函数)。也就是我们的目标是修改F(x) 中的 w和b逼近 H(x) 。如果我们改变思路，用F(x) 来逼近 H(x)-x ，那么我们最终得到的输出就变为 F(x)+x（这里的加指的是对应位置上的元素相加，也就是element-wise addition），这里将直接从输入连接到输出的结构也称为shortcut，那整个结构就是残差块，ResNet的基础模块。</p>\n<p><img src=\"/DLNotes/12-1.png\" alt=\"12-1\"></p>\n<p>ResNet沿用了VGG全3×33×3卷积层的设计。残差块里首先有2个有相同输出通道数的3×33×3卷积层。每个卷积层后接BN层和ReLU激活函数，然后将输入直接加在最后的ReLU激活函数前，这种结构用于层数较少的神经网络中，比如ResNet34。若输入通道数比较多，就需要引入1×11×1卷积层来调整输入的通道数，这种结构也叫作瓶颈模块，通常用于网络层数较多的结构中。如下图所示：</p>\n<p><img src=\"/DLNotes/12-2.png\" alt=\"12-2\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">class Residual(tf.keras.Model):\n    # 定义网络结构\n    def __init__(self,num_channels,use_1x1conv&#x3D;False,strides&#x3D;1):\n        super(Residual,self).__init__()\n        # 卷积层\n        self.conv1 &#x3D; layers.Conv2D(num_channels,padding&#x3D;&#39;same&#39;,kernel_size&#x3D;3,strides&#x3D;strides)\n        # 卷积层\n        self.conv2 &#x3D; layers.Conv2D(num_channels,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;)\n        # 是否使用1*1的卷积\n        if use_1x1conv:\n            self.conv3 &#x3D; layers.Conv2D(num_channels,kernel_size&#x3D;1,strides&#x3D;strides)\n        else:\n            self.conv3 &#x3D; None\n        # BN层\n        self.bn1 &#x3D; layers.BatchNormalization()\n        self.bn2 &#x3D; layers.BatchNormalization()\n    # 定义前向传播过程  \n    def call(self,x):\n        Y &#x3D; activations.relu(self.bn1(self.conv1(x)))\n        Y &#x3D; self.bn2(self.conv2(Y))\n        if self.conv3:\n            x &#x3D; self.conv3(x)\n        outputs &#x3D; activations.relu(Y+x)\n        return outputs</code></pre>\n\n<p>1*1卷积用来调整通道数。</p>\n<h2 id=\"残差模块\"><a href=\"#残差模块\" class=\"headerlink\" title=\"残差模块\"></a>残差模块</h2><p><img src=\"/DLNotes/12-3.png\" alt=\"12-3\"></p>\n<p>ResNet网络中按照残差块的通道数分为不同的模块。第一个模块前使用了步幅为2的最大池化层，所以无须减小高和宽。之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">class ResnetBlock(tf.keras.layers.Layer):\n    # 定义所需的网络结构\n    def __init__(self,num_channels,num_res,first_block&#x3D;False):\n        super(ResnetBlock,self).__init__()\n        # 存储残差块\n        self.listLayers&#x3D;[]\n        # 遍历残差数目生成模块\n        for i in range(num_res):\n            # 如果是第一个残差块而且不是第一个模块时\n            if i &#x3D;&#x3D;0 and not first_block:\n                self.listLayers.append(Residual(num_channels,use_1x1conv&#x3D;True,strides&#x3D;2))\n            else:\n                self.listLayers.append(Residual(num_channels))\n    # 定义前向传播\n    def call(self,X):\n        for layer in self.listLayers.layers:\n            X &#x3D; layer(X)\n        return X</code></pre>\n\n<h2 id=\"构建resNet网络\"><a href=\"#构建resNet网络\" class=\"headerlink\" title=\"构建resNet网络\"></a>构建resNet网络</h2><p>ResNet的前两层跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7×77×7卷积层后接步幅为2的3×33×3的最大池化层。不同之处在于ResNet每个卷积层后增加了BN层,接着是所有残差模块，最后，与GoogLeNet一样，加入全局平均池化层（GAP）后接上全连接层输出。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">class ResNet(tf.keras.Model):\n    # 定义网络的构成\n    def __init__(self, num_blocks):\n        super(ResNet, self).__init__()\n        # 输入层\n        self.conv &#x3D; layers.Conv2D(64, kernel_size&#x3D;7, strides&#x3D;2, padding&#x3D;&#39;same&#39;)\n        # BN 层\n        self.bn &#x3D; layers.BatchNormalization()\n        # 激活层\n        self.relu &#x3D; layers.Activation(&#39;relu&#39;)\n        # 池化\n        self.mp &#x3D; layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2, padding&#x3D;&quot;same&quot;)\n        # 残差模块\n        self.res_block1 &#x3D; ResnetBlock(64, num_blocks[0], first_block&#x3D;True)\n        self.res_block2 &#x3D; ResnetBlock(128, num_blocks[1])\n        self.res_block3 &#x3D; ResnetBlock(256, num_blocks[2])\n        self.res_block4 &#x3D; ResnetBlock(512, num_blocks[3])\n        # GAP\n        self.gap &#x3D; layers.GlobalAvgPool2D()\n        # 全连接层\n        self.fc &#x3D; layers.Dense(\n            units&#x3D;10, activation&#x3D;tf.keras.activations.softmax)\n    # 定义前向传播过程\n\n    def call(self, x):\n        # 输入部分的传输过程\n        x &#x3D; self.conv(x)\n        x &#x3D; self.bn(x)\n        x &#x3D; self.relu(x)\n        x &#x3D; self.mp(x)\n        # block\n        x &#x3D; self.res_block1(x)\n        x &#x3D; self.res_block2(x)\n        x &#x3D; self.res_block3(x)\n        x &#x3D; self.res_block4(x)\n        # 输出部分的传输\n        x &#x3D; self.gap(x)\n        x &#x3D; self.fc(x)\n        return x</code></pre>\n\n<p>这里每个模块里有4个卷积层（不计算 1×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型被称为ResNet-18。通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。 在训练ResNet之前，我们来观察一下输入形状在ResNe的架构：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\nmynet &#x3D; ResNet([2,2,2,2])\nX &#x3D; tf.random.uniform((1,224,224,1))\ny &#x3D; mynet(X)\nmynet.summary()</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Model: &quot;res_net_5&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nconv2d_62 (Conv2D)           multiple                  3200      \n_________________________________________________________________\nbatch_normalization_53 (Batc multiple                  256       \n_________________________________________________________________\nactivation_5 (Activation)    multiple                  0         \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 multiple                  0         \n_________________________________________________________________\nresnet_block_14 (ResnetBlock multiple                  148736    \n_________________________________________________________________\nresnet_block_15 (ResnetBlock multiple                  526976    \n_________________________________________________________________\nresnet_block_16 (ResnetBlock multiple                  2102528   \n_________________________________________________________________\nresnet_block_17 (ResnetBlock multiple                  8399360   \n_________________________________________________________________\nglobal_average_pooling2d_3 ( multiple                  0         \n_________________________________________________________________\ndense_3 (Dense)              multiple                  5130      \n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nTotal params: 11,186,186\nTrainable params: 11,178,378\nNon-trainable params: 7,808\n_________________________________________________________________</code></pre>\n\n\n<h2 id=\"数据读取-3\"><a href=\"#数据读取-3\" class=\"headerlink\" title=\"数据读取\"></a>数据读取</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import numpy as np\nfrom tensorflow.keras.datasets import mnist\n# 获取手写数字数据集\n(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()\n# 训练集数据维度的调整：N H W C\ntrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))\n# 测试集数据维度的调整：N H W C\ntest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 定义两个方法随机抽取部分样本演示\n# 获取训练集数据\ndef get_train(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)\n    # 将这些数据resize成22*227大小\n    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)\n    # 返回抽取的\n    return resized_images.numpy(), train_labels[index]\n# 获取测试集数据 \ndef get_test(size):\n    # 随机生成要抽样的样本的索引\n    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)\n    # 将这些数据resize成224*224大小\n    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)\n    # 返回抽样的测试样本\n    return resized_images.numpy(), test_labels[index]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取训练样本和测试样本\ntrain_images,train_labels &#x3D; get_train(256)\ntest_images,test_labels &#x3D; get_test(128)</code></pre>\n\n<h2 id=\"模型编译-5\"><a href=\"#模型编译-5\" class=\"headerlink\" title=\"模型编译\"></a>模型编译</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定优化器，损失函数和评价指标\noptimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)\n\nmynet.compile(optimizer&#x3D;optimizer,\n              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,\n              metrics&#x3D;[&#39;accuracy&#39;])</code></pre>\n\n<h2 id=\"模型训练-5\"><a href=\"#模型训练-5\" class=\"headerlink\" title=\"模型训练\"></a>模型训练</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 模型训练：指定训练数据，batchsize,epoch,验证集\nmynet.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 4s&#x2F;step - loss: 2.7646 - accuracy: 0.1348 - val_loss: 4.4041 - val_accuracy: 0.0769\nEpoch 2&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 2.1875 - accuracy: 0.2826 - val_loss: 5.0271 - val_accuracy: 0.0769\nEpoch 3&#x2F;3\n2&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 1.9738 - accuracy: 0.3435 - val_loss: 3.6854 - val_accuracy: 0.3077</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">&lt;tensorflow.python.keras.callbacks.History at 0x13e4ef438&gt;</code></pre>\n\n<h2 id=\"模型评估-5\"><a href=\"#模型评估-5\" class=\"headerlink\" title=\"模型评估\"></a>模型评估</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 指定测试数据\nmynet.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 342ms&#x2F;step - loss: 4.9585 - accuracy: 0.1094</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">[4.958542823791504, 0.109375]</code></pre>\n\n\n\n<h1 id=\"imageAUG-图像增强\"><a href=\"#imageAUG-图像增强\" class=\"headerlink\" title=\"imageAUG 图像增强\"></a>imageAUG 图像增强</h1><p>大规模数据集是成功应用深度神经网络的前提。例如，我们可以对图像进行不同方式的裁剪，使感兴趣的物体出现在不同位置，从而减轻模型对物体出现位置的依赖性。我们也可以调整亮度、色彩等因素来降低模型对色彩的敏感度。可以说，在当年AlexNet的成功中，图像增强技术功不可没</p>\n<h2 id=\"1-常用的图像增强方法\"><a href=\"#1-常用的图像增强方法\" class=\"headerlink\" title=\"1.常用的图像增强方法\"></a>1.常用的图像增强方法</h2><p>图像增强（image augmentation）指通过剪切、旋转&#x2F;反射&#x2F;翻转变换、缩放变换、平移变换、尺度变换、对比度变换、噪声扰动、颜色变换等一种或多种组合数据增强变换的方式来增加数据集的大小。图像增强的意义是通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模，而且随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。</p>\n<p>常见的图像增强方式可以分为两类：几何变换类和颜色变换类</p>\n<ul>\n<li><p>几何变换类，主要是对图像进行几何变换操作，包括<strong>翻转，旋转，裁剪，变形，缩放</strong>等。</p>\n<p><img src=\"/DLNotes/13-1.png\" alt=\"13-1\"></p>\n</li>\n<li><p>颜色变换类，指通过模糊、颜色变换、擦除、填充等方式对图像进行处理</p>\n<p><img src=\"/DLNotes/13-2.png\" alt=\"13-2\"></p>\n</li>\n</ul>\n<h2 id=\"tf-image进行增强\"><a href=\"#tf-image进行增强\" class=\"headerlink\" title=\"tf.image进行增强\"></a>tf.image进行增强</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np</code></pre>\n\n<pre><code>/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n</code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">cat &#x3D; plt.imread(&#39;.&#x2F;cat.jpg&#39;)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">plt.imshow(cat)</code></pre>\n\n\n<p><img src=\"/DLNotes/13-3.png\" alt=\"13-3\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 左右翻转并显示\ncat1 &#x3D; tf.image.random_flip_left_right(cat)\nplt.imshow(cat1)</code></pre>\n\n<p><img src=\"/DLNotes/13-4.png\" alt=\"13-4\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 上下翻转\ncat2 &#x3D; tf.image.random_flip_up_down(cat)\nplt.imshow(cat2)</code></pre>\n\n<p><img src=\"/DLNotes/13-5.png\" alt=\"13-5\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 随机裁剪\ncat3 &#x3D; tf.image.random_crop(cat,(200,200,3))\nplt.imshow(cat3)</code></pre>\n\n<p><img src=\"/DLNotes/13-6.png\" alt=\"13-6\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 颜色变换\ncat4 &#x3D; tf.image.random_brightness(cat,0.5)\nplt.imshow(cat4)</code></pre>\n\n<p><img src=\"/DLNotes/13-7.png\" alt=\"13-7\"></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 随机变化图像\ncat5 &#x3D; tf.image.random_hue(cat,0.5)\nplt.imshow(cat5)</code></pre>\n\n<p><img src=\"/DLNotes/13-8.png\" alt=\"13-8\"></p>\n<h2 id=\"使用imagedataGenerator进行增强\"><a href=\"#使用imagedataGenerator进行增强\" class=\"headerlink\" title=\"使用imagedataGenerator进行增强\"></a>使用imagedataGenerator进行增强</h2><p>ImageDataGenerator()是keras.preprocessing.image模块中的DLNotes生成器，可以在batch中对数据进行增强，扩充数据集大小，增强模型的泛化能力。比如旋转，变形等，如下所示：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">from tensorflow.keras.datasets import mnist</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取数据集\n(x_train, y_train), (x_test, y_test) &#x3D; tf.keras.datasets.mnist.load_data()\n# 将数据转换为4维的形式\nx_train &#x3D; x_train.reshape(x_train.shape[0],28,28,1)\nx_test &#x3D; x_test.reshape(x_test.shape[0],28,28,1)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 实例化\ndatagen &#x3D; tf.keras.preprocessing.image.ImageDataGenerator(shear_range&#x3D;10)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">for x,y in datagen.flow(x_train,y_train,batch_size&#x3D;9):\n    plt.figure(figsize&#x3D;(8,8))\n    for i in range(0,9):\n        plt.subplot(330+1+i)\n        plt.imshow(x[i].reshape(28,28),cmap&#x3D;&#39;gray&#39;)\n        plt.title(y[i])\n    plt.show()\n    break</code></pre>\n\n<p><img src=\"/DLNotes/13-9.png\" alt=\"13-9\"></p>\n<h1 id=\"微调\"><a href=\"#微调\" class=\"headerlink\" title=\"微调\"></a>微调</h1><p>如何在只有6万张图像的MNIST训练数据集上训练模型。学术界当下使用最广泛的大规模图像数据集ImageNet，它有超过1,000万的图像和1,000类的物体。然而，我们平常接触到数据集的规模通常在这两者之间。假设我们想从图像中识别出不同种类的椅子，然后将购买链接推荐给用户。一种可能的方法是先找出100种常见的椅子，为每种椅子拍摄1,000张不同角度的图像，然后在收集到的图像数据集上训练一个分类模型。另外一种解决办法是应用迁移学习（transfer learning），将从源数据集学到的知识迁移到目标数据集上。例如，虽然ImageNet数据集的图像大多跟椅子无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成等。这些类似的特征对于识别椅子也可能同样有效。</p>\n<p>微调由以下4步构成。</p>\n<ol>\n<li>在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。</li>\n<li>创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。</li>\n<li>为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。</li>\n<li>在目标数据集（如椅子数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。</li>\n</ol>\n<p><img src=\"/DLNotes/14.png\" alt=\"14\"></p>\n<p>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</p>\n<p>例如：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 热狗识别。将基于一个小数据集对在ImageNet数据集上训练好的ResNet模型进行微调。该小数据集含有数千张热狗或者其他事物的图像。我们将使用微调得到的模型来识别一张图像中是否包含热狗。\nimport tensorflow as tf\nimport numpy as np\n# 通过以下方法读取图像文件，该方法以文件夹路径为参数,生成经过图像增强后的结果，并产生batch数据：\nflow_from_directory(self, directory,\n                            target_size&#x3D;(256, 256), color_mode&#x3D;&#39;rgb&#39;,\n                            classes&#x3D;None, class_mode&#x3D;&#39;categorical&#39;,\n                            batch_size&#x3D;32, shuffle&#x3D;True, seed&#x3D;None,\n                            save_to_dir&#x3D;None）</code></pre>\n\n<p>主要参数：</p>\n<ul>\n<li>directory: 目标文件夹路径，对于每一个类对应一个子文件夹，该子文件夹中任何JPG、PNG、BNP、PPM的DLNotes都可以读取。</li>\n<li>target_size: 默认为(256, 256)，图像将被resize成该尺寸。</li>\n<li>batch_size: batch数据的大小，默认32。</li>\n<li>shuffle: 是否打乱数据，默认为True。</li>\n</ul>\n<p>我们创建两个<code>tf.keras.preprocessing.image.ImageDataGenerator</code>实例来分别读取训练数据集和测试数据集中的所有图像文件。将训练集DLNotes全部处理为高和宽均为224像素的输入。此外，我们对RGB（红、绿、蓝）三个颜色通道的数值做标准化。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 获取数据集\nimport pathlib\ntrain_dir &#x3D; &#39;transferdata&#x2F;train&#39;\ntest_dir &#x3D; &#39;transferdata&#x2F;test&#39;\n# 获取训练集数据\ntrain_dir &#x3D; pathlib.Path(train_dir)\ntrain_count &#x3D; len(list(train_dir.glob(&#39;*&#x2F;*.jpg&#39;)))\n# 获取测试集数据\ntest_dir &#x3D; pathlib.Path(test_dir)\ntest_count &#x3D; len(list(test_dir.glob(&#39;*&#x2F;*.jpg&#39;)))\n# 创建imageDataGenerator进行图像处理\nimage_generator &#x3D; tf.keras.preprocessing.image.ImageDataGenerator(rescale&#x3D;1.&#x2F;255)\n# 设置参数\nBATCH_SIZE &#x3D; 32\nIMG_HEIGHT &#x3D; 224\nIMG_WIDTH &#x3D; 224\n# 获取训练数据\ntrain_data_gen &#x3D; image_generator.flow_from_directory(directory&#x3D;str(train_dir),\n                                                    batch_size&#x3D;BATCH_SIZE,\n                                                    target_size&#x3D;(IMG_HEIGHT, IMG_WIDTH),\n                                                    shuffle&#x3D;True)\n# 获取测试数据\ntest_data_gen &#x3D; image_generator.flow_from_directory(directory&#x3D;str(test_dir),\n                                                    batch_size&#x3D;BATCH_SIZE,\n                                                    target_size&#x3D;(IMG_HEIGHT, IMG_WIDTH),\n                                                    shuffle&#x3D;True)</code></pre>\n\n<p>随机取1个batch的DLNotes然后绘制出来。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import matplotlib.pyplot as plt\n# 显示图像\ndef show_batch(image_batch, label_batch):\n    plt.figure(figsize&#x3D;(10,10))\n    for n in range(15):\n        ax &#x3D; plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n]）\n        plt.axis(&#39;off&#39;)\n# 随机选择一个batch的图像        \nimage_batch, label_batch &#x3D; next(train_data_gen)\n# 图像显示\nshow_batch(image_batch, label_batch)</code></pre>\n\n<p><img src=\"/DLNotes/14-1.png\" alt=\"14-1\"></p>\n<p>我们使用在ImageNet数据集上预训练的ResNet-50作为源模型。这里指定<code>weights=&#39;imagenet&#39;</code>来自动下载并加载预训练的模型参数。在第一次使用时需要联网下载模型参数。</p>\n<p>Keras应用程序（keras.applications）是具有预先训练权值的固定架构，该类封装了很多重量级的网络架构，如下图所示：</p>\n<p><img src=\"/DLNotes/14-2.png\" alt=\"14-2\"></p>\n<p>实现时实例化模型架构：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">tf.keras.applications.ResNet50(\n    include_top&#x3D;True, weights&#x3D;&#39;imagenet&#39;, input_tensor&#x3D;None, input_shape&#x3D;None,\n    pooling&#x3D;None, classes&#x3D;1000, **kwargs\n)</code></pre>\n\n<p>主要参数：</p>\n<ul>\n<li>include_top: 是否包括顶层的全连接层。</li>\n<li>weights: None 代表随机初始化， ‘imagenet’ 代表加载在 ImageNet 上预训练的权值。</li>\n<li>input_shape: 可选，输入尺寸元组，仅当 include_top&#x3D;False 时有效，否则输入形状必须是 (224, 224, 3)（channels_last 格式）或 (3, 224, 224)（channels_first 格式）。它必须为 3 个输入通道，且宽高必须不小于 32，比如 (200, 200, 3) 是一个合法的输入尺寸。</li>\n</ul>\n<p>在该案例中我们使用resNet50预训练模型构建模型：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 加载预训练模型\nResNet50 &#x3D; tf.keras.applications.ResNet50(weights&#x3D;&#39;imagenet&#39;, input_shape&#x3D;(224,224,3))\n# 设置所有层不可训练\nfor layer in ResNet50.layers:\n    layer.trainable &#x3D; False\n# 设置模型\nnet &#x3D; tf.keras.models.Sequential()\n# 预训练模型\nnet.add(ResNet50)\n# 展开\nnet.add(tf.keras.layers.Flatten())\n# 二分类的全连接层\nnet.add(tf.keras.layers.Dense(2, activation&#x3D;&#39;softmax&#39;))\n# 模型编译：指定优化器，损失函数和评价指标\nnet.compile(optimizer&#x3D;&#39;adam&#39;,\n            loss&#x3D;&#39;categorical_crossentropy&#39;,\n            metrics&#x3D;[&#39;accuracy&#39;])\n# 模型训练：指定数据，每一个epoch中只运行10个迭代，指定验证数据集\nhistory &#x3D; net.fit(\n                    train_data_gen,\n                    steps_per_epoch&#x3D;10,\n                    epochs&#x3D;3,\n                    validation_data&#x3D;test_data_gen,\n                    validation_steps&#x3D;10\n                    )\n</code></pre>\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Epoch 1&#x2F;3\n10&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 28s 3s&#x2F;step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6930 - val_accuracy: 0.5094\nEpoch 2&#x2F;3\n10&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 29s 3s&#x2F;step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6935 - val_accuracy: 0.4812\nEpoch 3&#x2F;3\n10&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 31s 3s&#x2F;step - loss: 0.6935 - accuracy: 0.4844 - val_loss: 0.6933 - val_accuracy: 0.4875</code></pre>\n\n\n","text":"iris-鸢尾花# 导入相关的库 import seaborn as sns import numpy as np # 机器学习：sklearn from sklearn.model_selection import train_test_split from sklearn.l...","link":"","photos":[],"count_time":{"symbolsCount":"89k","symbolsTime":"1:21"},"categories":[{"name":"Deep Learning","slug":"Deep-Learning","count":2,"path":"api/categories/Deep-Learning.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"},{"name":"DLNotes分类","slug":"DLNotes分类","count":1,"path":"api/tags/DLNotes分类.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#iris-%E9%B8%A2%E5%B0%BE%E8%8A%B1\"><span class=\"toc-text\">iris-鸢尾花</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86\"><span class=\"toc-text\">数据处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#sklearn-%E5%AE%9E%E7%8E%B0%E9%B8%A2%E5%B0%BE%E8%8A%B1\"><span class=\"toc-text\">sklearn 实现鸢尾花</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#tf-keras%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">tf,keras实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-1\"><span class=\"toc-text\">数据处理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA\"><span class=\"toc-text\">模型构建</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E4%B8%8E%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">模型预测与评估</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80\"><span class=\"toc-text\">深度学习基础</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">激活函数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#sigmoid\"><span class=\"toc-text\">sigmoid</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#tanh\"><span class=\"toc-text\">tanh</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#relu\"><span class=\"toc-text\">relu</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#leakyrelu\"><span class=\"toc-text\">leakyrelu</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#softmax\"><span class=\"toc-text\">softmax</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96\"><span class=\"toc-text\">参数初始化</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Xavizer%E5%88%9D%E5%A7%8B%E5%8C%96\"><span class=\"toc-text\">Xavizer初始化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#He%E5%88%9D%E5%A7%8B%E5%8C%96\"><span class=\"toc-text\">He初始化</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%90%AD%E5%BB%BA\"><span class=\"toc-text\">神经网络的搭建</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#sequential%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">sequential方式</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%A9%E7%94%A8functional-API%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">利用functional API构建模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%80%9A%E8%BF%87model%E5%AD%90%E7%B1%BB%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">通过model子类构建模型</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">损失函数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1\"><span class=\"toc-text\">交叉熵损失</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E5%88%86%E7%B1%BB%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">二分类的交叉熵损失函数</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#MAE-L1-LOSS\"><span class=\"toc-text\">MAE(L1 LOSS)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#MSE-L2-loss\"><span class=\"toc-text\">MSE(L2 loss)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#smoothL1\"><span class=\"toc-text\">smoothL1</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">优化方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">梯度下降算法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#momentum\"><span class=\"toc-text\">momentum</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#adagrad\"><span class=\"toc-text\">adagrad</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#RMSprop\"><span class=\"toc-text\">RMSprop</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Adam\"><span class=\"toc-text\">Adam</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%AD%A3%E5%88%99%E5%8C%96\"><span class=\"toc-text\">正则化</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#dropout\"><span class=\"toc-text\">dropout</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%8F%90%E5%89%8D%E5%81%9C%E6%AD%A2\"><span class=\"toc-text\">提前停止</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#minist%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">minist数据集</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD\"><span class=\"toc-text\">数据加载</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-2\"><span class=\"toc-text\">数据处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA-1\"><span class=\"toc-text\">模型构建</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">模型评估</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98\"><span class=\"toc-text\">模型保存</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#LeNet-5\"><span class=\"toc-text\">LeNet-5</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD\"><span class=\"toc-text\">数据集加载</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-3\"><span class=\"toc-text\">数据处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA-2\"><span class=\"toc-text\">模型构建</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91-1\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-1\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-1\"><span class=\"toc-text\">模型评估</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#cifar%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">cifar数据集</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#AlexNet\"><span class=\"toc-text\">AlexNet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA-3\"><span class=\"toc-text\">模型构建</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96\"><span class=\"toc-text\">数据读取</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91-2\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-2\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-2\"><span class=\"toc-text\">模型评估</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#VGG\"><span class=\"toc-text\">VGG</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA-4\"><span class=\"toc-text\">模型构建</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#VGG%E5%9D%97%E7%9A%84%E6%9E%84%E5%BB%BA\"><span class=\"toc-text\">VGG块的构建</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">构建模型</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96-1\"><span class=\"toc-text\">数据读取</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91-3\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-3\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-3\"><span class=\"toc-text\">模型评估</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#GoogleNet\"><span class=\"toc-text\">GoogleNet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Inception%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">Inception模块</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#GoogLeNet%E6%9E%84%E5%BB%BA\"><span class=\"toc-text\">GoogLeNet构建</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#B1%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">B1模块</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#B2%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">B2模块</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#B3%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">B3模块</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#B4%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">B4模块</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#b5%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">b5模块</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96-2\"><span class=\"toc-text\">数据读取</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91-4\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-4\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-4\"><span class=\"toc-text\">模型评估</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#ResNet\"><span class=\"toc-text\">ResNet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%AE%8B%E5%B7%AE%E5%9D%97\"><span class=\"toc-text\">残差块</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%AE%8B%E5%B7%AE%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">残差模块</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9E%84%E5%BB%BAresNet%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">构建resNet网络</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96-3\"><span class=\"toc-text\">数据读取</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91-5\"><span class=\"toc-text\">模型编译</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-5\"><span class=\"toc-text\">模型训练</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-5\"><span class=\"toc-text\">模型评估</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#imageAUG-%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">imageAUG 图像增强</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E5%B8%B8%E7%94%A8%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">1.常用的图像增强方法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#tf-image%E8%BF%9B%E8%A1%8C%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">tf.image进行增强</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BD%BF%E7%94%A8imagedataGenerator%E8%BF%9B%E8%A1%8C%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">使用imagedataGenerator进行增强</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BE%AE%E8%B0%83\"><span class=\"toc-text\">微调</span></a></li></ol>","author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/googlemail.png","link":"mailto:code.quan666zhang@gmail.com"}}}},"mapped":true,"prev_post":{"title":"AutoXGB(XGboost + optuna)","uid":"41e8b66af73631eb10964784b17cc5fa","slug":"AutoXGB","date":"2023-02-09T10:23:39.000Z","updated":"2024-11-05T08:21:11.317Z","comments":true,"path":"api/articles/AutoXGB.json","keywords":null,"cover":"/img/IMG_1267.JPG","text":"简介 Introduction源代码地址（Source code url） XGBoost + Optuna: no brainer auto train xgboost directly from CSV files auto tune xgboost using optuna...","link":"","photos":[],"count_time":{"symbolsCount":"4.3k","symbolsTime":"4 mins."},"categories":[{"name":"机器学习Machine Learning","slug":"机器学习Machine-Learning","count":3,"path":"api/categories/机器学习Machine-Learning.json"}],"tags":[{"name":"Python","slug":"Python","count":2,"path":"api/tags/Python.json"},{"name":"机器学习","slug":"机器学习","count":3,"path":"api/tags/机器学习.json"},{"name":"推荐系统","slug":"推荐系统","count":3,"path":"api/tags/推荐系统.json"},{"name":"XGBoost","slug":"XGBoost","count":2,"path":"api/tags/XGBoost.json"}],"author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/googlemail.png","link":"mailto:code.quan666zhang@gmail.com"}}}}},"next_post":{"title":"基于R推荐系统搭建","uid":"53b940f6ea7d5afb2d81c3c681083d3b","slug":"基于R推荐系统搭建","date":"2022-03-21T14:23:39.000Z","updated":"2024-11-05T09:23:33.279Z","comments":true,"path":"api/articles/基于R推荐系统搭建.json","keywords":null,"cover":"/img/IMG_1267.JPG","text":"前言首先，R语言牛皮之处就不过多阐述，总之很方便很方便。R语言就是为了数据处理而生的，可以轻松链接数据库，可以轻松对数据进行处理和分析。 这篇博客主要归纳一下如何使用R语言搭建一个简单的推荐系统。首先导入包： #install.packages(&quot;RJDBC&quot;...","link":"","photos":[],"count_time":{"symbolsCount":"43k","symbolsTime":"39 mins."},"categories":[{"name":"机器学习Machine Learning","slug":"机器学习Machine-Learning","count":3,"path":"api/categories/机器学习Machine-Learning.json"}],"tags":[{"name":"机器学习","slug":"机器学习","count":3,"path":"api/tags/机器学习.json"},{"name":"推荐系统","slug":"推荐系统","count":3,"path":"api/tags/推荐系统.json"},{"name":"R语言","slug":"R语言","count":1,"path":"api/tags/R语言.json"}],"author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/googlemail.png","link":"mailto:code.quan666zhang@gmail.com"}}}}}}
{"title":"XGBoost","uid":"4a22d0b29df90690f72b32998c550a24","slug":"XGBoost","date":"2023-02-10T07:21:14.000Z","updated":"2024-11-06T02:24:29.760Z","comments":true,"path":"api/articles/XGBoost.json","keywords":null,"cover":"/img/ai.jpg","content":"<h2 id=\"XGBoost\"><a href=\"#XGBoost\" class=\"headerlink\" title=\"XGBoost\"></a>XGBoost</h2><p>XGBoost是一个非常高效、应用广泛的GBDT机器学习库，详细信息可参考<a href=\"https://xgboost.readthedocs.io/en/latest/\">xgbbost</a><br>XGBoost提供了高效简洁的python接口，可用于分类、回归任务。在本实验中使用了xgboost的分类接口。</p>\n<p>下面是一个股票预测的例子：</p>\n<h2 id=\"所需要的包-Module-Required\"><a href=\"#所需要的包-Module-Required\" class=\"headerlink\" title=\"所需要的包 Module Required\"></a>所需要的包 Module Required</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import math\nimport matplotlib\nimport numpy as np\nimport pandas  as pd\nimport seaborn as sns\nimport time\n\nfrom datetime import date\nfrom matplotlib import pyplot as plt\nfrom pylab import rcParams\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nfrom xgboost import XGBRegressor</code></pre>\n\n<h2 id=\"参数-Parameters\"><a href=\"#参数-Parameters\" class=\"headerlink\" title=\"参数 Parameters\"></a>参数 Parameters</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test_size &#x3D; 0.2                # proportion of dataset to be used as test set\nN &#x3D; 3                          # for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n\nmodel_seed &#x3D; 100</code></pre>\n\n<h2 id=\"数据加载-Data-Loading\"><a href=\"#数据加载-Data-Loading\" class=\"headerlink\" title=\"数据加载 Data Loading\"></a>数据加载 Data Loading</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def _load_data():\n\n    #stk_path &#x3D; &quot;&#x2F;content&#x2F;drive&#x2F;MyDrive&#x2F;Colab Notebooks&#x2F;data_samples&#x2F;VTI.csv&quot;\n    stk_path &#x3D; &quot;.&#x2F;VTI.csv&quot;\n    df &#x3D; pd.read_csv(stk_path, sep&#x3D;&quot;,&quot;)\n    # Convert Date column to datetime\n    df.loc[:, &#39;Date&#39;] &#x3D; pd.to_datetime(df[&#39;Date&#39;], format&#x3D;&#39;%Y-%m-%d&#39;)\n    # Change all column headings to be lower case, and remove spacing\n    df.columns &#x3D; [str(x).lower().replace(&#39; &#39;, &#39;_&#39;) for x in df.columns]\n    # Get month of each sample\n    df[&#39;month&#39;] &#x3D; df[&#39;date&#39;].dt.month\n    # Sort by datetime\n    df.sort_values(by&#x3D;&#39;date&#39;, inplace&#x3D;True, ascending&#x3D;True)\n\n    return df</code></pre>\n\n<h2 id=\"特征工程-Feature-engineering\"><a href=\"#特征工程-Feature-engineering\" class=\"headerlink\" title=\"特征工程 Feature engineering\"></a>特征工程 Feature engineering</h2><p>生成新特征：最高最低价差、开盘收盘价差；前N天的信息拼入当天，作为当天的特征<br>Generate new features: highest and lowest price difference, opening and closing price difference; The information of the previous N days is put into the current day as the characteristics of the current day</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def feature_engineer(df):\n\n    df[&#39;range_hl&#39;] &#x3D; df[&#39;high&#39;] - df[&#39;low&#39;]\n    df[&#39;range_oc&#39;] &#x3D; df[&#39;open&#39;] - df[&#39;close&#39;]\n\n    lag_cols &#x3D; [&#39;adj_close&#39;, &#39;range_hl&#39;, &#39;range_oc&#39;, &#39;volume&#39;]\n    shift_range &#x3D; [x + 1 for x in range(N)]\n    for col in lag_cols:\n        for i in shift_range:\n            new_col&#x3D;&#39;&#123;&#125;_lag_&#123;&#125;&#39;.format(col, i)   # 格式化字符串\n            df[new_col]&#x3D;df[col].shift(i)\n\n    return df[N:]</code></pre>\n\n<h2 id=\"数据标准化-Data-standardization\"><a href=\"#数据标准化-Data-standardization\" class=\"headerlink\" title=\"数据标准化 Data standardization\"></a>数据标准化 Data standardization</h2><p><a href=\"https://www.zhihu.com/question/58883125/answer/206813653\">XGBoost</a>的本质为树模型，树模型本身无需做数据标准化。但是，在树模型中，若训练集不能代表总体，即测试集中出现训练集中从未出现的特征及回归值（训练数据过少或股价前所未有的高&#x2F;底），模型的效果基本没有效果。</p>\n<p>因此，需要对数据做“非常规”的标准化做折中，以使模型能正常运行。这里的“非常规”指计算前N天内的标准差和均值，为当天数据的标准化作准备。这样做会丢失一部分数据信息，仅仅是为了让树模型正常运行的一种取巧。</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def get_mov_avg_std(df, col, N):\n    &quot;&quot;&quot;\n    Given a dataframe, get mean and std dev at timestep t using values from t-1, t-2, ..., t-N.\n    Inputs\n        df         : dataframe. Can be of any length.\n        col        : name of the column you want to calculate mean and std dev\n        N          : get mean and std dev at timestep t using values from t-1, t-2, ..., t-N\n    Outputs\n        df_out     : same as df but with additional column containing mean and std dev\n    &quot;&quot;&quot;\n    mean_list &#x3D; df[col].rolling(window&#x3D;N, min_periods&#x3D;1).mean()  # len(mean_list) &#x3D; len(df)\n    std_list &#x3D; df[col].rolling(window&#x3D;N, min_periods&#x3D;1).std()  # first value will be NaN, because normalized by N-1\n\n    # Add one timestep to the predictions ,这里又shift了一步\n    mean_list &#x3D; np.concatenate((np.array([np.nan]), np.array(mean_list[:-1])))\n    std_list &#x3D; np.concatenate((np.array([np.nan]), np.array(std_list[:-1])))\n\n    # Append mean_list to df\n    df_out &#x3D; df.copy()\n    df_out[col + &#39;_mean&#39;] &#x3D; mean_list\n    df_out[col + &#39;_std&#39;] &#x3D; std_list\n\n    return df_out\n\n\ndef scale_row(row, feat_mean, feat_std):\n    &quot;&quot;&quot;\n    Given a pandas series in row, scale it to have 0 mean and var 1 using feat_mean and feat_std\n    Inputs\n        row      : pandas series. Need to scale this.\n        feat_mean: mean\n        feat_std : standard deviation\n    Outputs\n        row_scaled : pandas series with same length as row, but scaled\n    &quot;&quot;&quot;\n    # If feat_std &#x3D; 0 (this happens if adj_close doesn&#39;t change over N days),\n    # set it to a small number to avoid division by zero\n    feat_std &#x3D; 0.001 if feat_std &#x3D;&#x3D; 0 else feat_std\n    row_scaled &#x3D; (row - feat_mean) &#x2F; feat_std\n\n    return row_scaled</code></pre>\n\n<h2 id=\"计算绝对百分比误差-MAPE\"><a href=\"#计算绝对百分比误差-MAPE\" class=\"headerlink\" title=\"计算绝对百分比误差 MAPE\"></a>计算绝对百分比误差 MAPE</h2><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def get_mape(y_true, y_pred):\n    &quot;&quot;&quot;\n    Compute mean absolute percentage error (MAPE)\n    &quot;&quot;&quot;\n    y_true, y_pred &#x3D; np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) &#x2F; y_true)) * 100</code></pre>\n\n<h2 id=\"整体流程-Main-Process\"><a href=\"#整体流程-Main-Process\" class=\"headerlink\" title=\"整体流程 Main Process\"></a>整体流程 Main Process</h2><h3 id=\"第一步：获取数据-Step-1-Data-Loading\"><a href=\"#第一步：获取数据-Step-1-Data-Loading\" class=\"headerlink\" title=\"第一步：获取数据 Step 1: Data Loading\"></a>第一步：获取数据 Step 1: Data Loading</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">data_df&#x3D;_load_data()</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">data_df.head()</code></pre>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj_close</th>\n      <th>volume</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-11-25</td>\n      <td>107.510002</td>\n      <td>107.660004</td>\n      <td>107.250000</td>\n      <td>107.470001</td>\n      <td>101.497200</td>\n      <td>1820300</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-11-27</td>\n      <td>107.589996</td>\n      <td>107.760002</td>\n      <td>107.220001</td>\n      <td>107.629997</td>\n      <td>101.648300</td>\n      <td>552400</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-11-30</td>\n      <td>107.779999</td>\n      <td>107.849998</td>\n      <td>107.110001</td>\n      <td>107.169998</td>\n      <td>101.213867</td>\n      <td>3618100</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-12-01</td>\n      <td>107.589996</td>\n      <td>108.209999</td>\n      <td>107.370003</td>\n      <td>108.180000</td>\n      <td>102.167740</td>\n      <td>2443600</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-12-02</td>\n      <td>108.099998</td>\n      <td>108.269997</td>\n      <td>106.879997</td>\n      <td>107.050003</td>\n      <td>101.100533</td>\n      <td>2937200</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n<h3 id=\"第二步：特征工程-Step-2-Feature-engineering\"><a href=\"#第二步：特征工程-Step-2-Feature-engineering\" class=\"headerlink\" title=\"第二步：特征工程 Step 2: Feature engineering\"></a>第二步：特征工程 Step 2: Feature engineering</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">df&#x3D;feature_engineer(data_df)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">df.head()</code></pre>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj_close</th>\n      <th>volume</th>\n      <th>month</th>\n      <th>range_hl</th>\n      <th>range_oc</th>\n      <th>...</th>\n      <th>adj_close_lag_3</th>\n      <th>range_hl_lag_1</th>\n      <th>range_hl_lag_2</th>\n      <th>range_hl_lag_3</th>\n      <th>range_oc_lag_1</th>\n      <th>range_oc_lag_2</th>\n      <th>range_oc_lag_3</th>\n      <th>volume_lag_1</th>\n      <th>volume_lag_2</th>\n      <th>volume_lag_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>2015-12-01</td>\n      <td>107.589996</td>\n      <td>108.209999</td>\n      <td>107.370003</td>\n      <td>108.180000</td>\n      <td>102.167740</td>\n      <td>2443600</td>\n      <td>12</td>\n      <td>0.839996</td>\n      <td>-0.590004</td>\n      <td>...</td>\n      <td>101.497200</td>\n      <td>0.739997</td>\n      <td>0.540001</td>\n      <td>0.410004</td>\n      <td>0.610001</td>\n      <td>-0.040001</td>\n      <td>0.040001</td>\n      <td>3618100.0</td>\n      <td>552400.0</td>\n      <td>1820300.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-12-02</td>\n      <td>108.099998</td>\n      <td>108.269997</td>\n      <td>106.879997</td>\n      <td>107.050003</td>\n      <td>101.100533</td>\n      <td>2937200</td>\n      <td>12</td>\n      <td>1.390000</td>\n      <td>1.049995</td>\n      <td>...</td>\n      <td>101.648300</td>\n      <td>0.839996</td>\n      <td>0.739997</td>\n      <td>0.540001</td>\n      <td>-0.590004</td>\n      <td>0.610001</td>\n      <td>-0.040001</td>\n      <td>2443600.0</td>\n      <td>3618100.0</td>\n      <td>552400.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015-12-03</td>\n      <td>107.290001</td>\n      <td>107.480003</td>\n      <td>105.059998</td>\n      <td>105.449997</td>\n      <td>99.589470</td>\n      <td>3345600</td>\n      <td>12</td>\n      <td>2.420005</td>\n      <td>1.840004</td>\n      <td>...</td>\n      <td>101.213867</td>\n      <td>1.390000</td>\n      <td>0.839996</td>\n      <td>0.739997</td>\n      <td>1.049995</td>\n      <td>-0.590004</td>\n      <td>0.610001</td>\n      <td>2937200.0</td>\n      <td>2443600.0</td>\n      <td>3618100.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015-12-04</td>\n      <td>105.809998</td>\n      <td>107.540001</td>\n      <td>105.620003</td>\n      <td>107.389999</td>\n      <td>101.421646</td>\n      <td>4520000</td>\n      <td>12</td>\n      <td>1.919998</td>\n      <td>-1.580001</td>\n      <td>...</td>\n      <td>102.167740</td>\n      <td>2.420005</td>\n      <td>1.390000</td>\n      <td>0.839996</td>\n      <td>1.840004</td>\n      <td>1.049995</td>\n      <td>-0.590004</td>\n      <td>3345600.0</td>\n      <td>2937200.0</td>\n      <td>2443600.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-12-07</td>\n      <td>107.230003</td>\n      <td>107.269997</td>\n      <td>106.059998</td>\n      <td>106.550003</td>\n      <td>100.628342</td>\n      <td>3000500</td>\n      <td>12</td>\n      <td>1.209999</td>\n      <td>0.680000</td>\n      <td>...</td>\n      <td>101.100533</td>\n      <td>1.919998</td>\n      <td>2.420005</td>\n      <td>1.390000</td>\n      <td>-1.580001</td>\n      <td>1.840004</td>\n      <td>1.049995</td>\n      <td>4520000.0</td>\n      <td>3345600.0</td>\n      <td>2937200.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n\n</div>\n\n\n\n<h3 id=\"第三步：数据标准化-Step-3-Data-standardization\"><a href=\"#第三步：数据标准化-Step-3-Data-standardization\" class=\"headerlink\" title=\"第三步：数据标准化 Step 3: Data standardization\"></a>第三步：数据标准化 Step 3: Data standardization</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 先统一计算出标准化的数据，在对其进行数据切分。\ncols_list &#x3D; [\n    &quot;adj_close&quot;,\n    &quot;range_hl&quot;,\n    &quot;range_oc&quot;,\n    &quot;volume&quot;\n]\nfor col in cols_list:\n    df &#x3D; get_mov_avg_std(df, col, N)</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">df.head()</code></pre>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj_close</th>\n      <th>volume</th>\n      <th>month</th>\n      <th>range_hl</th>\n      <th>range_oc</th>\n      <th>...</th>\n      <th>volume_lag_2</th>\n      <th>volume_lag_3</th>\n      <th>adj_close_mean</th>\n      <th>adj_close_std</th>\n      <th>range_hl_mean</th>\n      <th>range_hl_std</th>\n      <th>range_oc_mean</th>\n      <th>range_oc_std</th>\n      <th>volume_mean</th>\n      <th>volume_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>2015-12-01</td>\n      <td>107.589996</td>\n      <td>108.209999</td>\n      <td>107.370003</td>\n      <td>108.180000</td>\n      <td>102.167740</td>\n      <td>2443600</td>\n      <td>12</td>\n      <td>0.839996</td>\n      <td>-0.590004</td>\n      <td>...</td>\n      <td>552400.0</td>\n      <td>1820300.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-12-02</td>\n      <td>108.099998</td>\n      <td>108.269997</td>\n      <td>106.879997</td>\n      <td>107.050003</td>\n      <td>101.100533</td>\n      <td>2937200</td>\n      <td>12</td>\n      <td>1.390000</td>\n      <td>1.049995</td>\n      <td>...</td>\n      <td>3618100.0</td>\n      <td>552400.0</td>\n      <td>102.167740</td>\n      <td>NaN</td>\n      <td>0.839996</td>\n      <td>NaN</td>\n      <td>-0.590004</td>\n      <td>NaN</td>\n      <td>2.443600e+06</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015-12-03</td>\n      <td>107.290001</td>\n      <td>107.480003</td>\n      <td>105.059998</td>\n      <td>105.449997</td>\n      <td>99.589470</td>\n      <td>3345600</td>\n      <td>12</td>\n      <td>2.420005</td>\n      <td>1.840004</td>\n      <td>...</td>\n      <td>2443600.0</td>\n      <td>3618100.0</td>\n      <td>101.634136</td>\n      <td>0.754629</td>\n      <td>1.114998</td>\n      <td>0.388912</td>\n      <td>0.229995</td>\n      <td>1.159654</td>\n      <td>2.690400e+06</td>\n      <td>349027.907194</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015-12-04</td>\n      <td>105.809998</td>\n      <td>107.540001</td>\n      <td>105.620003</td>\n      <td>107.389999</td>\n      <td>101.421646</td>\n      <td>4520000</td>\n      <td>12</td>\n      <td>1.919998</td>\n      <td>-1.580001</td>\n      <td>...</td>\n      <td>2937200.0</td>\n      <td>2443600.0</td>\n      <td>100.952581</td>\n      <td>1.295487</td>\n      <td>1.550000</td>\n      <td>0.802064</td>\n      <td>0.766665</td>\n      <td>1.239533</td>\n      <td>2.908800e+06</td>\n      <td>451670.145128</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-12-07</td>\n      <td>107.230003</td>\n      <td>107.269997</td>\n      <td>106.059998</td>\n      <td>106.550003</td>\n      <td>100.628342</td>\n      <td>3000500</td>\n      <td>12</td>\n      <td>1.209999</td>\n      <td>0.680000</td>\n      <td>...</td>\n      <td>3345600.0</td>\n      <td>2937200.0</td>\n      <td>100.703883</td>\n      <td>0.978374</td>\n      <td>1.910001</td>\n      <td>0.515075</td>\n      <td>0.436666</td>\n      <td>1.790597</td>\n      <td>3.600933e+06</td>\n      <td>821711.806738</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n\n</div>\n\n\n\n<h3 id=\"第四步：生成训练数据和测试数据-Step-4-Train-x2F-Test-Data-Generation\"><a href=\"#第四步：生成训练数据和测试数据-Step-4-Train-x2F-Test-Data-Generation\" class=\"headerlink\" title=\"第四步：生成训练数据和测试数据 Step 4: Train&#x2F;Test Data Generation\"></a>第四步：生成训练数据和测试数据 Step 4: Train&#x2F;Test Data Generation</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 因训练数据和测试数据的标准化方式不同，因此需切分训练和测试数据。\nnum_test &#x3D; int(test_size * len(df))\nnum_train &#x3D; len(df) - num_test\ntrain &#x3D; df[:num_train]\ntest &#x3D; df[num_train:]</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">train.head()</code></pre>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj_close</th>\n      <th>volume</th>\n      <th>month</th>\n      <th>range_hl</th>\n      <th>range_oc</th>\n      <th>...</th>\n      <th>volume_lag_2</th>\n      <th>volume_lag_3</th>\n      <th>adj_close_mean</th>\n      <th>adj_close_std</th>\n      <th>range_hl_mean</th>\n      <th>range_hl_std</th>\n      <th>range_oc_mean</th>\n      <th>range_oc_std</th>\n      <th>volume_mean</th>\n      <th>volume_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>2015-12-01</td>\n      <td>107.589996</td>\n      <td>108.209999</td>\n      <td>107.370003</td>\n      <td>108.180000</td>\n      <td>102.167740</td>\n      <td>2443600</td>\n      <td>12</td>\n      <td>0.839996</td>\n      <td>-0.590004</td>\n      <td>...</td>\n      <td>552400.0</td>\n      <td>1820300.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-12-02</td>\n      <td>108.099998</td>\n      <td>108.269997</td>\n      <td>106.879997</td>\n      <td>107.050003</td>\n      <td>101.100533</td>\n      <td>2937200</td>\n      <td>12</td>\n      <td>1.390000</td>\n      <td>1.049995</td>\n      <td>...</td>\n      <td>3618100.0</td>\n      <td>552400.0</td>\n      <td>102.167740</td>\n      <td>NaN</td>\n      <td>0.839996</td>\n      <td>NaN</td>\n      <td>-0.590004</td>\n      <td>NaN</td>\n      <td>2.443600e+06</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015-12-03</td>\n      <td>107.290001</td>\n      <td>107.480003</td>\n      <td>105.059998</td>\n      <td>105.449997</td>\n      <td>99.589470</td>\n      <td>3345600</td>\n      <td>12</td>\n      <td>2.420005</td>\n      <td>1.840004</td>\n      <td>...</td>\n      <td>2443600.0</td>\n      <td>3618100.0</td>\n      <td>101.634136</td>\n      <td>0.754629</td>\n      <td>1.114998</td>\n      <td>0.388912</td>\n      <td>0.229995</td>\n      <td>1.159654</td>\n      <td>2.690400e+06</td>\n      <td>349027.907194</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015-12-04</td>\n      <td>105.809998</td>\n      <td>107.540001</td>\n      <td>105.620003</td>\n      <td>107.389999</td>\n      <td>101.421646</td>\n      <td>4520000</td>\n      <td>12</td>\n      <td>1.919998</td>\n      <td>-1.580001</td>\n      <td>...</td>\n      <td>2937200.0</td>\n      <td>2443600.0</td>\n      <td>100.952581</td>\n      <td>1.295487</td>\n      <td>1.550000</td>\n      <td>0.802064</td>\n      <td>0.766665</td>\n      <td>1.239533</td>\n      <td>2.908800e+06</td>\n      <td>451670.145128</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-12-07</td>\n      <td>107.230003</td>\n      <td>107.269997</td>\n      <td>106.059998</td>\n      <td>106.550003</td>\n      <td>100.628342</td>\n      <td>3000500</td>\n      <td>12</td>\n      <td>1.209999</td>\n      <td>0.680000</td>\n      <td>...</td>\n      <td>3345600.0</td>\n      <td>2937200.0</td>\n      <td>100.703883</td>\n      <td>0.978374</td>\n      <td>1.910001</td>\n      <td>0.515075</td>\n      <td>0.436666</td>\n      <td>1.790597</td>\n      <td>3.600933e+06</td>\n      <td>821711.806738</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n\n</div>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">test.head()</code></pre>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj_close</th>\n      <th>volume</th>\n      <th>month</th>\n      <th>range_hl</th>\n      <th>range_oc</th>\n      <th>...</th>\n      <th>volume_lag_2</th>\n      <th>volume_lag_3</th>\n      <th>adj_close_mean</th>\n      <th>adj_close_std</th>\n      <th>range_hl_mean</th>\n      <th>range_hl_std</th>\n      <th>range_oc_mean</th>\n      <th>range_oc_std</th>\n      <th>volume_mean</th>\n      <th>volume_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>605</th>\n      <td>2018-04-24</td>\n      <td>138.100006</td>\n      <td>138.190002</td>\n      <td>134.860001</td>\n      <td>135.800003</td>\n      <td>134.584366</td>\n      <td>3053500</td>\n      <td>4</td>\n      <td>3.330001</td>\n      <td>2.300003</td>\n      <td>...</td>\n      <td>1669600.0</td>\n      <td>4003900.0</td>\n      <td>136.616023</td>\n      <td>0.644186</td>\n      <td>1.383331</td>\n      <td>0.241734</td>\n      <td>0.589997</td>\n      <td>0.407800</td>\n      <td>2.569067e+06</td>\n      <td>1.255867e+06</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>2018-04-25</td>\n      <td>135.770004</td>\n      <td>136.250000</td>\n      <td>134.610001</td>\n      <td>135.949997</td>\n      <td>134.733032</td>\n      <td>2275400</td>\n      <td>4</td>\n      <td>1.639999</td>\n      <td>-0.179993</td>\n      <td>...</td>\n      <td>2033700.0</td>\n      <td>1669600.0</td>\n      <td>135.691040</td>\n      <td>0.958728</td>\n      <td>2.106669</td>\n      <td>1.069313</td>\n      <td>1.230001</td>\n      <td>0.995943</td>\n      <td>2.252267e+06</td>\n      <td>7.173725e+05</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>2018-04-26</td>\n      <td>136.520004</td>\n      <td>137.679993</td>\n      <td>136.250000</td>\n      <td>137.240005</td>\n      <td>136.011490</td>\n      <td>1284600</td>\n      <td>4</td>\n      <td>1.429993</td>\n      <td>-0.720001</td>\n      <td>...</td>\n      <td>3053500.0</td>\n      <td>2033700.0</td>\n      <td>135.179001</td>\n      <td>0.904249</td>\n      <td>2.106669</td>\n      <td>1.069313</td>\n      <td>0.816671</td>\n      <td>1.309668</td>\n      <td>2.454200e+06</td>\n      <td>5.328931e+05</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>2018-04-27</td>\n      <td>137.539993</td>\n      <td>137.740005</td>\n      <td>136.800003</td>\n      <td>137.330002</td>\n      <td>136.100677</td>\n      <td>1133600</td>\n      <td>4</td>\n      <td>0.940002</td>\n      <td>0.209991</td>\n      <td>...</td>\n      <td>2275400.0</td>\n      <td>3053500.0</td>\n      <td>135.109629</td>\n      <td>0.784564</td>\n      <td>2.133331</td>\n      <td>1.041653</td>\n      <td>0.466670</td>\n      <td>1.610508</td>\n      <td>2.204500e+06</td>\n      <td>8.865788e+05</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>2018-04-30</td>\n      <td>137.690002</td>\n      <td>137.990005</td>\n      <td>136.250000</td>\n      <td>136.330002</td>\n      <td>135.109634</td>\n      <td>2277100</td>\n      <td>4</td>\n      <td>1.740005</td>\n      <td>1.360000</td>\n      <td>...</td>\n      <td>1284600.0</td>\n      <td>2275400.0</td>\n      <td>135.615066</td>\n      <td>0.765165</td>\n      <td>1.336665</td>\n      <td>0.359210</td>\n      <td>-0.230001</td>\n      <td>0.467008</td>\n      <td>1.564533e+06</td>\n      <td>6.202409e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n\n</div>\n\n\n\n<h3 id=\"第五步：标签和特征的标准化-Step-5-Label-amp-Feature-Standardization\"><a href=\"#第五步：标签和特征的标准化-Step-5-Label-amp-Feature-Standardization\" class=\"headerlink\" title=\"第五步：标签和特征的标准化 Step 5: Label &amp; Feature Standardization\"></a>第五步：标签和特征的标准化 Step 5: Label &amp; Feature Standardization</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 此步的目的是为了对在训练集不能代表总体的情况下，使树模型正确运行的一种取巧\ncols_to_scale &#x3D; [\n    &quot;adj_close&quot;\n]\nfor i in range(1, N + 1):\n    cols_to_scale.append(&quot;adj_close_lag_&quot; + str(i))\n    cols_to_scale.append(&quot;range_hl_lag_&quot; + str(i))\n    cols_to_scale.append(&quot;range_oc_lag_&quot; + str(i))\n    cols_to_scale.append(&quot;volume_lag_&quot; + str(i))\n\nscaler &#x3D; StandardScaler() # 启示三：标准化也不应带测试集，以避免信息泄漏\ntrain_scaled &#x3D; scaler.fit_transform(train[cols_to_scale])\n# Convert the numpy array back into pandas dataframe\ntrain_scaled &#x3D; pd.DataFrame(train_scaled, columns&#x3D;cols_to_scale)\ntrain_scaled[[&#39;date&#39;, &#39;month&#39;]] &#x3D; train.reset_index()[[&#39;date&#39;, &#39;month&#39;]]\n\ntest_scaled &#x3D; test[[&#39;date&#39;]]\nfor col in tqdm(cols_list):\n    feat_list &#x3D; [col + &#39;_lag_&#39; + str(shift) for shift in range(1, N + 1)]\n    temp &#x3D; test.apply(lambda row: scale_row(row[feat_list], row[col + &#39;_mean&#39;], row[col + &#39;_std&#39;]), axis&#x3D;1)\n    test_scaled &#x3D; pd.concat([test_scaled, temp], axis&#x3D;1)</code></pre>\n\n<pre><code>100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 26.77it/s]\n</code></pre>\n<h3 id=\"第六步：建立样本-Step-6-Sample-Creation\"><a href=\"#第六步：建立样本-Step-6-Sample-Creation\" class=\"headerlink\" title=\"第六步：建立样本 Step 6: Sample Creation\"></a>第六步：建立样本 Step 6: Sample Creation</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">features &#x3D; []\nfor i in range(1, N + 1):\n    features.append(&quot;adj_close_lag_&quot; + str(i))\n    features.append(&quot;range_hl_lag_&quot; + str(i))\n    features.append(&quot;range_oc_lag_&quot; + str(i))\n    features.append(&quot;volume_lag_&quot; + str(i))\n\ntarget &#x3D; &quot;adj_close&quot;\n\nX_train &#x3D; train[features]\ny_train &#x3D; train[target]\nX_sample &#x3D; test[features]\ny_sample &#x3D; test[target]\n\nX_train_scaled &#x3D; train_scaled[features]\ny_train_scaled &#x3D; train_scaled[target]\nX_sample_scaled &#x3D; test_scaled[features]</code></pre>\n\n<h3 id=\"第七步：训练-Step-7-Training\"><a href=\"#第七步：训练-Step-7-Training\" class=\"headerlink\" title=\"第七步：训练 Step 7: Training\"></a>第七步：训练 Step 7: Training</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">from sklearn.model_selection import GridSearchCV</code></pre>\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">parameters&#x3D;&#123;&#39;n_estimators&#39;:[90],\n            &#39;max_depth&#39;:[7],\n            &#39;learning_rate&#39;: [0.3],\n            &#39;min_child_weight&#39;:range(5, 21, 1),\n            #&#39;subsample&#39;:[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n            #&#39;gamma&#39;:[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n            #&#39;colsample_bytree&#39;:[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n            #&#39;colsample_bylevel&#39;:[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n            &#125;\n#parameters&#x3D;&#123;&#39;max_depth&#39;:range(2,10,1)&#125;\nmodel&#x3D;XGBRegressor(seed&#x3D;model_seed,\n                     n_estimators&#x3D;100,\n                     max_depth&#x3D;3,\n                     eval_metric&#x3D;&#39;rmse&#39;,\n                     learning_rate&#x3D;0.1,\n                     min_child_weight&#x3D;1,\n                     subsample&#x3D;1,\n                     colsample_bytree&#x3D;1,\n                     colsample_bylevel&#x3D;1,\n                     gamma&#x3D;0)\ngs&#x3D;GridSearchCV(estimator&#x3D; model,param_grid&#x3D;parameters,cv&#x3D;5,refit&#x3D; True,scoring&#x3D;&#39;neg_mean_squared_error&#39;)\n\ngs.fit(X_train_scaled,y_train_scaled)\nprint (&#39;最优参数: &#39; + str(gs.best_params_))\n\nest_scaled &#x3D; gs.predict(X_train_scaled)\ntrain[&#39;est&#39;] &#x3D; est_scaled * math.sqrt(scaler.var_[0]) + scaler.mean_[0]\n\npre_y_scaled &#x3D; gs.predict(X_sample_scaled)\ntest[&#39;pre_y_scaled&#39;] &#x3D; pre_y_scaled\ntest[&#39;pre_y&#39;]&#x3D;test[&#39;pre_y_scaled&#39;] * test[&#39;adj_close_std&#39;] + test[&#39;adj_close_mean&#39;]\n\nplt.figure()\nax &#x3D; test.plot(x&#x3D;&#39;date&#39;, y&#x3D;&#39;adj_close&#39;, style&#x3D;&#39;b-&#39;, grid&#x3D;True)\nax &#x3D; test.plot(x&#x3D;&#39;date&#39;, y&#x3D;&#39;pre_y&#39;, style&#x3D;&#39;r-&#39;, grid&#x3D;True, ax&#x3D;ax)\nplt.show()\n\nrmse&#x3D;math.sqrt(mean_squared_error(y_sample, test[&#39;pre_y&#39;]))\nprint(&quot;RMSE on dev set &#x3D; %0.3f&quot; % rmse)\nmape &#x3D; get_mape(y_sample, test[&#39;pre_y&#39;])\nprint(&quot;MAPE on dev set &#x3D; %0.3f%%&quot; % mape)\n\nimp &#x3D; list(zip(train[features], gs.best_estimator_.feature_importances_))\nimp.sort(key&#x3D;lambda tup: tup[1])\nfor i in range(-1,-10,-1):\n    print(imp[i])</code></pre>\n\n<pre><code>最优参数: &#123;&#39;learning_rate&#39;: 0.3, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 7, &#39;n_estimators&#39;: 90&#125;\n\n\n/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train[&#39;est&#39;] = est_scaled * math.sqrt(scaler.var_[0]) + scaler.mean_[0]\n/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test[&#39;pre_y_scaled&#39;] = pre_y_scaled\n/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test[&#39;pre_y&#39;]=test[&#39;pre_y_scaled&#39;] * test[&#39;adj_close_std&#39;] + test[&#39;adj_close_mean&#39;]\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n</code></pre>\n<p><img src=\"/img/output_32_3.png\" alt=\"png\"></p>\n<pre><code>RMSE on dev set = 1.149\nMAPE on dev set = 0.581%\n(&#39;adj_close_lag_1&#39;, 0.8624093)\n(&#39;adj_close_lag_2&#39;, 0.10811194)\n(&#39;adj_close_lag_3&#39;, 0.026851863)\n(&#39;range_oc_lag_1&#39;, 0.00043455773)\n(&#39;volume_lag_2&#39;, 0.0003508884)\n(&#39;volume_lag_3&#39;, 0.00034092006)\n(&#39;range_hl_lag_2&#39;, 0.00028984202)\n(&#39;range_oc_lag_2&#39;, 0.00027450564)\n(&#39;range_oc_lag_3&#39;, 0.0002714092)\n</code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"></code></pre>","feature":true,"text":"XGBoostXGBoost是一个非常高效、应用广泛的GBDT机器学习库，详细信息可参考xgbbostXGBoost提供了高效简洁的python接口，可用于分类、回归任务。在本实验中使用了xgboost的分类接口。 下面是一个股票预测的例子： 所需要的包 Module Requi...","link":"","photos":[],"count_time":{"symbolsCount":"22k","symbolsTime":"20 mins."},"categories":[{"name":"机器学习Machine Learning","slug":"机器学习Machine-Learning","count":3,"path":"api/categories/机器学习Machine-Learning.json"}],"tags":[{"name":"Python","slug":"Python","count":2,"path":"api/tags/Python.json"},{"name":"机器学习","slug":"机器学习","count":3,"path":"api/tags/机器学习.json"},{"name":"推荐系统","slug":"推荐系统","count":3,"path":"api/tags/推荐系统.json"},{"name":"XGBoost","slug":"XGBoost","count":2,"path":"api/tags/XGBoost.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#XGBoost\"><span class=\"toc-text\">XGBoost</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85-Module-Required\"><span class=\"toc-text\">所需要的包 Module Required</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0-Parameters\"><span class=\"toc-text\">参数 Parameters</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD-Data-Loading\"><span class=\"toc-text\">数据加载 Data Loading</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Feature-engineering\"><span class=\"toc-text\">特征工程 Feature engineering</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96-Data-standardization\"><span class=\"toc-text\">数据标准化 Data standardization</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AE%A1%E7%AE%97%E7%BB%9D%E5%AF%B9%E7%99%BE%E5%88%86%E6%AF%94%E8%AF%AF%E5%B7%AE-MAPE\"><span class=\"toc-text\">计算绝对百分比误差 MAPE</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B-Main-Process\"><span class=\"toc-text\">整体流程 Main Process</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE-Step-1-Data-Loading\"><span class=\"toc-text\">第一步：获取数据 Step 1: Data Loading</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Step-2-Feature-engineering\"><span class=\"toc-text\">第二步：特征工程 Step 2: Feature engineering</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96-Step-3-Data-standardization\"><span class=\"toc-text\">第三步：数据标准化 Step 3: Data standardization</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E7%94%9F%E6%88%90%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E5%92%8C%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE-Step-4-Train-x2F-Test-Data-Generation\"><span class=\"toc-text\">第四步：生成训练数据和测试数据 Step 4: Train&#x2F;Test Data Generation</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E6%A0%87%E7%AD%BE%E5%92%8C%E7%89%B9%E5%BE%81%E7%9A%84%E6%A0%87%E5%87%86%E5%8C%96-Step-5-Label-amp-Feature-Standardization\"><span class=\"toc-text\">第五步：标签和特征的标准化 Step 5: Label &amp; Feature Standardization</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E5%85%AD%E6%AD%A5%EF%BC%9A%E5%BB%BA%E7%AB%8B%E6%A0%B7%E6%9C%AC-Step-6-Sample-Creation\"><span class=\"toc-text\">第六步：建立样本 Step 6: Sample Creation</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%B8%83%E6%AD%A5%EF%BC%9A%E8%AE%AD%E7%BB%83-Step-7-Training\"><span class=\"toc-text\">第七步：训练 Step 7: Training</span></a></li></ol></li></ol>","author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/email.png","link":"mailto:code.quan666zhang@gmail.com"}}}},"mapped":true,"prev_post":{"title":"SNN-Spike Neural Network","uid":"6588ccbfb741c3887af0529d54933115","slug":"SNN-Spike-Neural-Network","date":"2023-02-24T02:00:15.000Z","updated":"2024-11-06T02:24:29.743Z","comments":true,"path":"api/articles/SNN-Spike-Neural-Network.json","keywords":null,"cover":"/img/ai.jpg","text":"谨以此博客纪念一下近一个月以来的意难平。 踏足这个领域源于本周二的一封邮件。年轻人总是不屈于现状想在四方debuff中。时隔两年，回国工作之后语言水平直线下降，基础知识已然模糊。这些都是借口，奔三路上近乎一事无成，各种滋味，环境迫使，犹如溺水之孩。 意难平意难平，为资质平庸所累，...","link":"","photos":[],"count_time":{"symbolsCount":"5.2k","symbolsTime":"5 mins."},"categories":[{"name":"Deep Learning","slug":"Deep-Learning","count":2,"path":"api/categories/Deep-Learning.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"},{"name":"SNN","slug":"SNN","count":1,"path":"api/tags/SNN.json"}],"author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/email.png","link":"mailto:code.quan666zhang@gmail.com"}}}},"feature":true},"next_post":{"title":"AutoXGB(XGboost + optuna)","uid":"41e8b66af73631eb10964784b17cc5fa","slug":"AutoXGB","date":"2023-02-09T10:23:39.000Z","updated":"2024-11-06T02:24:29.761Z","comments":true,"path":"api/articles/AutoXGB.json","keywords":null,"cover":"/img/ai.jpg","text":"简介 Introduction源代码地址（Source code url） XGBoost + Optuna: no brainer auto train xgboost directly from CSV files auto tune xgboost using optuna...","link":"","photos":[],"count_time":{"symbolsCount":"4.3k","symbolsTime":"4 mins."},"categories":[{"name":"机器学习Machine Learning","slug":"机器学习Machine-Learning","count":3,"path":"api/categories/机器学习Machine-Learning.json"}],"tags":[{"name":"Python","slug":"Python","count":2,"path":"api/tags/Python.json"},{"name":"机器学习","slug":"机器学习","count":3,"path":"api/tags/机器学习.json"},{"name":"推荐系统","slug":"推荐系统","count":3,"path":"api/tags/推荐系统.json"},{"name":"XGBoost","slug":"XGBoost","count":2,"path":"api/tags/XGBoost.json"}],"author":{"name":"Quanito","slug":"blog-author","avatar":"/staticImg/avatar.jpg","link":"/","description":"大道五十，天衍四十九，人遁其一","socials":{"github":"https://github.com/1250681923","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"GoogleMail":{"icon":"/img/email.png","link":"mailto:code.quan666zhang@gmail.com"}}}}}}
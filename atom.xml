<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://quanzhang.top/atom.xml" rel="self"/>
  
  <link href="http://quanzhang.top/"/>
  <updated>2024-11-06T02:24:29.749Z</updated>
  <id>http://quanzhang.top/</id>
  
  <author>
    <name>Quan ZHANG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大语言模型引言</title>
    <link href="http://quanzhang.top/post/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BC%95%E8%A8%80.html"/>
    <id>http://quanzhang.top/post/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BC%95%E8%A8%80.html</id>
    <published>2023-08-22T01:36:50.000Z</published>
    <updated>2024-11-06T02:24:29.749Z</updated>
    
    <content type="html"><![CDATA[<p>从这几年的工作经验说起，接触最多的莫过于思考大模型在工业制造领域的落地可能性。目前工业制造领域引入大模型，从降本提效角度出发，加速促进AI技术落地。</p><p>但遇见了很多问题，无论是人文还是技术层面，很难进展。</p><p>人文</p><ul><li>大部分企业并不看好LLM，只是期望从这个话题中引入资金</li><li>从基础软件阶段，跳过大数据时代直接迈入人工智能时代是一个悖论</li><li>数据管理过于拉垮，很多央国企数据中心还未将数据资产化</li><li>央国企技术人员多为底层，无任何激励，无资源支持，工作之余无精力为事业进一步探索，全靠责任心无法进展</li><li>二次分配不合理，大部分开发迫于工作压力无精力转行，LLM是一个长期投资方向，如果短期无收益，所在企业也不支持</li></ul><p>最终很多行业迫于项目验收压力，采购一系列显卡服务器硬件，以及阿里百度等研发的集成框架软件，美其名曰引入LLM。实则与本公司开发员工相距甚远，最终不了了之。</p><p>技术</p><ul><li>企业数据资产化落伍严重，无数据支撑无法挖掘LLM经济潜力，而数据资产化也是长期投资</li><li>动态数据和静态数据划分缺方法论。导致落地方为探索第一步。初期划分不合理，会导致严重资源浪费，经常会了解到有真正在落地的项目，每几个月就要重新训练一次大模型</li><li>技术壁垒高，方法不确定，框架设计需要从顶层设计，大部分牛马没这个地位</li><li>目前集成框架软件化，如OLLAMA、XInference等等，大部分企业一步慢步步慢，如果开发不懂底层集成逻辑，更难进一步调优，技术完全黑盒化</li></ul><p>现状就写到这里吧，越写越气。</p><p>那么从个人角度出发，这是一个很好的接触新科技的方法。将分为以下几步进行</p><ul><li>学习集成框架底层</li><li>学习模型调优、微调、训练手段</li><li>学有余力研究剪枝等方法</li><li>自己尝试做算法集管理</li><li>尝试跟随智谱AI，做产品化</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从这几年的工作经验说起，接触最多的莫过于思考大模型在工业制造领域的落地可能性。目前工业制造领域引入大模型，从降本提效角度出发，加速促进AI技术落地。&lt;/p&gt;
&lt;p&gt;但遇见了很多问题，无论是人文还是技术层面，很难进展。&lt;/p&gt;
&lt;p&gt;人文&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大部分企业</summary>
      
    
    
    
    <category term="大语言模型LLM" scheme="http://quanzhang.top/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BLLM/"/>
    
    
    <category term="人工智能" scheme="http://quanzhang.top/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="大语言模型LLM" scheme="http://quanzhang.top/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BLLM/"/>
    
  </entry>
  
  <entry>
    <title>SNN-Spike Neural Network</title>
    <link href="http://quanzhang.top/post/SNN-Spike-Neural-Network.html"/>
    <id>http://quanzhang.top/post/SNN-Spike-Neural-Network.html</id>
    <published>2023-02-24T02:00:15.000Z</published>
    <updated>2024-11-06T02:24:29.743Z</updated>
    
    <content type="html"><![CDATA[<p>谨以此博客纪念一下近一个月以来的意难平。</p><p>踏足这个领域源于本周二的一封邮件。年轻人总是不屈于现状想在四方debuff中。时隔两年，回国工作之后语言水平直线下降，基础知识已然模糊。这些都是借口，奔三路上近乎一事无成，各种滋味，环境迫使，犹如溺水之孩。</p><p>意难平意难平，为资质平庸所累，言语再多只有悲喜自渡。</p><p>emo结束，言归正传，面试SNN的一个Phd offer。为图卢兹计算机研究院全奖课题Hybrid AI based on Spiking Neural Networks (SNNs)。同时了解了一点脉冲神经网络的基础知识。</p><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p>首先，第一篇论文出自于IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 14, NO. 6  题目为<em><strong>Simple Model of Spiking Neurons</strong></em>。下发为按要求整理的文章小结。</p><p>In this paper, a simple spiking model is presented. This model depends on 4 parameters which reproduces spiking and bursting behavior of known types of cortical neurons by reducing biophysically accurate Hodgkin-Huxley-type neuronal models to a 2D system:</p><p>在本文中，提出了一个简单的脉冲模型。 该模型取决于 4 个参数，这些参数通过将生物物理学上准确的 Hodgkin-Huxley 型神经元模型简化为 2D 系统来重现已知类型皮层神经元的尖峰和爆发行为：</p><p><img src="/SNN/wpsIVJTRR.jpg" alt="img"> </p><p>Where v,u,a,b,c,d are dimensionless.</p><p>其中 v、u、a、b、c、d 是无量纲的。</p><p>As shown in Fig2, each inset shows a voltage response of the model neuron to a step of dc-current. Various choices of the parameters result in various patterns of spiking and bursting which can easily reproduce behavior of excitatory cortical cells (RS, IB, CH), inhibitory cortical cells (FS, LTS), thalamo-cortical neurons (TC) and other types of neurons (RZ). Dynamics of other neuronal types, including those in brainstem, hippocampus, basal ganglia, and olfactory bulb, can also be described.</p><p>如图 2 所示，每个插图显示模型神经元对直流电流阶跃的电压响应。 参数的各种选择导致各种尖峰和爆发模式，可以轻松重现兴奋性皮层细胞（RS、IB、CH）、抑制性皮层细胞（FS、LTS）、丘脑-皮层神经元（TC）和其他类型神经元的行为 神经元 (RZ)。 还可以描述其他神经元类型的动力学，包括脑干、海马、基底神经节和嗅球中的神经元类型。</p><p>Excitatory cortical neurons fire low frequency trains of action potentials with a spike frequency adaptation (called the spike frequency adaptation). TZ has 2 firing regimes depends on the +&#x2F;- current step delivered. RZ can be switched between resting and repetitive spiking states by an appropriately timed brief stimulus.</p><p>兴奋性皮层神经元发射具有尖峰频率适应（称为尖峰频率适应）的低频动作电位序列。 TZ 有 2 种发射机制，具体取决于交付的 +&#x2F;- 当前步长。 RZ 可以通过适当定时的短暂刺激在静止状态和重复尖峰状态之间切换。</p><p>A sparse network of randomly connected 1000 spiking cortical neurons in real time has been simulated using this model.  The ratio of excitatory to inhibitory neurons to be 4 to 1 and they used RS cells to model all excitatory neurons and FS cells to model all inhibitory neurons.</p><p>使用该模型实时模拟了一个由随机连接的 1000 个尖峰皮层神经元组成的稀疏网络。 兴奋性神经元与抑制性神经元的比例为 4 比 1，他们使用 RS 细胞模拟所有兴奋性神经元，使用 FS 细胞模拟所有抑制性神经元。</p><p>The result shows that neurons fire Poisson spike trains with mean firing rates around 8 Hz and there are occasional episodes of synchronized firings in the alpha and gamma frequency range (10 and 40 Hz, respectively). This simple spiking model describes accurately dynamics of known types of cortical neurons. Thus, there is no contradiction between biological plausibility and computational efficiency of model neural networks</p><p>结果表明，神经元以大约 8 Hz 的平均发射率发射泊松尖峰序列，并且偶尔会在 alpha 和 gamma 频率范围（分别为 10 和 40 Hz）内同步发射。 这个简单的尖峰模型准确地描述了已知类型的皮层神经元的动力学。 因此，模型神经网络的生物学合理性和计算效率之间不存在矛盾</p><p>The authors have also used this model to simulate a sparse network of 10 000 spiking cortical neurons with 1 000 000 synaptic connections in real time using 1 GHZ desktop PC which can simulate thalamo-cortical networks consisting of tens of thousands of spiking neurons in real time with 1 ms resolution.</p><p>作者还使用该模型使用 1 GHZ 台式电脑实时模拟了由 10 000 个尖峰皮层神经元和 1 000 000 个突触连接组成的稀疏网络，该 PC 可以实时模拟由数万个尖峰神经元组成的丘脑-皮质网络 分辨率为 1 毫秒。</p><h2 id="SNN基础知识"><a href="#SNN基础知识" class="headerlink" title="SNN基础知识"></a>SNN基础知识</h2><p>首先，SNN作为第三代神经网络，目前没有可用的package，模型构造方式和评估手段没有一个统一的标准。由于神经元采用脉冲函数，不具备线性算法的连续性和可导性，因此传统的BP无法使用。尽管近几年有人模拟出相似算法并应用于CIFAR和MNIST数据集，但是效果较于上一代BP神经网络还是略弱，但精确度随着研究的发展逐步提升。由于脉冲神经网络参数量级和能耗较上一代神经网络框架优势极大，因此相关的研究是很有必要的。</p><p>参考项目：<a href="https://github.com/1250681923/Spiking-Neural-Network">https://github.com/1250681923/Spiking-Neural-Network</a></p><p>参考调查论文：<a href="https://www.researchgate.net/publication/361276255_Spiking_Neural_Networks_A_Survey%EF%BC%88[IEEE">https://www.researchgate.net/publication/361276255_Spiking_Neural_Networks_A_Survey（[IEEE</a> Access](<a href="https://www.researchgate.net/journal/IEEE-Access-2169-3536">https://www.researchgate.net/journal/IEEE-Access-2169-3536</a>) 10， June 2022）</p><p>Principe SNN </p><p><img src="/SNN/wps2UpCDD.png" alt="img"> </p><p>Compared with the ANN network with large amount of computation, SNN network can usually obtain lower power consumption.</p><p><img src="/SNN/wpstwOm9H.jpg" alt="img"> </p><p><img src="/SNN/wps9Nmz2E.png" alt="img"> </p><p>Method of converting picture signal into spike signal:</p><ol><li><p>As (a), we change the original pixel intensity of the sample to a binary value (usually normalized to [0,1])</p></li><li><p>As 3 (b). Use an encoder to generate a global spike signal. Each neuron of this encoder receives the intensity signal of multiple pixels of the picture as input and generates spike as output.</p></li></ol><p>How to train SNNs</p><p>Iterative version of LIF model</p><p><img src="/SNN/wpsXSKJ1u.jpg" alt="img"> </p><p>The parameters of the iterative version of the LIF model can be updated (Using STBP) as follows:</p><p><img src="/SNN/wpsupsjXp.jpg" alt="img"> </p><p>Evaluation</p><ol><li>Recognition accuracy</li></ol><p><img src="/SNN/wpsc8lmRC.jpg" alt="img"> </p><p>We first calculate the fire rate of each output neuron, that is, the spike rate, within the given time window T. Then take the neuron with the highest fire rate as the output.</p><p><img src="/SNN/wpsw6xSHa.jpg" alt="img" style="zoom:25%;" />means the output of the neuron i in layer N at t</p><ol start="2"><li>Compute cost</li></ol><p>Also as shown in <a href="https://github.com/1250681923/Spiking-Neural-Network">https://github.com/1250681923/Spiking-Neural-Network</a></p><p>Spike Time Dependent Plasticity</p><p>STDP is actually a biological process used by brain to modify its neural connections (synapses). Molding of weights is based on the following two rules:</p><ul><li><p>Any synapse that contribute to the firing of a post-synaptic neuron should be made strong. its value should be increased.</p></li><li><p>Synapses that don’t contribute to the firing of a post-synaptic neuron should be limited. its value should be decreased.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;谨以此博客纪念一下近一个月以来的意难平。&lt;/p&gt;
&lt;p&gt;踏足这个领域源于本周二的一封邮件。年轻人总是不屈于现状想在四方debuff中。时隔两年，回国工作之后语言水平直线下降，基础知识已然模糊。这些都是借口，奔三路上近乎一事无成，各种滋味，环境迫使，犹如溺水之孩。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Deep Learning" scheme="http://quanzhang.top/categories/Deep-Learning/"/>
    
    
    <category term="深度学习" scheme="http://quanzhang.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="SNN" scheme="http://quanzhang.top/tags/SNN/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost</title>
    <link href="http://quanzhang.top/post/XGBoost.html"/>
    <id>http://quanzhang.top/post/XGBoost.html</id>
    <published>2023-02-10T07:21:14.000Z</published>
    <updated>2024-11-06T02:24:29.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>XGBoost是一个非常高效、应用广泛的GBDT机器学习库，详细信息可参考<a href="https://xgboost.readthedocs.io/en/latest/">xgbbost</a><br>XGBoost提供了高效简洁的python接口，可用于分类、回归任务。在本实验中使用了xgboost的分类接口。</p><p>下面是一个股票预测的例子：</p><h2 id="所需要的包-Module-Required"><a href="#所需要的包-Module-Required" class="headerlink" title="所需要的包 Module Required"></a>所需要的包 Module Required</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import mathimport matplotlibimport numpy as npimport pandas  as pdimport seaborn as snsimport timefrom datetime import datefrom matplotlib import pyplot as pltfrom pylab import rcParamsfrom sklearn.metrics import mean_squared_errorfrom sklearn.preprocessing import StandardScalerfrom tqdm import tqdmfrom xgboost import XGBRegressor</code></pre><h2 id="参数-Parameters"><a href="#参数-Parameters" class="headerlink" title="参数 Parameters"></a>参数 Parameters</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_size &#x3D; 0.2                # proportion of dataset to be used as test setN &#x3D; 3                          # for feature at day t, we use lags from t-1, t-2, ..., t-N as featuresmodel_seed &#x3D; 100</code></pre><h2 id="数据加载-Data-Loading"><a href="#数据加载-Data-Loading" class="headerlink" title="数据加载 Data Loading"></a>数据加载 Data Loading</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">def _load_data():    #stk_path &#x3D; &quot;&#x2F;content&#x2F;drive&#x2F;MyDrive&#x2F;Colab Notebooks&#x2F;data_samples&#x2F;VTI.csv&quot;    stk_path &#x3D; &quot;.&#x2F;VTI.csv&quot;    df &#x3D; pd.read_csv(stk_path, sep&#x3D;&quot;,&quot;)    # Convert Date column to datetime    df.loc[:, &#39;Date&#39;] &#x3D; pd.to_datetime(df[&#39;Date&#39;], format&#x3D;&#39;%Y-%m-%d&#39;)    # Change all column headings to be lower case, and remove spacing    df.columns &#x3D; [str(x).lower().replace(&#39; &#39;, &#39;_&#39;) for x in df.columns]    # Get month of each sample    df[&#39;month&#39;] &#x3D; df[&#39;date&#39;].dt.month    # Sort by datetime    df.sort_values(by&#x3D;&#39;date&#39;, inplace&#x3D;True, ascending&#x3D;True)    return df</code></pre><h2 id="特征工程-Feature-engineering"><a href="#特征工程-Feature-engineering" class="headerlink" title="特征工程 Feature engineering"></a>特征工程 Feature engineering</h2><p>生成新特征：最高最低价差、开盘收盘价差；前N天的信息拼入当天，作为当天的特征<br>Generate new features: highest and lowest price difference, opening and closing price difference; The information of the previous N days is put into the current day as the characteristics of the current day</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def feature_engineer(df):    df[&#39;range_hl&#39;] &#x3D; df[&#39;high&#39;] - df[&#39;low&#39;]    df[&#39;range_oc&#39;] &#x3D; df[&#39;open&#39;] - df[&#39;close&#39;]    lag_cols &#x3D; [&#39;adj_close&#39;, &#39;range_hl&#39;, &#39;range_oc&#39;, &#39;volume&#39;]    shift_range &#x3D; [x + 1 for x in range(N)]    for col in lag_cols:        for i in shift_range:            new_col&#x3D;&#39;&#123;&#125;_lag_&#123;&#125;&#39;.format(col, i)   # 格式化字符串            df[new_col]&#x3D;df[col].shift(i)    return df[N:]</code></pre><h2 id="数据标准化-Data-standardization"><a href="#数据标准化-Data-standardization" class="headerlink" title="数据标准化 Data standardization"></a>数据标准化 Data standardization</h2><p><a href="https://www.zhihu.com/question/58883125/answer/206813653">XGBoost</a>的本质为树模型，树模型本身无需做数据标准化。但是，在树模型中，若训练集不能代表总体，即测试集中出现训练集中从未出现的特征及回归值（训练数据过少或股价前所未有的高&#x2F;底），模型的效果基本没有效果。</p><p>因此，需要对数据做“非常规”的标准化做折中，以使模型能正常运行。这里的“非常规”指计算前N天内的标准差和均值，为当天数据的标准化作准备。这样做会丢失一部分数据信息，仅仅是为了让树模型正常运行的一种取巧。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def get_mov_avg_std(df, col, N):    &quot;&quot;&quot;    Given a dataframe, get mean and std dev at timestep t using values from t-1, t-2, ..., t-N.    Inputs        df         : dataframe. Can be of any length.        col        : name of the column you want to calculate mean and std dev        N          : get mean and std dev at timestep t using values from t-1, t-2, ..., t-N    Outputs        df_out     : same as df but with additional column containing mean and std dev    &quot;&quot;&quot;    mean_list &#x3D; df[col].rolling(window&#x3D;N, min_periods&#x3D;1).mean()  # len(mean_list) &#x3D; len(df)    std_list &#x3D; df[col].rolling(window&#x3D;N, min_periods&#x3D;1).std()  # first value will be NaN, because normalized by N-1    # Add one timestep to the predictions ,这里又shift了一步    mean_list &#x3D; np.concatenate((np.array([np.nan]), np.array(mean_list[:-1])))    std_list &#x3D; np.concatenate((np.array([np.nan]), np.array(std_list[:-1])))    # Append mean_list to df    df_out &#x3D; df.copy()    df_out[col + &#39;_mean&#39;] &#x3D; mean_list    df_out[col + &#39;_std&#39;] &#x3D; std_list    return df_outdef scale_row(row, feat_mean, feat_std):    &quot;&quot;&quot;    Given a pandas series in row, scale it to have 0 mean and var 1 using feat_mean and feat_std    Inputs        row      : pandas series. Need to scale this.        feat_mean: mean        feat_std : standard deviation    Outputs        row_scaled : pandas series with same length as row, but scaled    &quot;&quot;&quot;    # If feat_std &#x3D; 0 (this happens if adj_close doesn&#39;t change over N days),    # set it to a small number to avoid division by zero    feat_std &#x3D; 0.001 if feat_std &#x3D;&#x3D; 0 else feat_std    row_scaled &#x3D; (row - feat_mean) &#x2F; feat_std    return row_scaled</code></pre><h2 id="计算绝对百分比误差-MAPE"><a href="#计算绝对百分比误差-MAPE" class="headerlink" title="计算绝对百分比误差 MAPE"></a>计算绝对百分比误差 MAPE</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">def get_mape(y_true, y_pred):    &quot;&quot;&quot;    Compute mean absolute percentage error (MAPE)    &quot;&quot;&quot;    y_true, y_pred &#x3D; np.array(y_true), np.array(y_pred)    return np.mean(np.abs((y_true - y_pred) &#x2F; y_true)) * 100</code></pre><h2 id="整体流程-Main-Process"><a href="#整体流程-Main-Process" class="headerlink" title="整体流程 Main Process"></a>整体流程 Main Process</h2><h3 id="第一步：获取数据-Step-1-Data-Loading"><a href="#第一步：获取数据-Step-1-Data-Loading" class="headerlink" title="第一步：获取数据 Step 1: Data Loading"></a>第一步：获取数据 Step 1: Data Loading</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">data_df&#x3D;_load_data()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">data_df.head()</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>high</th>      <th>low</th>      <th>close</th>      <th>adj_close</th>      <th>volume</th>      <th>month</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2015-11-25</td>      <td>107.510002</td>      <td>107.660004</td>      <td>107.250000</td>      <td>107.470001</td>      <td>101.497200</td>      <td>1820300</td>      <td>11</td>    </tr>    <tr>      <th>1</th>      <td>2015-11-27</td>      <td>107.589996</td>      <td>107.760002</td>      <td>107.220001</td>      <td>107.629997</td>      <td>101.648300</td>      <td>552400</td>      <td>11</td>    </tr>    <tr>      <th>2</th>      <td>2015-11-30</td>      <td>107.779999</td>      <td>107.849998</td>      <td>107.110001</td>      <td>107.169998</td>      <td>101.213867</td>      <td>3618100</td>      <td>11</td>    </tr>    <tr>      <th>3</th>      <td>2015-12-01</td>      <td>107.589996</td>      <td>108.209999</td>      <td>107.370003</td>      <td>108.180000</td>      <td>102.167740</td>      <td>2443600</td>      <td>12</td>    </tr>    <tr>      <th>4</th>      <td>2015-12-02</td>      <td>108.099998</td>      <td>108.269997</td>      <td>106.879997</td>      <td>107.050003</td>      <td>101.100533</td>      <td>2937200</td>      <td>12</td>    </tr>  </tbody></table></div><h3 id="第二步：特征工程-Step-2-Feature-engineering"><a href="#第二步：特征工程-Step-2-Feature-engineering" class="headerlink" title="第二步：特征工程 Step 2: Feature engineering"></a>第二步：特征工程 Step 2: Feature engineering</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">df&#x3D;feature_engineer(data_df)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">df.head()</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>high</th>      <th>low</th>      <th>close</th>      <th>adj_close</th>      <th>volume</th>      <th>month</th>      <th>range_hl</th>      <th>range_oc</th>      <th>...</th>      <th>adj_close_lag_3</th>      <th>range_hl_lag_1</th>      <th>range_hl_lag_2</th>      <th>range_hl_lag_3</th>      <th>range_oc_lag_1</th>      <th>range_oc_lag_2</th>      <th>range_oc_lag_3</th>      <th>volume_lag_1</th>      <th>volume_lag_2</th>      <th>volume_lag_3</th>    </tr>  </thead>  <tbody>    <tr>      <th>3</th>      <td>2015-12-01</td>      <td>107.589996</td>      <td>108.209999</td>      <td>107.370003</td>      <td>108.180000</td>      <td>102.167740</td>      <td>2443600</td>      <td>12</td>      <td>0.839996</td>      <td>-0.590004</td>      <td>...</td>      <td>101.497200</td>      <td>0.739997</td>      <td>0.540001</td>      <td>0.410004</td>      <td>0.610001</td>      <td>-0.040001</td>      <td>0.040001</td>      <td>3618100.0</td>      <td>552400.0</td>      <td>1820300.0</td>    </tr>    <tr>      <th>4</th>      <td>2015-12-02</td>      <td>108.099998</td>      <td>108.269997</td>      <td>106.879997</td>      <td>107.050003</td>      <td>101.100533</td>      <td>2937200</td>      <td>12</td>      <td>1.390000</td>      <td>1.049995</td>      <td>...</td>      <td>101.648300</td>      <td>0.839996</td>      <td>0.739997</td>      <td>0.540001</td>      <td>-0.590004</td>      <td>0.610001</td>      <td>-0.040001</td>      <td>2443600.0</td>      <td>3618100.0</td>      <td>552400.0</td>    </tr>    <tr>      <th>5</th>      <td>2015-12-03</td>      <td>107.290001</td>      <td>107.480003</td>      <td>105.059998</td>      <td>105.449997</td>      <td>99.589470</td>      <td>3345600</td>      <td>12</td>      <td>2.420005</td>      <td>1.840004</td>      <td>...</td>      <td>101.213867</td>      <td>1.390000</td>      <td>0.839996</td>      <td>0.739997</td>      <td>1.049995</td>      <td>-0.590004</td>      <td>0.610001</td>      <td>2937200.0</td>      <td>2443600.0</td>      <td>3618100.0</td>    </tr>    <tr>      <th>6</th>      <td>2015-12-04</td>      <td>105.809998</td>      <td>107.540001</td>      <td>105.620003</td>      <td>107.389999</td>      <td>101.421646</td>      <td>4520000</td>      <td>12</td>      <td>1.919998</td>      <td>-1.580001</td>      <td>...</td>      <td>102.167740</td>      <td>2.420005</td>      <td>1.390000</td>      <td>0.839996</td>      <td>1.840004</td>      <td>1.049995</td>      <td>-0.590004</td>      <td>3345600.0</td>      <td>2937200.0</td>      <td>2443600.0</td>    </tr>    <tr>      <th>7</th>      <td>2015-12-07</td>      <td>107.230003</td>      <td>107.269997</td>      <td>106.059998</td>      <td>106.550003</td>      <td>100.628342</td>      <td>3000500</td>      <td>12</td>      <td>1.209999</td>      <td>0.680000</td>      <td>...</td>      <td>101.100533</td>      <td>1.919998</td>      <td>2.420005</td>      <td>1.390000</td>      <td>-1.580001</td>      <td>1.840004</td>      <td>1.049995</td>      <td>4520000.0</td>      <td>3345600.0</td>      <td>2937200.0</td>    </tr>  </tbody></table><p>5 rows × 22 columns</p></div><h3 id="第三步：数据标准化-Step-3-Data-standardization"><a href="#第三步：数据标准化-Step-3-Data-standardization" class="headerlink" title="第三步：数据标准化 Step 3: Data standardization"></a>第三步：数据标准化 Step 3: Data standardization</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 先统一计算出标准化的数据，在对其进行数据切分。cols_list &#x3D; [    &quot;adj_close&quot;,    &quot;range_hl&quot;,    &quot;range_oc&quot;,    &quot;volume&quot;]for col in cols_list:    df &#x3D; get_mov_avg_std(df, col, N)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">df.head()</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>high</th>      <th>low</th>      <th>close</th>      <th>adj_close</th>      <th>volume</th>      <th>month</th>      <th>range_hl</th>      <th>range_oc</th>      <th>...</th>      <th>volume_lag_2</th>      <th>volume_lag_3</th>      <th>adj_close_mean</th>      <th>adj_close_std</th>      <th>range_hl_mean</th>      <th>range_hl_std</th>      <th>range_oc_mean</th>      <th>range_oc_std</th>      <th>volume_mean</th>      <th>volume_std</th>    </tr>  </thead>  <tbody>    <tr>      <th>3</th>      <td>2015-12-01</td>      <td>107.589996</td>      <td>108.209999</td>      <td>107.370003</td>      <td>108.180000</td>      <td>102.167740</td>      <td>2443600</td>      <td>12</td>      <td>0.839996</td>      <td>-0.590004</td>      <td>...</td>      <td>552400.0</td>      <td>1820300.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>4</th>      <td>2015-12-02</td>      <td>108.099998</td>      <td>108.269997</td>      <td>106.879997</td>      <td>107.050003</td>      <td>101.100533</td>      <td>2937200</td>      <td>12</td>      <td>1.390000</td>      <td>1.049995</td>      <td>...</td>      <td>3618100.0</td>      <td>552400.0</td>      <td>102.167740</td>      <td>NaN</td>      <td>0.839996</td>      <td>NaN</td>      <td>-0.590004</td>      <td>NaN</td>      <td>2.443600e+06</td>      <td>NaN</td>    </tr>    <tr>      <th>5</th>      <td>2015-12-03</td>      <td>107.290001</td>      <td>107.480003</td>      <td>105.059998</td>      <td>105.449997</td>      <td>99.589470</td>      <td>3345600</td>      <td>12</td>      <td>2.420005</td>      <td>1.840004</td>      <td>...</td>      <td>2443600.0</td>      <td>3618100.0</td>      <td>101.634136</td>      <td>0.754629</td>      <td>1.114998</td>      <td>0.388912</td>      <td>0.229995</td>      <td>1.159654</td>      <td>2.690400e+06</td>      <td>349027.907194</td>    </tr>    <tr>      <th>6</th>      <td>2015-12-04</td>      <td>105.809998</td>      <td>107.540001</td>      <td>105.620003</td>      <td>107.389999</td>      <td>101.421646</td>      <td>4520000</td>      <td>12</td>      <td>1.919998</td>      <td>-1.580001</td>      <td>...</td>      <td>2937200.0</td>      <td>2443600.0</td>      <td>100.952581</td>      <td>1.295487</td>      <td>1.550000</td>      <td>0.802064</td>      <td>0.766665</td>      <td>1.239533</td>      <td>2.908800e+06</td>      <td>451670.145128</td>    </tr>    <tr>      <th>7</th>      <td>2015-12-07</td>      <td>107.230003</td>      <td>107.269997</td>      <td>106.059998</td>      <td>106.550003</td>      <td>100.628342</td>      <td>3000500</td>      <td>12</td>      <td>1.209999</td>      <td>0.680000</td>      <td>...</td>      <td>3345600.0</td>      <td>2937200.0</td>      <td>100.703883</td>      <td>0.978374</td>      <td>1.910001</td>      <td>0.515075</td>      <td>0.436666</td>      <td>1.790597</td>      <td>3.600933e+06</td>      <td>821711.806738</td>    </tr>  </tbody></table><p>5 rows × 30 columns</p></div><h3 id="第四步：生成训练数据和测试数据-Step-4-Train-x2F-Test-Data-Generation"><a href="#第四步：生成训练数据和测试数据-Step-4-Train-x2F-Test-Data-Generation" class="headerlink" title="第四步：生成训练数据和测试数据 Step 4: Train&#x2F;Test Data Generation"></a>第四步：生成训练数据和测试数据 Step 4: Train&#x2F;Test Data Generation</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 因训练数据和测试数据的标准化方式不同，因此需切分训练和测试数据。num_test &#x3D; int(test_size * len(df))num_train &#x3D; len(df) - num_testtrain &#x3D; df[:num_train]test &#x3D; df[num_train:]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train.head()</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>high</th>      <th>low</th>      <th>close</th>      <th>adj_close</th>      <th>volume</th>      <th>month</th>      <th>range_hl</th>      <th>range_oc</th>      <th>...</th>      <th>volume_lag_2</th>      <th>volume_lag_3</th>      <th>adj_close_mean</th>      <th>adj_close_std</th>      <th>range_hl_mean</th>      <th>range_hl_std</th>      <th>range_oc_mean</th>      <th>range_oc_std</th>      <th>volume_mean</th>      <th>volume_std</th>    </tr>  </thead>  <tbody>    <tr>      <th>3</th>      <td>2015-12-01</td>      <td>107.589996</td>      <td>108.209999</td>      <td>107.370003</td>      <td>108.180000</td>      <td>102.167740</td>      <td>2443600</td>      <td>12</td>      <td>0.839996</td>      <td>-0.590004</td>      <td>...</td>      <td>552400.0</td>      <td>1820300.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>4</th>      <td>2015-12-02</td>      <td>108.099998</td>      <td>108.269997</td>      <td>106.879997</td>      <td>107.050003</td>      <td>101.100533</td>      <td>2937200</td>      <td>12</td>      <td>1.390000</td>      <td>1.049995</td>      <td>...</td>      <td>3618100.0</td>      <td>552400.0</td>      <td>102.167740</td>      <td>NaN</td>      <td>0.839996</td>      <td>NaN</td>      <td>-0.590004</td>      <td>NaN</td>      <td>2.443600e+06</td>      <td>NaN</td>    </tr>    <tr>      <th>5</th>      <td>2015-12-03</td>      <td>107.290001</td>      <td>107.480003</td>      <td>105.059998</td>      <td>105.449997</td>      <td>99.589470</td>      <td>3345600</td>      <td>12</td>      <td>2.420005</td>      <td>1.840004</td>      <td>...</td>      <td>2443600.0</td>      <td>3618100.0</td>      <td>101.634136</td>      <td>0.754629</td>      <td>1.114998</td>      <td>0.388912</td>      <td>0.229995</td>      <td>1.159654</td>      <td>2.690400e+06</td>      <td>349027.907194</td>    </tr>    <tr>      <th>6</th>      <td>2015-12-04</td>      <td>105.809998</td>      <td>107.540001</td>      <td>105.620003</td>      <td>107.389999</td>      <td>101.421646</td>      <td>4520000</td>      <td>12</td>      <td>1.919998</td>      <td>-1.580001</td>      <td>...</td>      <td>2937200.0</td>      <td>2443600.0</td>      <td>100.952581</td>      <td>1.295487</td>      <td>1.550000</td>      <td>0.802064</td>      <td>0.766665</td>      <td>1.239533</td>      <td>2.908800e+06</td>      <td>451670.145128</td>    </tr>    <tr>      <th>7</th>      <td>2015-12-07</td>      <td>107.230003</td>      <td>107.269997</td>      <td>106.059998</td>      <td>106.550003</td>      <td>100.628342</td>      <td>3000500</td>      <td>12</td>      <td>1.209999</td>      <td>0.680000</td>      <td>...</td>      <td>3345600.0</td>      <td>2937200.0</td>      <td>100.703883</td>      <td>0.978374</td>      <td>1.910001</td>      <td>0.515075</td>      <td>0.436666</td>      <td>1.790597</td>      <td>3.600933e+06</td>      <td>821711.806738</td>    </tr>  </tbody></table><p>5 rows × 30 columns</p></div><pre class="line-numbers language-python" data-language="python"><code class="language-python">test.head()</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>high</th>      <th>low</th>      <th>close</th>      <th>adj_close</th>      <th>volume</th>      <th>month</th>      <th>range_hl</th>      <th>range_oc</th>      <th>...</th>      <th>volume_lag_2</th>      <th>volume_lag_3</th>      <th>adj_close_mean</th>      <th>adj_close_std</th>      <th>range_hl_mean</th>      <th>range_hl_std</th>      <th>range_oc_mean</th>      <th>range_oc_std</th>      <th>volume_mean</th>      <th>volume_std</th>    </tr>  </thead>  <tbody>    <tr>      <th>605</th>      <td>2018-04-24</td>      <td>138.100006</td>      <td>138.190002</td>      <td>134.860001</td>      <td>135.800003</td>      <td>134.584366</td>      <td>3053500</td>      <td>4</td>      <td>3.330001</td>      <td>2.300003</td>      <td>...</td>      <td>1669600.0</td>      <td>4003900.0</td>      <td>136.616023</td>      <td>0.644186</td>      <td>1.383331</td>      <td>0.241734</td>      <td>0.589997</td>      <td>0.407800</td>      <td>2.569067e+06</td>      <td>1.255867e+06</td>    </tr>    <tr>      <th>606</th>      <td>2018-04-25</td>      <td>135.770004</td>      <td>136.250000</td>      <td>134.610001</td>      <td>135.949997</td>      <td>134.733032</td>      <td>2275400</td>      <td>4</td>      <td>1.639999</td>      <td>-0.179993</td>      <td>...</td>      <td>2033700.0</td>      <td>1669600.0</td>      <td>135.691040</td>      <td>0.958728</td>      <td>2.106669</td>      <td>1.069313</td>      <td>1.230001</td>      <td>0.995943</td>      <td>2.252267e+06</td>      <td>7.173725e+05</td>    </tr>    <tr>      <th>607</th>      <td>2018-04-26</td>      <td>136.520004</td>      <td>137.679993</td>      <td>136.250000</td>      <td>137.240005</td>      <td>136.011490</td>      <td>1284600</td>      <td>4</td>      <td>1.429993</td>      <td>-0.720001</td>      <td>...</td>      <td>3053500.0</td>      <td>2033700.0</td>      <td>135.179001</td>      <td>0.904249</td>      <td>2.106669</td>      <td>1.069313</td>      <td>0.816671</td>      <td>1.309668</td>      <td>2.454200e+06</td>      <td>5.328931e+05</td>    </tr>    <tr>      <th>608</th>      <td>2018-04-27</td>      <td>137.539993</td>      <td>137.740005</td>      <td>136.800003</td>      <td>137.330002</td>      <td>136.100677</td>      <td>1133600</td>      <td>4</td>      <td>0.940002</td>      <td>0.209991</td>      <td>...</td>      <td>2275400.0</td>      <td>3053500.0</td>      <td>135.109629</td>      <td>0.784564</td>      <td>2.133331</td>      <td>1.041653</td>      <td>0.466670</td>      <td>1.610508</td>      <td>2.204500e+06</td>      <td>8.865788e+05</td>    </tr>    <tr>      <th>609</th>      <td>2018-04-30</td>      <td>137.690002</td>      <td>137.990005</td>      <td>136.250000</td>      <td>136.330002</td>      <td>135.109634</td>      <td>2277100</td>      <td>4</td>      <td>1.740005</td>      <td>1.360000</td>      <td>...</td>      <td>1284600.0</td>      <td>2275400.0</td>      <td>135.615066</td>      <td>0.765165</td>      <td>1.336665</td>      <td>0.359210</td>      <td>-0.230001</td>      <td>0.467008</td>      <td>1.564533e+06</td>      <td>6.202409e+05</td>    </tr>  </tbody></table><p>5 rows × 30 columns</p></div><h3 id="第五步：标签和特征的标准化-Step-5-Label-amp-Feature-Standardization"><a href="#第五步：标签和特征的标准化-Step-5-Label-amp-Feature-Standardization" class="headerlink" title="第五步：标签和特征的标准化 Step 5: Label &amp; Feature Standardization"></a>第五步：标签和特征的标准化 Step 5: Label &amp; Feature Standardization</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 此步的目的是为了对在训练集不能代表总体的情况下，使树模型正确运行的一种取巧cols_to_scale &#x3D; [    &quot;adj_close&quot;]for i in range(1, N + 1):    cols_to_scale.append(&quot;adj_close_lag_&quot; + str(i))    cols_to_scale.append(&quot;range_hl_lag_&quot; + str(i))    cols_to_scale.append(&quot;range_oc_lag_&quot; + str(i))    cols_to_scale.append(&quot;volume_lag_&quot; + str(i))scaler &#x3D; StandardScaler() # 启示三：标准化也不应带测试集，以避免信息泄漏train_scaled &#x3D; scaler.fit_transform(train[cols_to_scale])# Convert the numpy array back into pandas dataframetrain_scaled &#x3D; pd.DataFrame(train_scaled, columns&#x3D;cols_to_scale)train_scaled[[&#39;date&#39;, &#39;month&#39;]] &#x3D; train.reset_index()[[&#39;date&#39;, &#39;month&#39;]]test_scaled &#x3D; test[[&#39;date&#39;]]for col in tqdm(cols_list):    feat_list &#x3D; [col + &#39;_lag_&#39; + str(shift) for shift in range(1, N + 1)]    temp &#x3D; test.apply(lambda row: scale_row(row[feat_list], row[col + &#39;_mean&#39;], row[col + &#39;_std&#39;]), axis&#x3D;1)    test_scaled &#x3D; pd.concat([test_scaled, temp], axis&#x3D;1)</code></pre><pre><code>100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 26.77it/s]</code></pre><h3 id="第六步：建立样本-Step-6-Sample-Creation"><a href="#第六步：建立样本-Step-6-Sample-Creation" class="headerlink" title="第六步：建立样本 Step 6: Sample Creation"></a>第六步：建立样本 Step 6: Sample Creation</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">features &#x3D; []for i in range(1, N + 1):    features.append(&quot;adj_close_lag_&quot; + str(i))    features.append(&quot;range_hl_lag_&quot; + str(i))    features.append(&quot;range_oc_lag_&quot; + str(i))    features.append(&quot;volume_lag_&quot; + str(i))target &#x3D; &quot;adj_close&quot;X_train &#x3D; train[features]y_train &#x3D; train[target]X_sample &#x3D; test[features]y_sample &#x3D; test[target]X_train_scaled &#x3D; train_scaled[features]y_train_scaled &#x3D; train_scaled[target]X_sample_scaled &#x3D; test_scaled[features]</code></pre><h3 id="第七步：训练-Step-7-Training"><a href="#第七步：训练-Step-7-Training" class="headerlink" title="第七步：训练 Step 7: Training"></a>第七步：训练 Step 7: Training</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">from sklearn.model_selection import GridSearchCV</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">parameters&#x3D;&#123;&#39;n_estimators&#39;:[90],            &#39;max_depth&#39;:[7],            &#39;learning_rate&#39;: [0.3],            &#39;min_child_weight&#39;:range(5, 21, 1),            #&#39;subsample&#39;:[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],            #&#39;gamma&#39;:[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],            #&#39;colsample_bytree&#39;:[0.5, 0.6, 0.7, 0.8, 0.9, 1],            #&#39;colsample_bylevel&#39;:[0.5, 0.6, 0.7, 0.8, 0.9, 1]            &#125;#parameters&#x3D;&#123;&#39;max_depth&#39;:range(2,10,1)&#125;model&#x3D;XGBRegressor(seed&#x3D;model_seed,                     n_estimators&#x3D;100,                     max_depth&#x3D;3,                     eval_metric&#x3D;&#39;rmse&#39;,                     learning_rate&#x3D;0.1,                     min_child_weight&#x3D;1,                     subsample&#x3D;1,                     colsample_bytree&#x3D;1,                     colsample_bylevel&#x3D;1,                     gamma&#x3D;0)gs&#x3D;GridSearchCV(estimator&#x3D; model,param_grid&#x3D;parameters,cv&#x3D;5,refit&#x3D; True,scoring&#x3D;&#39;neg_mean_squared_error&#39;)gs.fit(X_train_scaled,y_train_scaled)print (&#39;最优参数: &#39; + str(gs.best_params_))est_scaled &#x3D; gs.predict(X_train_scaled)train[&#39;est&#39;] &#x3D; est_scaled * math.sqrt(scaler.var_[0]) + scaler.mean_[0]pre_y_scaled &#x3D; gs.predict(X_sample_scaled)test[&#39;pre_y_scaled&#39;] &#x3D; pre_y_scaledtest[&#39;pre_y&#39;]&#x3D;test[&#39;pre_y_scaled&#39;] * test[&#39;adj_close_std&#39;] + test[&#39;adj_close_mean&#39;]plt.figure()ax &#x3D; test.plot(x&#x3D;&#39;date&#39;, y&#x3D;&#39;adj_close&#39;, style&#x3D;&#39;b-&#39;, grid&#x3D;True)ax &#x3D; test.plot(x&#x3D;&#39;date&#39;, y&#x3D;&#39;pre_y&#39;, style&#x3D;&#39;r-&#39;, grid&#x3D;True, ax&#x3D;ax)plt.show()rmse&#x3D;math.sqrt(mean_squared_error(y_sample, test[&#39;pre_y&#39;]))print(&quot;RMSE on dev set &#x3D; %0.3f&quot; % rmse)mape &#x3D; get_mape(y_sample, test[&#39;pre_y&#39;])print(&quot;MAPE on dev set &#x3D; %0.3f%%&quot; % mape)imp &#x3D; list(zip(train[features], gs.best_estimator_.feature_importances_))imp.sort(key&#x3D;lambda tup: tup[1])for i in range(-1,-10,-1):    print(imp[i])</code></pre><pre><code>最优参数: &#123;&#39;learning_rate&#39;: 0.3, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 7, &#39;n_estimators&#39;: 90&#125;/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:27: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  train[&#39;est&#39;] = est_scaled * math.sqrt(scaler.var_[0]) + scaler.mean_[0]/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:30: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  test[&#39;pre_y_scaled&#39;] = pre_y_scaled/var/folders/5m/mg8r4rhs2hgg96ylwdvgvxrr0000gn/T/ipykernel_200/735584386.py:31: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  test[&#39;pre_y&#39;]=test[&#39;pre_y_scaled&#39;] * test[&#39;adj_close_std&#39;] + test[&#39;adj_close_mean&#39;]&lt;Figure size 640x480 with 0 Axes&gt;</code></pre><p><img src="/img/output_32_3.png" alt="png"></p><pre><code>RMSE on dev set = 1.149MAPE on dev set = 0.581%(&#39;adj_close_lag_1&#39;, 0.8624093)(&#39;adj_close_lag_2&#39;, 0.10811194)(&#39;adj_close_lag_3&#39;, 0.026851863)(&#39;range_oc_lag_1&#39;, 0.00043455773)(&#39;volume_lag_2&#39;, 0.0003508884)(&#39;volume_lag_3&#39;, 0.00034092006)(&#39;range_hl_lag_2&#39;, 0.00028984202)(&#39;range_oc_lag_2&#39;, 0.00027450564)(&#39;range_oc_lag_3&#39;, 0.0002714092)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;XGBoost&quot;&gt;&lt;a href=&quot;#XGBoost&quot; class=&quot;headerlink&quot; title=&quot;XGBoost&quot;&gt;&lt;/a&gt;XGBoost&lt;/h2&gt;&lt;p&gt;XGBoost是一个非常高效、应用广泛的GBDT机器学习库，详细信息可参考&lt;a href=&quot;http</summary>
      
    
    
    
    <category term="机器学习Machine Learning" scheme="http://quanzhang.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Machine-Learning/"/>
    
    
    <category term="Python" scheme="http://quanzhang.top/tags/Python/"/>
    
    <category term="机器学习" scheme="http://quanzhang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐系统" scheme="http://quanzhang.top/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="XGBoost" scheme="http://quanzhang.top/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>AutoXGB(XGboost + optuna)</title>
    <link href="http://quanzhang.top/post/AutoXGB.html"/>
    <id>http://quanzhang.top/post/AutoXGB.html</id>
    <published>2023-02-09T10:23:39.000Z</published>
    <updated>2024-11-06T02:24:29.761Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介-Introduction"><a href="#简介-Introduction" class="headerlink" title="简介 Introduction"></a>简介 Introduction</h2><p><a href="https://github.com/abhishekkrthakur/autoxgb.git">源代码地址（Source code url）</a></p><p>XGBoost + Optuna: no brainer</p><ul><li>auto train xgboost directly from CSV files</li><li>auto tune xgboost using optuna </li><li>auto serve best xgboost model using fastapi</li></ul><p>AutoXGB是XGBoost和Optuna的结合，允许</p><ul><li>在CSV文件上自动训练xgboost模型</li><li>对xgboost使用optuna自动参数调优</li><li>使用fastapi提供最优xgboost模型</li></ul><h2 id="安装方法-Installation"><a href="#安装方法-Installation" class="headerlink" title="安装方法 Installation"></a>安装方法 Installation</h2><p>使用pip进行安装<br>Install using pip</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install autoxgb</code></pre><h2 id="使用-Usage"><a href="#使用-Usage" class="headerlink" title="使用 Usage"></a>使用 Usage</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">from autoxgb import AutoXGB</code></pre><h2 id="参数-Parameters"><a href="#参数-Parameters" class="headerlink" title="参数 Parameters"></a>参数 Parameters</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">################################################################################## required parameters################################################################################ path to training datatrain_filename &#x3D; &quot;data_samples&#x2F;binary_classification.csv&quot;# The path on my Colab# train_filename &#x3D; &quot;&#x2F;content&#x2F;drive&#x2F;MyDrive&#x2F;Colab Notebooks&#x2F;data_samples&#x2F;binary_classification.csv&quot;# path to output folder to store artifactsoutput &#x3D; &quot;output&quot;################################################################################## optional parameters################################################################################ path to test data. if specified, the model will be evaluated on the test data# and test_predictions.csv will be saved to the output folder# if not specified, only OOF predictions will be saved# test_filename &#x3D; &quot;test.csv&quot;test_filename &#x3D; None# task: classification or regression# if not specified, the task will be inferred automatically# task &#x3D; &quot;classification&quot;# task &#x3D; &quot;regression&quot;task &#x3D; None# an id column# if not specified, the id column will be generated automatically with the name &#96;id&#96;# idx &#x3D; &quot;id&quot;idx &#x3D; None# target columns are list of strings# if not specified, the target column be assumed to be named &#96;target&#96;# and the problem will be treated as one of: binary classification, multiclass classification,# or single column regression# targets &#x3D; [&quot;target&quot;]# targets &#x3D; [&quot;target1&quot;, &quot;target2&quot;]targets &#x3D; [&quot;income&quot;]# features columns are list of strings# if not specified, all columns except &#96;id&#96;, &#96;targets&#96; &amp; &#96;kfold&#96; columns will be used# features &#x3D; [&quot;col1&quot;, &quot;col2&quot;]features &#x3D; None# categorical_features are list of strings# if not specified, categorical columns will be inferred automatically# categorical_features &#x3D; [&quot;col1&quot;, &quot;col2&quot;]categorical_features &#x3D; None# use_gpu is boolean# if not specified, GPU is not used# use_gpu &#x3D; True# use_gpu &#x3D; Falseuse_gpu &#x3D; True# number of folds to use for cross-validation# default is 5num_folds &#x3D; 5# random seed for reproducibility# default is 42seed &#x3D; 42# number of optuna trials to run# default is 1000# num_trials &#x3D; 1000num_trials &#x3D; 100# time_limit for optuna trials in seconds# if not specified, timeout is not set and all trials are run# time_limit &#x3D; Nonetime_limit &#x3D; 360# if fast is set to True, the hyperparameter tuning will use only one fold# however, the model will be trained on all folds in the end# to generate OOF predictions and test predictions# default is False# fast &#x3D; Falsefast &#x3D; False</code></pre><h2 id="用python-API训练"><a href="#用python-API训练" class="headerlink" title="用python API训练"></a>用python API训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># Now its time to train the model!axgb &#x3D; AutoXGB(    train_filename&#x3D;train_filename,    output&#x3D;output,    test_filename&#x3D;test_filename,    task&#x3D;task,    idx&#x3D;idx,    targets&#x3D;targets,    features&#x3D;features,    categorical_features&#x3D;categorical_features,    use_gpu&#x3D;use_gpu,    num_folds&#x3D;num_folds,    seed&#x3D;seed,    num_trials&#x3D;num_trials,    time_limit&#x3D;time_limit,    fast&#x3D;fast,)axgb.train()</code></pre><h2 id="用CLI训练"><a href="#用CLI训练" class="headerlink" title="用CLI训练"></a>用CLI训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># Train the model using the autoxgb train command. The parameters are same as above.autoxgb train \ --train_filename datasets&#x2F;30train.csv \ --output outputs&#x2F;30days \ --test_filename datasets&#x2F;30test.csv \ --use_gpu</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># You can also serve the trained model using the autoxgb serve command.autoxgb serve --model_path outputs&#x2F;mll --host 0.0.0.0 --debug</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&#96;autoxgb &lt;command&gt; --help&#96; </code></pre><h2 id="训练过程-Training-Process"><a href="#训练过程-Training-Process" class="headerlink" title="训练过程 Training Process"></a>训练过程 Training Process</h2><p><img src="/img/image-20230209190221610.png" alt="image-20230209190221610"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简介-Introduction&quot;&gt;&lt;a href=&quot;#简介-Introduction&quot; class=&quot;headerlink&quot; title=&quot;简介 Introduction&quot;&gt;&lt;/a&gt;简介 Introduction&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://g</summary>
      
    
    
    
    <category term="机器学习Machine Learning" scheme="http://quanzhang.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Machine-Learning/"/>
    
    
    <category term="Python" scheme="http://quanzhang.top/tags/Python/"/>
    
    <category term="机器学习" scheme="http://quanzhang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐系统" scheme="http://quanzhang.top/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="XGBoost" scheme="http://quanzhang.top/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>DLNotes</title>
    <link href="http://quanzhang.top/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html"/>
    <id>http://quanzhang.top/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</id>
    <published>2022-08-01T14:10:05.000Z</published>
    <updated>2024-11-06T02:24:29.757Z</updated>
    
    <content type="html"><![CDATA[<h1 id="iris-鸢尾花"><a href="#iris-鸢尾花" class="headerlink" title="iris-鸢尾花"></a>iris-鸢尾花</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入相关的库import seaborn as snsimport numpy as np</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 机器学习：sklearnfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionCV</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 深度学习：tf.kerasfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Densefrom tensorflow.keras import utils</code></pre><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 加载数据iris &#x3D; sns.load_dataset(&#39;iris&#39;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">iris.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(150, 5)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">iris.head()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">sns.pairplot(iris,hue&#x3D;&quot;species&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;seaborn.axisgrid.PairGrid at 0x11fcb1240&gt;</code></pre><p><img src="/DLNotes/2-1.png" alt="2-1"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获得数据集的特征值和目标值X &#x3D; iris.values[:,:4]y &#x3D; iris.values[:,4]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 数据集划分train_x,test_x,train_y,test_y &#x3D; train_test_split(X,y,test_size &#x3D; 0.5,random_state&#x3D;0)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_x.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(75, 4)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_x.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(75, 4)</code></pre><h2 id="sklearn-实现鸢尾花"><a href="#sklearn-实现鸢尾花" class="headerlink" title="sklearn 实现鸢尾花"></a>sklearn 实现鸢尾花</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 使用逻辑回归# 实例化估计器lr &#x3D; LogisticRegressionCV()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型训练lr.fit(train_x,train_y)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)&#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;sklearn&#x2F;linear_model&#x2F;_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status&#x3D;1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https:&#x2F;&#x2F;scikit-learn.org&#x2F;stable&#x2F;modules&#x2F;linear_model.html#logistic-regression  extra_warning_msg&#x3D;_LOGISTIC_SOLVER_CONVERGENCE_MSG)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">LogisticRegressionCV()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型评估lr.score(test_x,test_y)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.9333333333333333</code></pre><h2 id="tf-keras实现"><a href="#tf-keras实现" class="headerlink" title="tf,keras实现"></a>tf,keras实现</h2><h3 id="数据处理-1"><a href="#数据处理-1" class="headerlink" title="数据处理"></a>数据处理</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 目标值的热编码def one_hot_encode(arr):    # 获取目标值中的所有类别斌进行热编码    uniques,ids &#x3D; np.unique(arr,return_inverse&#x3D;True)    return utils.to_categorical(ids,len(uniques))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 对目标值进行编码train_y_ohe &#x3D; one_hot_encode(train_y)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_y_ohe &#x3D; one_hot_encode(test_y)</code></pre><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 通过squential进行构建model &#x3D; Sequential([    # 隐藏层    Dense(10,activation&#x3D;&quot;relu&quot;,input_shape&#x3D;(4,)),    # 隐藏层    Dense(10,activation&#x3D;&quot;relu&quot;),    # 输出层    Dense(3,activation&#x3D;&quot;softmax&quot;)])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;dense (Dense)                (None, 10)                50        _________________________________________________________________dense_1 (Dense)              (None, 10)                110       _________________________________________________________________dense_2 (Dense)              (None, 3)                 33        &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 193Trainable params: 193Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">utils.plot_model(model,show_shapes&#x3D;True)</code></pre><p><img src="/DLNotes/2-2.png" alt="2-1"></p><h3 id="模型预测与评估"><a href="#模型预测与评估" class="headerlink" title="模型预测与评估"></a>模型预测与评估</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型编译model.compile(optimizer&#x3D;&quot;adam&quot;,loss&#x3D;&quot;categorical_crossentropy&quot;,metrics&#x3D;[&quot;accuracy&quot;])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 类型准换train_x &#x3D; np.array(train_x,dtype&#x3D; np.float32)test_x &#x3D; np.array(test_x,dtype&#x3D;np.float32)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型训练model.fit(train_x,train_y_ohe,epochs&#x3D;10,batch_size&#x3D;1,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 582us&#x2F;step - loss: 1.6949 - accuracy: 0.2667Epoch 2&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 498us&#x2F;step - loss: 1.0696 - accuracy: 0.3867Epoch 3&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 523us&#x2F;step - loss: 0.7988 - accuracy: 0.7200Epoch 4&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 516us&#x2F;step - loss: 0.6704 - accuracy: 0.7467Epoch 5&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 480us&#x2F;step - loss: 0.5823 - accuracy: 0.7733Epoch 6&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 478us&#x2F;step - loss: 0.5058 - accuracy: 0.8000Epoch 7&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 468us&#x2F;step - loss: 0.4638 - accuracy: 0.8667Epoch 8&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 489us&#x2F;step - loss: 0.4091 - accuracy: 0.8533Epoch 9&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 472us&#x2F;step - loss: 0.3607 - accuracy: 0.9067Epoch 10&#x2F;1075&#x2F;75 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 478us&#x2F;step - loss: 0.3224 - accuracy: 0.9467</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x14329a400&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型评估loss,accuracy &#x3D; model.evaluate(test_x,test_y_ohe,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">3&#x2F;3 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 702us&#x2F;step - loss: 0.4016 - accuracy: 0.7467</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.4016245901584625</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">accuracy</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.746666669845581</code></pre><h1 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h1><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入所需要的库import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt</code></pre><h3 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x &#x3D; np.linspace(-10,10,1000)y &#x3D; tf.nn.sigmoid(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.plot(x,y)plt.grid()</code></pre><p><img src="/DLNotes/3-1.png" alt="3-1"></p><h3 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x &#x3D; np.linspace(-10,10,100)y &#x3D; tf.nn.tanh(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.plot(x,y)plt.grid()</code></pre><p><img src="/DLNotes/3-2.png" alt="3-2"></p><h3 id="relu"><a href="#relu" class="headerlink" title="relu"></a>relu</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x &#x3D; np.linspace(-10,10,100)y &#x3D; tf.nn.relu(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.plot(x,y)plt.grid()</code></pre><p><img src="/DLNotes/3-3.png" alt="3-3"></p><h3 id="leakyrelu"><a href="#leakyrelu" class="headerlink" title="leakyrelu"></a>leakyrelu</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x &#x3D; np.linspace(-10,10,100)y &#x3D; tf.nn.leaky_relu(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.plot(x,y)plt.grid()</code></pre><p> <img src="/DLNotes/3-4.png" alt="3-4"></p><h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x &#x3D; tf.constant([0.2,0.02,0.15,1.3,0.5,0.06,1.1,0.05,3.75])y &#x3D; tf.nn.softmax(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">y</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(9,), dtype&#x3D;float32, numpy&#x3D;array([0.02167152, 0.01810158, 0.02061459, 0.06510484, 0.02925349,       0.01884031, 0.05330333, 0.01865285, 0.75445753], dtype&#x3D;float32)&gt;</code></pre><h2 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tf</code></pre><h3 id="Xavizer初始化"><a href="#Xavizer初始化" class="headerlink" title="Xavizer初始化"></a>Xavizer初始化</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 正态分布的# 实例化initializer &#x3D; tf.keras.initializers.glorot_normal()values &#x3D; initializer((9,1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">values</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;array([[-0.24432576],       [-0.14220025],       [ 0.03321752],       [ 0.56275785],       [ 0.17512582],       [-0.18233004],       [-0.44970375],       [-0.2163621 ],       [ 0.37192827]], dtype&#x3D;float32)&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 标准化：均匀分布initializern &#x3D; tf.keras.initializers.glorot_uniform()values &#x3D; initializern((9,1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">values</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;array([[ 0.5761199 ],       [-0.42968088],       [ 0.5325227 ],       [-0.18232065],       [-0.59441626],       [ 0.7678894 ],       [-0.6589678 ],       [-0.75305176],       [-0.24894887]], dtype&#x3D;float32)&gt;</code></pre><h3 id="He初始化"><a href="#He初始化" class="headerlink" title="He初始化"></a>He初始化</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 正态分布# 实例化initializer &#x3D; tf.keras.initializers.he_normal()# 采样得到权重values &#x3D; initializer((9,1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">values</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;array([[ 0.64234483],       [ 0.8432255 ],       [ 0.56904906],       [ 0.2679259 ],       [ 0.06764679],       [-0.36957997],       [ 0.27991033],       [ 0.51744246],       [-0.15655899]], dtype&#x3D;float32)&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 标准化：均匀分布initializer &#x3D; tf.keras.initializers.he_uniform()values &#x3D; initializer((9,1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">values</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(9, 1), dtype&#x3D;float32, numpy&#x3D;array([[ 0.1383363 ],       [ 0.5817473 ],       [-0.24477297],       [-0.4477986 ],       [ 0.6623007 ],       [-0.60182106],       [-0.6880068 ],       [-0.5368612 ],       [-0.04563677]], dtype&#x3D;float32)&gt;</code></pre><h2 id="神经网络的搭建"><a href="#神经网络的搭建" class="headerlink" title="神经网络的搭建"></a>神经网络的搭建</h2><h3 id="sequential方式"><a href="#sequential方式" class="headerlink" title="sequential方式"></a>sequential方式</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入工具包import tensorflow as tfimport tensorflow.keras as kerasimport tensorflow.keras.layers as layers</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义model,构建模型model &#x3D; keras.Sequential([    # 第一个隐层    layers.Dense(3, activation&#x3D;&quot;relu&quot;, kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer1&quot;,input_shape&#x3D;(3,)),    # 第二个隐层    layers.Dense(2, activation&#x3D;&quot;relu&quot;,                 kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer2&quot;),    # 输出层    layers.Dense(2, activation&#x3D;&quot;sigmoid&quot;,                 kernel_initializer&#x3D;&quot;he_normal&quot;, name&#x3D;&quot;layer3&quot;)    ],    name&#x3D;&quot;sequential&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;layer1 (Dense)               (None, 3)                 12        _________________________________________________________________layer2 (Dense)               (None, 2)                 8         _________________________________________________________________layer3 (Dense)               (None, 2)                 6         &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 26Trainable params: 26Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">keras.utils.plot_model(model)</code></pre><p><img src="/DLNotes/3-5.png" alt="3-5"></p><h3 id="利用functional-API构建模型"><a href="#利用functional-API构建模型" class="headerlink" title="利用functional API构建模型"></a>利用functional API构建模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义模型的输入inputs &#x3D; keras.Input(shape&#x3D;(3,), name&#x3D;&#39;input&#39;)# 第一个隐层x &#x3D; layers.Dense(3, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer1&quot;)(inputs)# 第二个隐层x &#x3D; layers.Dense(2, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer2&quot;)(x)# 输出层outputs &#x3D; layers.Dense(2, activation&#x3D;&quot;sigmoid&quot;, name&#x3D;&quot;output&quot;)(x)# 创建模型model &#x3D; keras.Model(inputs&#x3D;inputs, outputs&#x3D;outputs,                    name&#x3D;&quot;Functional API Model&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;Functional API Model&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;input (InputLayer)           [(None, 3)]               0         _________________________________________________________________layer1 (Dense)               (None, 3)                 12        _________________________________________________________________layer2 (Dense)               (None, 2)                 8         _________________________________________________________________output (Dense)               (None, 2)                 6         &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 26Trainable params: 26Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">keras.utils.plot_model(model,show_shapes&#x3D;True)</code></pre><p><img src="/DLNotes/3-6.png" alt="3-6"></p><h3 id="通过model子类构建模型"><a href="#通过model子类构建模型" class="headerlink" title="通过model子类构建模型"></a>通过model子类构建模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义一个model的子类class MyModel(keras.Model):    # 定义网络的层结构    def __init__(self):        super(MyModel,self).__init__()        # 第一层隐层        self.layer1 &#x3D; layers.Dense(3,activation&#x3D;&quot;relu&quot;,name&#x3D;&quot;layer1&quot;)        # 第二个隐层        self.layer2 &#x3D; layers.Dense(2,activation&#x3D;&quot;relu&quot;,name&#x3D;&quot;layer2&quot;)        # 输出层        self.layer3 &#x3D; layers.Dense(2,activation&#x3D;&quot;sigmoid&quot;,name &#x3D; &quot;layer3&quot;)    # 定义网络的前向传播    def call(self,inputs):        x &#x3D; self.layer1(inputs)        x &#x3D; self.layer2(x)        outputs &#x3D; self.layer3(x)        return outputs</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化moxingmodel &#x3D; MyModel()# 设置输入x &#x3D; tf.ones((1,3))y &#x3D; model(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">y</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(1, 2), dtype&#x3D;float32, numpy&#x3D;array([[0.5810978, 0.5847459]], dtype&#x3D;float32)&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;my_model&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;layer1 (Dense)               multiple                  12        _________________________________________________________________layer2 (Dense)               multiple                  8         _________________________________________________________________layer3 (Dense)               multiple                  6         &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 26Trainable params: 26Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">keras.utils.plot_model(model)</code></pre><p><img src="/DLNotes/3-7.png" alt="3-7"></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tf</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置真实值和预测值y_true &#x3D; [[0,1,0],[0,0,1]]y_pre &#x3D; [[0.05,0.9,0.05],[0.05,0.05,0.9]]# 实例化交叉熵损失cce &#x3D; tf.keras.losses.CategoricalCrossentropy()# 计算损失结果cce(y_true,y_pre)</code></pre><h3 id="二分类的交叉熵损失函数"><a href="#二分类的交叉熵损失函数" class="headerlink" title="二分类的交叉熵损失函数"></a>二分类的交叉熵损失函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置真实值和预测值y_true &#x3D; [[0],[1]]y_pre &#x3D; [[0.1],[0.9]]# 实例化bce &#x3D; tf.keras.losses.BinaryCrossentropy()# 计算损失函数bce(y_true,y_pre).numpy()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.10536041</code></pre><h3 id="MAE-L1-LOSS"><a href="#MAE-L1-LOSS" class="headerlink" title="MAE(L1 LOSS)"></a>MAE(L1 LOSS)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置真实值和预测值y_true &#x3D; [[0.],[1.]]y_pre &#x3D; [[0.],[1.]]# 实例化MAE损失mae &#x3D; tf.keras.losses.MeanAbsoluteError()mae(y_true,y_pre)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.0&gt;</code></pre><h3 id="MSE-L2-loss"><a href="#MSE-L2-loss" class="headerlink" title="MSE(L2 loss)"></a>MSE(L2 loss)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置真实值和预测值y_true &#x3D; [[0.],[1.]]y_pre &#x3D; [[0.],[1.]]# 实例化MSEmse &#x3D; tf.keras.losses.MeanSquaredError()mse(y_true,y_pre)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.0&gt;</code></pre><h3 id="smoothL1"><a href="#smoothL1" class="headerlink" title="smoothL1"></a>smoothL1</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置真实值和预测值y_true &#x3D; [[0.2],[1.]]y_pre &#x3D; [[0.2],[0.6]]# 实例化损失smooth &#x3D; tf.keras.losses.Huber()smooth(y_true,y_pre)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.039999995&gt;</code></pre><h1 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h1><h2 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入工具包import tensorflow as tf</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化SGDopt &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.1)# 定义要更新的参数var &#x3D; tf.Variable(1.0)# 定义损失函数loss &#x3D; lambda:(var**2)&#x2F;2.0# 计算损失梯度，并进行参数更新opt.minimize(loss,[var]).numpy()# 参数更新结果var.numpy()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.9</code></pre><h2 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化opt &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.1,momentum&#x3D;0.9)# 定义要更新的参数var &#x3D; tf.Variable(1.0)val0&#x3D; var.value()# 定义损失函数loss &#x3D; lambda:(var**2)&#x2F;2.0# 第一次更新opt.minimize(loss,[var]).numpy()val1 &#x3D; var.value()# 第二次更新opt.minimize(loss,[var]).numpy()val2 &#x3D; var.value()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">val0</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;1.0&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">val1</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.9&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">val2</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.71999997&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">val0-val1</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.100000024&gt;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">val1-val2</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Tensor: shape&#x3D;(), dtype&#x3D;float32, numpy&#x3D;0.18&gt;</code></pre><h2 id="adagrad"><a href="#adagrad" class="headerlink" title="adagrad"></a>adagrad</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化opt &#x3D; tf.keras.optimizers.Adagrad(learning_rate&#x3D;0.1,initial_accumulator_value&#x3D;0.1,epsilon&#x3D;1e-06)# 定义要更新的参数var &#x3D; tf.Variable(1.0)# 定义损失函数def loss():    return (var**2)&#x2F;2.0# 进行更新opt.minimize(loss,[var]).numpy()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">1</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">var</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tf.Variable &#39;Variable:0&#39; shape&#x3D;() dtype&#x3D;float32, numpy&#x3D;0.90465385&gt;</code></pre><h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化opt &#x3D; tf.keras.optimizers.RMSprop(learning_rate&#x3D;0.1,rho&#x3D;0.1)# 定义要更新的参数var &#x3D; tf.Variable(1.0)# 定义损失函数def loss():    return (var**2)&#x2F;2.0# 进行更新opt.minimize(loss,[var]).numpy()var.numpy()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.89459074</code></pre><h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化opt &#x3D; tf.keras.optimizers.Adam(learning_rate&#x3D;0.1)# 定义要调整的参数var &#x3D; tf.Variable(1.0)# 定义损失函数def loss():    return (var**2)&#x2F;2.0# 进行更新opt.minimize(loss,[var])# 显示结果var.numpy()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">0.90000033</code></pre><h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入工具包import tensorflow as tfimport numpy as np</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义dropout层layer &#x3D; tf.keras.layers.Dropout(0,input_shape&#x3D;(2,))# 定义输入数据data &#x3D; np.arange(1,11).reshape(5,2).astype(np.float32)print(data)# 对输入数据进行随机失活outputs &#x3D; layer(data,training&#x3D;True)print(outputs)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[[ 1.  2.] [ 3.  4.] [ 5.  6.] [ 7.  8.] [ 9. 10.]]tf.Tensor([[ 1.  2.] [ 3.  4.] [ 5.  6.] [ 7.  8.] [ 9. 10.]], shape&#x3D;(5, 2), dtype&#x3D;float32)</code></pre><h2 id="提前停止"><a href="#提前停止" class="headerlink" title="提前停止"></a>提前停止</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义回调函数callback &#x3D; tf.keras.callbacks.EarlyStopping(monitor&#x3D;&quot;loss&quot;,patience&#x3D;3)# 定义一层的网络model &#x3D; tf.keras.models.Sequential([tf.keras.layers.Dense(10)])# 模型编译model.compile(tf.keras.optimizers.SGD(),loss&#x3D;&#39;mse&#39;)# 模型训练history &#x3D; model.fit(np.arange(100).reshape(5,20),np.array([0,1,0,1,0]),epochs&#x3D;10,batch_size&#x3D;1,verbose&#x3D;1)len(history.history[&#39;loss&#39;])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 645us&#x2F;step - loss: 56302425635553280.0000Epoch 2&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 3809886121814745262099957060468736.0000Epoch 3&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 868us&#x2F;step - loss: infEpoch 4&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 964us&#x2F;step - loss: infEpoch 5&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 761us&#x2F;step - loss: nanEpoch 6&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 709us&#x2F;step - loss: nanEpoch 7&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 805us&#x2F;step - loss: nanEpoch 8&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 746us&#x2F;step - loss: nanEpoch 9&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 801us&#x2F;step - loss: nanEpoch 10&#x2F;105&#x2F;5 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 555us&#x2F;step - loss: nan</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">10</code></pre><h1 id="minist数据集"><a href="#minist数据集" class="headerlink" title="minist数据集"></a>minist数据集</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 导入所需的工具包import numpy as npimport matplotlib.pyplot as plt# tf中使用工具包import tensorflow as tf# 构建模型from tensorflow.keras.models import Sequential# 相关的网络层，所有神经元在Dense层里，Dropout随机失活（最常用的正则化方法），激活函数，BN层from tensorflow.keras.layers import Dense,Dropout,Activation,BatchNormalization# 导入辅助工具包from tensorflow.keras import utils# 正则化from tensorflow.keras import regularizers# 数据集from tensorflow.keras.datasets import mnist</code></pre><h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 加载数据集(x_train,y_train),(x_test,y_test) &#x3D; mnist.load_data()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_train.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(60000, 28, 28)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_test.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(10000, 28, 28)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">y_train</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">array([5, 0, 4, ..., 5, 6, 8], dtype&#x3D;uint8)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 显示数据#创建画布plt.figure()#输出plt.imshow(x_train[10000],cmap&#x3D;&quot;gray&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;matplotlib.image.AxesImage at 0x182df7f6be0&gt;</code></pre><p><img src="/DLNotes/6-1.png" alt="6-1"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">y_train[10000]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">3</code></pre><h2 id="数据处理-2"><a href="#数据处理-2" class="headerlink" title="数据处理"></a>数据处理</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 数据维度的调整x_train &#x3D; x_train.reshape(60000,784)x_test &#x3D; x_test.reshape(10000,784)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 数据类型调整x_train &#x3D; x_train.astype(&#39;float32&#39;)x_test &#x3D; x_test.astype(&quot;float32&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 归一化x_train &#x3D; x_train&#x2F;255x_test &#x3D; x_test&#x2F;255</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 将目标值转换成热编码的形式y_train &#x3D; utils.to_categorical(y_train,10)y_test &#x3D; utils.to_categorical(y_test,10)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">y_train.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(60000, 10)</code></pre><h2 id="模型构建-1"><a href="#模型构建-1" class="headerlink" title="模型构建"></a>模型构建</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 使用序列模型进行构建model &#x3D; Sequential()# 全连接层：2个隐层，一个输出层# 第一个隐层:512个神经元，先激活后BN，随机失活model.add(Dense(512,activation &#x3D; &quot;relu&quot;,input_shape&#x3D;(784,)))model.add(BatchNormalization())model.add(Dropout(0.2))# 第二个隐层：512个神经元，先BN后激活，随机失活model.add(Dense(512,kernel_regularizer&#x3D;regularizers.l2(0.01)))model.add(BatchNormalization())model.add(Activation(&quot;relu&quot;))model.add(Dropout(0.2))# 输出层model.add(Dense(10,activation&#x3D;&quot;softmax&quot;))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential_1&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;dense_2 (Dense)              (None, 512)               401920    _________________________________________________________________batch_normalization_2 (Batch (None, 512)               2048      _________________________________________________________________dropout_1 (Dropout)          (None, 512)               0         _________________________________________________________________dense_3 (Dense)              (None, 512)               262656    _________________________________________________________________batch_normalization_3 (Batch (None, 512)               2048      _________________________________________________________________activation (Activation)      (None, 512)               0         _________________________________________________________________dropout_2 (Dropout)          (None, 512)               0         _________________________________________________________________dense_4 (Dense)              (None, 10)                5130      &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 673,802Trainable params: 671,754Non-trainable params: 2,048_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">utils.plot_model(model)</code></pre><p><img src="/DLNotes/6-2.png" alt="6-2"></p><h2 id="模型编译"><a href="#模型编译" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 损失函数，优化器，评价指标model.compile(loss&#x3D; tf.keras.losses.categorical_crossentropy,optimizer &#x3D; tf.keras.optimizers.Adam(),              metrics&#x3D;tf.keras.metrics.Accuracy())</code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 使用fit,指定训练集，epochs,batch_size,val,verbosehistory &#x3D; model.fit(x_train,y_train,epochs&#x3D;4,batch_size&#x3D;128,validation_data&#x3D;(x_test,y_test),verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1235 - accuracy: 0.0088 - val_loss: 0.1619 - val_accuracy: 0.0124Epoch 2&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1225 - accuracy: 0.0084 - val_loss: 0.1584 - val_accuracy: 0.0093Epoch 3&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1179 - accuracy: 0.0084 - val_loss: 0.1595 - val_accuracy: 0.0120Epoch 4&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1113 - accuracy: 0.0091 - val_loss: 0.1399 - val_accuracy: 0.0057</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">history.history</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&#123;&#39;loss&#39;: [0.12347722053527832,  0.1224995031952858,  0.11792848259210587,  0.11130338907241821], &#39;accuracy&#39;: [0.008786666207015514,  0.00840499997138977,  0.008430000394582748,  0.009065000340342522], &#39;val_loss&#39;: [0.16186854243278503,  0.15844473242759705,  0.15949705243110657,  0.13993136584758759], &#39;val_accuracy&#39;: [0.012380000203847885,  0.009259999729692936,  0.011950000189244747,  0.0056500001810491085]&#125;</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 损失函数plt.figure()plt.plot(history.history[&#39;loss&#39;],label&#x3D;&quot;train&quot;)plt.plot(history.history[&quot;val_loss&quot;],label&#x3D;&quot;val&quot;)plt.legend()plt.grid()</code></pre><p><img src="/DLNotes/6-3.png" alt="6-3"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 准确率plt.figure()plt.plot(history.history[&#39;accuracy&#39;],label&#x3D;&quot;train&quot;)plt.plot(history.history[&quot;val_accuracy&quot;],label&#x3D;&quot;val&quot;)plt.legend()plt.grid()</code></pre><p><img src="/DLNotes/6-4.png" alt="6-4"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 回调函数tensorboard &#x3D; tf.keras.callbacks.TensorBoard(log_dir &#x3D; &quot;.&#x2F;graph&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 训练history &#x3D; model.fit(x_train,y_train,epochs&#x3D;4,validation_data&#x3D;(x_test,y_test),batch_size&#x3D;128,                    verbose&#x3D;1,callbacks&#x3D;[tensorboard])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;4  1&#x2F;469 [..............................] - ETA: 0s - loss: 0.1043 - accuracy: 0.0109WARNING:tensorflow:From &#x2F;opt&#x2F;anaconda3&#x2F;envs&#x2F;dlcv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;tensorflow&#x2F;python&#x2F;ops&#x2F;summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.Instructions for updating:use &#96;tf.profiler.experimental.stop&#96; instead.WARNING:tensorflow:Callbacks method &#96;on_train_batch_end&#96; is slow compared to the batch time (batch time: 0.0062s vs &#96;on_train_batch_end&#96; time: 0.0188s). Check your callbacks.469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1092 - accuracy: 0.0093 - val_loss: 0.1541 - val_accuracy: 0.0091Epoch 2&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1070 - accuracy: 0.0096 - val_loss: 0.1400 - val_accuracy: 0.0076Epoch 3&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 4ms&#x2F;step - loss: 0.1059 - accuracy: 0.0097 - val_loss: 0.1472 - val_accuracy: 0.0090Epoch 4&#x2F;4469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 2s 5ms&#x2F;step - loss: 0.1018 - accuracy: 0.0111 - val_loss: 0.1462 - val_accuracy: 0.0136</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.evaluate(x_test,y_test,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 0.1462 - accuracy: 0.0136</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[0.1461515724658966, 0.013629999943077564]</code></pre><h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 保存model.save(&quot;model.h5&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 记载loadmodel &#x3D; tf.keras.models.load_model(&quot;model.h5&quot;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">loadmodel.evaluate(x_test,y_test,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 0s 1ms&#x2F;step - loss: 0.1462 - accuracy: 0.0136</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[0.1461515724658966, 0.013629999943077564]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"></code></pre><h1 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tffrom tensorflow.keras.datasets import mnist</code></pre><h2 id="数据集加载"><a href="#数据集加载" class="headerlink" title="数据集加载"></a>数据集加载</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">(train_images,train_labels),(test_images,test_labels) &#x3D; mnist.load_data()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(60000, 28, 28)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(10000, 28, 28)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_labels.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(60000,)</code></pre><h2 id="数据处理-3"><a href="#数据处理-3" class="headerlink" title="数据处理"></a>数据处理</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 维度调整train_images &#x3D; tf.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">TensorShape([60000, 28, 28, 1])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_images &#x3D; tf.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">TensorShape([10000, 28, 28, 1])</code></pre><h2 id="模型构建-2"><a href="#模型构建-2" class="headerlink" title="模型构建"></a>模型构建</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">net &#x3D; tf.keras.models.Sequential([    # 卷积层：6个5*5的卷积 sigmoid    tf.keras.layers.Conv2D(filters&#x3D;6, kernel_size&#x3D;5,                           activation&#x3D;&quot;sigmoid&quot;, input_shape&#x3D;(28, 28, 1)),    # max pooling    tf.keras.layers.MaxPool2D(pool_size&#x3D;2, strides&#x3D;2),    # 卷积层：16 5*5 sigmoid    tf.keras.layers.Conv2D(filters&#x3D;16, kernel_size&#x3D;5, activation&#x3D;&quot;sigmoid&quot;),    # max pooling    tf.keras.layers.MaxPool2D(pool_size&#x3D;2, strides&#x3D;2),    # 维度调整    tf.keras.layers.Flatten(),    # 全连接层，sigmoid    tf.keras.layers.Dense(120, activation&#x3D;&quot;sigmoid&quot;),    # 全连接层，sigmoid    tf.keras.layers.Dense(84, activation&#x3D;&quot;sigmoid&quot;),    # 输出层 softmax    tf.keras.layers.Dense(10, activation&#x3D;&quot;softmax&quot;)])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">net.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;conv2d (Conv2D)              (None, 24, 24, 6)         156       _________________________________________________________________max_pooling2d (MaxPooling2D) (None, 12, 12, 6)         0         _________________________________________________________________conv2d_1 (Conv2D)            (None, 8, 8, 16)          2416      _________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 4, 4, 16)          0         _________________________________________________________________flatten (Flatten)            (None, 256)               0         _________________________________________________________________dense (Dense)                (None, 120)               30840     _________________________________________________________________dense_1 (Dense)              (None, 84)                10164     _________________________________________________________________dense_2 (Dense)              (None, 10)                850       &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 44,426Trainable params: 44,426Non-trainable params: 0_________________________________________________________________</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">tf.keras.utils.plot_model(net)</code></pre><p><img src="/DLNotes/7-1.png" alt="7-1"></p><h2 id="模型编译-1"><a href="#模型编译-1" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 设置优化器，损失函数 评价指标net.compile(optimizer&#x3D;tf.keras.optimizers.SGD(learning_rate&#x3D;0.9),           loss &#x3D; tf.keras.losses.sparse_categorical_crossentropy,           metrics&#x3D;[&quot;accuracy&quot;])</code></pre><h2 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">net.fit(train_images,train_labels,epochs&#x3D;5,batch_size&#x3D;128,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;5469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 17ms&#x2F;step - loss: 0.0752 - accuracy: 0.9762Epoch 2&#x2F;5469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 18ms&#x2F;step - loss: 0.0664 - accuracy: 0.9793Epoch 3&#x2F;5469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 18ms&#x2F;step - loss: 0.0651 - accuracy: 0.9790Epoch 4&#x2F;5469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 9s 18ms&#x2F;step - loss: 0.0580 - accuracy: 0.9817Epoch 5&#x2F;5469&#x2F;469 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 9s 18ms&#x2F;step - loss: 0.0534 - accuracy: 0.9834</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x111d30940&gt;</code></pre><h2 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">net.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">313&#x2F;313 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 2ms&#x2F;step - loss: 0.0579 - accuracy: 0.9806</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[0.05785652995109558, 0.9805999994277954]</code></pre><h1 id="cifar数据集"><a href="#cifar数据集" class="headerlink" title="cifar数据集"></a>cifar数据集</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"># CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k个图像，图像大小32×32×3。# CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32×32×3。# 随后了解下 ImageNet，目前主流的数据集from tensorflow.keras.datasets import cifar10</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(train_images,train_labels),(test_images,test_labels) &#x3D; cifar10.load_data()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(10000, 32, 32, 3)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_images.shape</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(50000, 32, 32, 3)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">import matplotlib.pyplot as plt</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.figure(figsize&#x3D;(3,3))plt.imshow(train_images[4])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;matplotlib.image.AxesImage at 0x14f8c5ef0&gt;</code></pre><p><img src="/DLNotes/8-1.png" alt="8-1"></p><h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tf</code></pre><p><img src="/DLNotes/9-3.png" alt="9-3"></p><h2 id="模型构建-3"><a href="#模型构建-3" class="headerlink" title="模型构建"></a>模型构建</h2><p><img src="/DLNotes/9-2.png" alt="9-2"></p><p>该网络的特点是：</p><ul><li>AlexNet包含8层变换，有5层卷积和2层全连接隐藏层，以及1个全连接输出层</li><li>AlexNet第一层中的卷积核形状是11×1111×11。第二层中的卷积核形状减小到5×55×5，之后全采用3×33×3。所有的池化层窗口大小为3×33×3、步幅为2的最大池化。</li><li>AlexNet将sigmoid激活函数改成了ReLU激活函数，使计算更简单，网络更容易训练</li><li>AlexNet通过dropOut来控制全连接层的模型复杂度。</li><li>AlexNet引入了大量的图像增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">net &#x3D; tf.keras.models.Sequential([    # 卷积层：96 11*11 4 relu    tf.keras.layers.Conv2D(filters&#x3D;96, kernel_size&#x3D;11,                           strides&#x3D;4, activation&#x3D;&quot;relu&quot;),    # 池化：3*3 2    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),    # 卷积：256 5*5 1 RELU same    tf.keras.layers.Conv2D(filters&#x3D;256, kernel_size&#x3D;5,                           padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),    # 池化： 3*3 2    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),    # 卷积：384 3*3 1 RELU same    tf.keras.layers.Conv2D(filters&#x3D;384, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),    # 卷积：384 3*3 1 RELU same    tf.keras.layers.Conv2D(filters&#x3D;384, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),    # 卷积：256 3*3 1 RELU same    tf.keras.layers.Conv2D(filters&#x3D;256, kernel_size&#x3D;3, padding&#x3D;&quot;same&quot;, activation&#x3D;&quot;relu&quot;),    # 池化：3*3 2    tf.keras.layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2),    # 展开    tf.keras.layers.Flatten(),    # 全连接层：4096 relu    tf.keras.layers.Dense(4096, activation&#x3D;&quot;relu&quot;),    # 随机失活    tf.keras.layers.Dropout(0.5),    # 全连接层：4096 relu    tf.keras.layers.Dense(4096, activation&#x3D;&quot;relu&quot;),    # 随机失活    tf.keras.layers.Dropout(0.5),    # 输出层：    tf.keras.layers.Dense(10, activation&#x3D;&quot;softmax&quot;)])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">X &#x3D; tf.random.uniform((1,227,227,1))y &#x3D; net(X)net.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;conv2d (Conv2D)              (1, 55, 55, 96)           11712     _________________________________________________________________max_pooling2d (MaxPooling2D) (1, 27, 27, 96)           0         _________________________________________________________________conv2d_1 (Conv2D)            (1, 27, 27, 256)          614656    _________________________________________________________________max_pooling2d_1 (MaxPooling2 (1, 13, 13, 256)          0         _________________________________________________________________conv2d_2 (Conv2D)            (1, 13, 13, 384)          885120    _________________________________________________________________conv2d_3 (Conv2D)            (1, 13, 13, 384)          1327488   _________________________________________________________________conv2d_4 (Conv2D)            (1, 13, 13, 256)          884992    _________________________________________________________________max_pooling2d_2 (MaxPooling2 (1, 6, 6, 256)            0         _________________________________________________________________flatten (Flatten)            (1, 9216)                 0         _________________________________________________________________dense (Dense)                (1, 4096)                 37752832  _________________________________________________________________dropout (Dropout)            (1, 4096)                 0         _________________________________________________________________dense_1 (Dense)              (1, 4096)                 16781312  _________________________________________________________________dropout_1 (Dropout)          (1, 4096)                 0         _________________________________________________________________dense_2 (Dense)              (1, 10)                   40970     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 58,299,082Trainable params: 58,299,082Non-trainable params: 0_________________________________________________________________</code></pre><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">from tensorflow.keras.datasets import mnistimport numpy as np</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">(train_images,train_label),(test_images,test_labels)&#x3D;mnist.load_data()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 维度调整train_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))test_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 对训练数据进行抽样def get_train(size):    # 随机生成index    index &#x3D; np.random.randint(0,train_images.shape[0],size)    # 选择图像并进行resize    resized_image &#x3D; tf.image.resize_with_pad(train_images[index],227,227)    return resized_image.numpy(),train_label[index]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 对测试数据进行抽样def get_test(size):    # 随机生成index    index &#x3D; np.random.randint(0,test_images.shape[0],size)    # 选择图像并进行resize    resized_image &#x3D; tf.image.resize_with_pad(test_images[index],227,227)    return resized_image.numpy(),test_labels[index]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 抽样结果train_images,train_label &#x3D; get_train(256)test_images,test_labels &#x3D; get_test(128)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">import matplotlib.pyplot as plt</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.imshow(train_images[4].astype(np.int8).squeeze(),cmap&#x3D;&#39;gray&#39;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;matplotlib.image.AxesImage at 0x146de3f60&gt;</code></pre><p><img src="/DLNotes/9-1.png" alt="9-1"></p><h2 id="模型编译-2"><a href="#模型编译-2" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 优化器,损失函数,评价指标net.compile(optimizer&#x3D;tf.keras.optimizers.SGD(learning_rate&#x3D;0.01),loss&#x3D;tf.keras.losses.sparse_categorical_crossentropy           ,metrics&#x3D;[&#39;accuracy&#39;])</code></pre><h2 id="模型训练-2"><a href="#模型训练-2" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">net.fit(train_images,train_label,batch_size&#x3D;128,epochs&#x3D;3,validation_split&#x3D;0.1,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: 197.2379 - accuracy: 0.1000 - val_loss: 15641.0518 - val_accuracy: 0.1538Epoch 2&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: 630482274353152.0000 - accuracy: 0.1478 - val_loss: nan - val_accuracy: 0.0385Epoch 3&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 3s 2s&#x2F;step - loss: nan - accuracy: 0.1435 - val_loss: nan - val_accuracy: 0.0385</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x1498ac278&gt;</code></pre><h2 id="模型评估-2"><a href="#模型评估-2" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">net.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 168ms&#x2F;step - loss: nan - accuracy: 0.0938</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[nan, 0.09375]</code></pre><h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tf </code></pre><h2 id="模型构建-4"><a href="#模型构建-4" class="headerlink" title="模型构建"></a>模型构建</h2><h3 id="VGG块的构建"><a href="#VGG块的构建" class="headerlink" title="VGG块的构建"></a>VGG块的构建</h3><p>VGG可以看成是加深版的AlexNet，整个网络由卷积层和全连接层叠加而成，和AlexNet不同的是，VGG中使用的都是小尺寸的卷积核(3×3)，其网络架构如下图所示：</p><p><img src="/DLNotes/10-1.png" alt="10-1"></p><p>VGGNet使用的全部都是3x3的小卷积核和2x2的池化核，通过不断加深网络来提升性能。VGG可以通过重复使用简单的基础块来构建深度模型。</p><p><img src="/DLNotes/10-2.png" alt="10-2"></p><p>在tf.keras中实现VGG模型，首先来实现VGG块，它的组成规律是：连续使用多个相同的填充为1、卷积核大小为3×33×3的卷积层后接上一个步幅为2、窗口形状为2×22×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用<code>vgg_block</code>函数来实现这个基础的VGG块，它可以指定卷积层的数量<code>num_convs</code>和每层的卷积核个数num_filters：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">def vgg_block(num_conv,num_filters):    # 序列模型    blk &#x3D; tf.keras.models.Sequential()    # 遍历卷积层    for _ in range(num_conv):        # 设置卷积层        blk.add(tf.keras.layers.Conv2D(num_filters,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;,activation&#x3D;&quot;relu&quot;))    # 池化层    blk.add(tf.keras.layers.MaxPool2D(pool_size&#x3D;2,strides&#x3D;2))    return blk</code></pre><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">def vgg(conv_arch):    # 序列模型    net &#x3D; tf.keras.models.Sequential()    # 生成卷积部分    for (num_convs,num_filters) in conv_arch:        net.add(vgg_block(num_convs,num_filters))    # 全连接层    net.add(tf.keras.models.Sequential([        # 展评        tf.keras.layers.Flatten(),        # 全连接层        tf.keras.layers.Dense(4096,activation&#x3D;&quot;relu&quot;),        # 随机失活        tf.keras.layers.Dropout(0.5),        # 全连接层        tf.keras.layers.Dense(4096,activation&#x3D;&quot;relu&quot;),        # 随机失活        tf.keras.layers.Dropout(0.5),        # 输出层        tf.keras.layers.Dense(10,activation&#x3D;&quot;softmax&quot;)    ]))    return net</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 卷积块的参数conv_arch &#x3D; ((2,64),(2,128),(3,256),(3,512),(3,512))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">net &#x3D; vgg(conv_arch)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">X &#x3D; tf.random.uniform((1,224,224,1))y &#x3D; net(X)net.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;sequential_1 (Sequential)    (1, 112, 112, 64)         37568     _________________________________________________________________sequential_2 (Sequential)    (1, 56, 56, 128)          221440    _________________________________________________________________sequential_3 (Sequential)    (1, 28, 28, 256)          1475328   _________________________________________________________________sequential_4 (Sequential)    (1, 14, 14, 512)          5899776   _________________________________________________________________sequential_5 (Sequential)    (1, 7, 7, 512)            7079424   _________________________________________________________________sequential_6 (Sequential)    (1, 10)                   119586826 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 134,300,362Trainable params: 134,300,362Non-trainable params: 0_________________________________________________________________</code></pre><h2 id="数据读取-1"><a href="#数据读取-1" class="headerlink" title="数据读取"></a>数据读取</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom tensorflow.keras.datasets import mnist# 获取手写数字数据集(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()# 训练集数据维度的调整：N H W Ctrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))# 测试集数据维度的调整：N H W Ctest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义两个方法随机抽取部分样本演示# 获取训练集数据def get_train(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)    # 将这些数据resize成22*227大小    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)    # 返回抽取的    return resized_images.numpy(), train_labels[index]# 获取测试集数据 def get_test(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)    # 将这些数据resize成224*224大小    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)    # 返回抽样的测试样本    return resized_images.numpy(), test_labels[index]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获取训练样本和测试样本train_images,train_labels &#x3D; get_train(256)test_images,test_labels &#x3D; get_test(128)</code></pre><h2 id="模型编译-3"><a href="#模型编译-3" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定优化器，损失函数和评价指标optimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)net.compile(optimizer&#x3D;optimizer,              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,              metrics&#x3D;[&#39;accuracy&#39;])</code></pre><h2 id="模型训练-3"><a href="#模型训练-3" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型训练：指定训练数据，batchsize,epoch,验证集net.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 65s 32s&#x2F;step - loss: 2.3255 - accuracy: 0.0783 - val_loss: 2.1876 - val_accuracy: 0.3462Epoch 2&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 52s 26s&#x2F;step - loss: 2.2593 - accuracy: 0.1435 - val_loss: 2.1084 - val_accuracy: 0.4231Epoch 3&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 51s 26s&#x2F;step - loss: 2.1924 - accuracy: 0.2348 - val_loss: 2.0070 - val_accuracy: 0.2308</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x12d95bd68&gt;</code></pre><h2 id="模型评估-3"><a href="#模型评估-3" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定测试数据net.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 11s 3s&#x2F;step - loss: 2.1049 - accuracy: 0.1484</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[2.1049132347106934, 0.1484375]</code></pre><h1 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tf</code></pre><p>GoogLeNet的名字不是GoogleNet，而是GoogLeNet，这是为了致敬LeNet。GoogLeNet和AlexNet&#x2F;VGGNet这类依靠加深网络结构的深度的思想不完全一样。GoogLeNet在加深度的同时做了结构上的创新，引入了一个叫做Inception的结构来代替之前的卷积加激活的经典组件。GoogLeNet在ImageNet分类比赛上的Top-5错误率降低到了6.7%。</p><h2 id="Inception模块"><a href="#Inception模块" class="headerlink" title="Inception模块"></a>Inception模块</h2><p>GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》（Inception）。Inception块在结构比较复杂，如下图所示：</p><p><img src="/DLNotes/11-1.png" alt="11-1"></p><p>Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1×11×1、3×33×3和5×55×5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1×11×1卷积来减少输入通道数，以降低模型复杂度。第4条线路则使用3×33×3最大池化层，后接1×11×1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结,并向后进行传输。</p><p><strong>1×11×1卷积</strong>：</p><p>它的计算方法和其他卷积核一样，唯一不同的是它的大小是1×11×1，没有考虑在特征图局部信息之间的关系。</p><p><img src="/DLNotes/11-2.png" alt="11-2"></p><p>它的作用主要是：</p><ul><li>实现跨通道的交互和信息整合</li><li>卷积核通道数的降维和升维，减少网络参数</li></ul><p>在tf.keras中实现Inception模块，各个卷积层卷积核的个数通过输入参数来控制，如下所示：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">class Inception(tf.keras.layers.Layer):    # 设置模块的构成    def __init__(self,c1,c2,c3,c4):        super().__init__()        # 线路1:1*1 RELU same c1        self.p1_1 &#x3D; tf.keras.layers.Conv2D(c1,kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding &#x3D;&quot;same&quot;)        # 线路2:1*1 RELU same c2[0]        self.p2_1 &#x3D; tf.keras.layers.Conv2D(c2[0],kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)        # 线路2:3*3 RELU same c2[1]        self.p2_2 &#x3D; tf.keras.layers.Conv2D(c2[1],kernel_size&#x3D;3,activation&#x3D;&quot;relu&quot;,padding&#x3D;&#39;same&#39;)        # 线路3:1*1 RELU same c3[0]        self.p3_1 &#x3D; tf.keras.layers.Conv2D(c3[0],kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)        # 线路3:5*5 RELU same c3[1]        self.p3_2 &#x3D; tf.keras.layers.Conv2D(c3[1],kernel_size&#x3D;5,activation&#x3D;&quot;relu&quot;,padding&#x3D;&#39;same&#39;)        # 线路4: max-pool         self.p4_1 &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,padding&#x3D;&quot;same&quot;,strides&#x3D;1)        # 线路4:1*1        self.p4_2 &#x3D; tf.keras.layers.Conv2D(c4,kernel_size&#x3D;1,activation&#x3D;&quot;relu&quot;,padding&#x3D;&quot;same&quot;)    # 前行传播过程    def call(self,x):        # 线路1        p1 &#x3D; self.p1_1(x)        # 线路2        p2 &#x3D; self.p2_2(self.p2_1(x))        # 线路3        p3 &#x3D; self.p3_2(self.p3_1(x))        # 线路4        p4 &#x3D; self.p4_2(self.p4_1(x))        # concat        outputs &#x3D; tf.concat([p1,p2,p3,p4],axis&#x3D;-1)        return outputs    </code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Inception(64,(96,128),(16,32),32)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;__main__.Inception at 0x1048a6828&gt;</code></pre><h2 id="GoogLeNet构建"><a href="#GoogLeNet构建" class="headerlink" title="GoogLeNet构建"></a>GoogLeNet构建</h2><p><img src="/DLNotes/11-3.png" alt="11-3"></p><p>整个网络架构我们分为五个模块，每个模块之间使用步幅为2的3×33×3最大池化层来减小输出高宽。</p><p><img src="/DLNotes/11-4.png" alt="11-4"></p><h3 id="B1模块"><a href="#B1模块" class="headerlink" title="B1模块"></a>B1模块</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs &#x3D; tf.keras.Input(shape&#x3D;(224,224,1),name&#x3D;&quot;input&quot;)# 卷积:7*7 64 x &#x3D; tf.keras.layers.Conv2D(64,kernel_size&#x3D;7,strides &#x3D; 2,padding&#x3D;&quot;same&quot;,activation&#x3D;&quot;relu&quot;)(inputs)# 池化层x &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre><h3 id="B2模块"><a href="#B2模块" class="headerlink" title="B2模块"></a>B2模块</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 卷积层:1*1x &#x3D; tf.keras.layers.Conv2D(64,kernel_size &#x3D; 1,padding&#x3D;&#39;same&#39;,activation&#x3D;&quot;relu&quot;)(x)# 卷积:3*3x &#x3D; tf.keras.layers.Conv2D(192,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;,activation&#x3D;&#39;relu&#39;)(x)# 池化层x &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre><h3 id="B3模块"><a href="#B3模块" class="headerlink" title="B3模块"></a>B3模块</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"># inceptionx &#x3D; Inception(64,(96,128),(16,32),32)(x)# inceptionx &#x3D; Inception(128,(128,192),(32,96),64)(x)# 池化x &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&quot;same&quot;)(x)</code></pre><h3 id="B4模块"><a href="#B4模块" class="headerlink" title="B4模块"></a>B4模块</h3><p>第四模块更加复杂。它串联了5个Inception块，其输出通道数分别是192+208+48+64&#x3D;512192+208+48+64&#x3D;512、160+224+64+64&#x3D;512160+224+64+64&#x3D;512、128+256+64+64&#x3D;512128+256+64+64&#x3D;512、112+288+64+64&#x3D;528112+288+64+64&#x3D;528和256+320+128+128&#x3D;832256+320+128+128&#x3D;832。并且增加了辅助分类器，根据实验发现网络的中间层具有很强的识别能力，为了利用中间层抽象的特征，在某些中间层中添加含有多层的分类器，如下图所示：</p><p><img src="/DLNotes/11-5.png" alt="11-5"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 辅助分类器def aux_classifier(x,filter_size):    # 池化层    x &#x3D; tf.keras.layers.AveragePooling2D(pool_size&#x3D;5,strides &#x3D; 3,padding&#x3D;&#39;same&#39;)(x)    # 卷积层    x &#x3D; tf.keras.layers.Conv2D(filters &#x3D; filter_size[0],kernel_size&#x3D;1,strides&#x3D;1,padding &#x3D;&quot;valid&quot;,activation&#x3D;&quot;relu&quot;)(x)    # 展评    x &#x3D; tf.keras.layers.Flatten()(x)    # 全连接    x &#x3D; tf.keras.layers.Dense(units &#x3D; filter_size[1],activation&#x3D;&quot;relu&quot;)(x)    # 输出层:    x &#x3D; tf.keras.layers.Dense(units&#x3D;10,activation&#x3D;&quot;softmax&quot;)(x)    return x</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># Inceptionx &#x3D; Inception(192,(96,208),(16,48),64)(x)# 辅助输出aux_output1 &#x3D; aux_classifier(x,[128,1024])# Inceptionx &#x3D; Inception(160,(112,224),(24,64),64)(x)# Inceptionx &#x3D; Inception(128,(128,256),(24,64),64)(x)# Inceptionx &#x3D; Inception(112,(144,288),(32,64),64)(x)# 辅助输出2aux_output2 &#x3D; aux_classifier(x,[128,1024])# Inceptionx &#x3D;Inception(256,(160,320),(32,128),128)(x)# 最大池化x &#x3D; tf.keras.layers.MaxPool2D(pool_size&#x3D;3,strides&#x3D;2,padding&#x3D;&#39;same&#39;)(x)</code></pre><h3 id="b5模块"><a href="#b5模块" class="headerlink" title="b5模块"></a>b5模块</h3><p>第五模块有输出通道数为256+320+128+128&#x3D;832256+320+128+128&#x3D;832和384+384+128+128&#x3D;1024384+384+128+128&#x3D;1024的两个Inception块。后面紧跟输出层，该模块使用全局平均池化层（GAP）来将每个通道的高和宽变成1。最后输出变成二维数组后接输出个数为标签类别数的全连接层。</p><p><strong>全局平均池化层（GAP）</strong></p><p>用来替代全连接层，将特征图每一通道中所有像素值相加后求平均，得到就是GAP的结果，在将其送入后续网络中进行计算</p><p><img src="/DLNotes/11-6.png" alt="11-6"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># inceptionx &#x3D; Inception(256,(160,320),(32,128),128)(x)x &#x3D; Inception(384,(192,384),(48,128),128)(x)# GAPx &#x3D; tf.keras.layers.GlobalAvgPool2D()(x)# 输出层output &#x3D; tf.keras.layers.Dense(10,activation&#x3D;&quot;softmax&quot;)(x)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型model &#x3D; tf.keras.Model(inputs&#x3D;inputs,outputs&#x3D;[output,aux_output1,aux_output2])</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;functional_1&quot;__________________________________________________________________________________________________Layer (type)                    Output Shape         Param #     Connected to                     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;input (InputLayer)              [(None, 224, 224, 1) 0                                            __________________________________________________________________________________________________conv2d_6 (Conv2D)               (None, 112, 112, 64) 3200        input[0][0]                      __________________________________________________________________________________________________max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           conv2d_6[0][0]                   __________________________________________________________________________________________________conv2d_7 (Conv2D)               (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            __________________________________________________________________________________________________conv2d_8 (Conv2D)               (None, 56, 56, 192)  110784      conv2d_7[0][0]                   __________________________________________________________________________________________________max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 192)  0           conv2d_8[0][0]                   __________________________________________________________________________________________________inception_1 (Inception)         (None, 28, 28, 256)  163696      max_pooling2d_2[0][0]            __________________________________________________________________________________________________inception_2 (Inception)         (None, 28, 28, 480)  388736      inception_1[0][0]                __________________________________________________________________________________________________max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 480)  0           inception_2[0][0]                __________________________________________________________________________________________________inception_3 (Inception)         (None, 14, 14, 512)  376176      max_pooling2d_5[0][0]            __________________________________________________________________________________________________inception_4 (Inception)         (None, 14, 14, 512)  449160      inception_3[0][0]                __________________________________________________________________________________________________inception_5 (Inception)         (None, 14, 14, 512)  510104      inception_4[0][0]                __________________________________________________________________________________________________inception_6 (Inception)         (None, 14, 14, 528)  605376      inception_5[0][0]                __________________________________________________________________________________________________inception_7 (Inception)         (None, 14, 14, 832)  868352      inception_6[0][0]                __________________________________________________________________________________________________max_pooling2d_11 (MaxPooling2D) (None, 7, 7, 832)    0           inception_7[0][0]                __________________________________________________________________________________________________average_pooling2d (AveragePooli (None, 5, 5, 512)    0           inception_3[0][0]                __________________________________________________________________________________________________average_pooling2d_1 (AveragePoo (None, 5, 5, 528)    0           inception_6[0][0]                __________________________________________________________________________________________________inception_8 (Inception)         (None, 7, 7, 832)    1043456     max_pooling2d_11[0][0]           __________________________________________________________________________________________________conv2d_27 (Conv2D)              (None, 5, 5, 128)    65664       average_pooling2d[0][0]          __________________________________________________________________________________________________conv2d_46 (Conv2D)              (None, 5, 5, 128)    67712       average_pooling2d_1[0][0]        __________________________________________________________________________________________________inception_9 (Inception)         (None, 7, 7, 1024)   1444080     inception_8[0][0]                __________________________________________________________________________________________________flatten (Flatten)               (None, 3200)         0           conv2d_27[0][0]                  __________________________________________________________________________________________________flatten_1 (Flatten)             (None, 3200)         0           conv2d_46[0][0]                  __________________________________________________________________________________________________global_average_pooling2d (Globa (None, 1024)         0           inception_9[0][0]                __________________________________________________________________________________________________dense (Dense)                   (None, 1024)         3277824     flatten[0][0]                    __________________________________________________________________________________________________dense_2 (Dense)                 (None, 1024)         3277824     flatten_1[0][0]                  __________________________________________________________________________________________________dense_4 (Dense)                 (None, 10)           10250       global_average_pooling2d[0][0]   __________________________________________________________________________________________________dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      __________________________________________________________________________________________________dense_3 (Dense)                 (None, 10)           10250       dense_2[0][0]                    &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 12,687,054Trainable params: 12,687,054Non-trainable params: 0__________________________________________________________________________________________________</code></pre><h2 id="数据读取-2"><a href="#数据读取-2" class="headerlink" title="数据读取"></a>数据读取</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom tensorflow.keras.datasets import mnist# 获取手写数字数据集(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()# 训练集数据维度的调整：N H W Ctrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))# 测试集数据维度的调整：N H W Ctest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义两个方法随机抽取部分样本演示# 获取训练集数据def get_train(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)    # 将这些数据resize成22*227大小    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)    # 返回抽取的    return resized_images.numpy(), train_labels[index]# 获取测试集数据 def get_test(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)    # 将这些数据resize成224*224大小    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)    # 返回抽样的测试样本    return resized_images.numpy(), test_labels[index]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获取训练样本和测试样本train_images,train_labels &#x3D; get_train(256)test_images,test_labels &#x3D; get_test(128)</code></pre><h2 id="模型编译-4"><a href="#模型编译-4" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定优化器，损失函数和评价指标optimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)# 模型有3个输出，所以指定损失函数对应的权重系数model.compile(optimizer&#x3D;optimizer,              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,              metrics&#x3D;[&#39;accuracy&#39;],loss_weights&#x3D;[1,0.3,0.3])</code></pre><h2 id="模型训练-4"><a href="#模型训练-4" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型训练：指定训练数据，batchsize,epoch,验证集model.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 5.0465 - dense_4_loss: 2.5478 - dense_1_loss: 5.5701 - dense_3_loss: 2.7589 - dense_4_accuracy: 0.1174 - dense_1_accuracy: 0.0696 - dense_3_accuracy: 0.0739 - val_loss: 3.8758 - val_dense_4_loss: 2.2874 - val_dense_1_loss: 2.9486 - val_dense_3_loss: 2.3461 - val_dense_4_accuracy: 0.1538 - val_dense_1_accuracy: 0.1154 - val_dense_3_accuracy: 0.0769Epoch 2&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 3s&#x2F;step - loss: 3.8362 - dense_4_loss: 2.3122 - dense_1_loss: 2.7749 - dense_3_loss: 2.3050 - dense_4_accuracy: 0.1087 - dense_1_accuracy: 0.1043 - dense_3_accuracy: 0.1000 - val_loss: 3.7066 - val_dense_4_loss: 2.3002 - val_dense_1_loss: 2.3821 - val_dense_3_loss: 2.3059 - val_dense_4_accuracy: 0.1154 - val_dense_1_accuracy: 0.0769 - val_dense_3_accuracy: 0.0385Epoch 3&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 4s&#x2F;step - loss: 3.6779 - dense_4_loss: 2.3000 - dense_1_loss: 2.3131 - dense_3_loss: 2.2799 - dense_4_accuracy: 0.1043 - dense_1_accuracy: 0.1522 - dense_3_accuracy: 0.1522 - val_loss: 3.6978 - val_dense_4_loss: 2.3022 - val_dense_1_loss: 2.3475 - val_dense_3_loss: 2.3045 - val_dense_4_accuracy: 0.1154 - val_dense_1_accuracy: 0.0769 - val_dense_3_accuracy: 0.0385</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x141bf7f60&gt;</code></pre><h2 id="模型评估-4"><a href="#模型评估-4" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定测试数据model.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 325ms&#x2F;step - loss: 3.6632 - dense_4_loss: 2.2931 - dense_1_loss: 2.2922 - dense_3_loss: 2.2749 - dense_4_accuracy: 0.1484 - dense_1_accuracy: 0.1719 - dense_3_accuracy: 0.1328</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[3.663177967071533, 2.2930545806884766, 2.2921969890594482, 2.274880886077881, 0.1484375, 0.171875, 0.1328125]</code></pre><h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tffrom tensorflow.keras import layers,activations</code></pre><p>网络越深，获取的信息就越多，特征也越丰富。但是在实践中，随着网络的加深，优化效果反而越差，测试数据和训练数据的准确率反而降低了。</p><p>针对这一问题，何恺明等人提出了残差网络（ResNet）在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。</p><h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h2><p>假设 F(x) 代表某个只包含有两层的映射函数， x 是输入， F(x)是输出。假设他们具有相同的维度。在训练的过程中我们希望能够通过修改网络中的 w和b去拟合一个理想的 H(x)(从输入到输出的一个理想的映射函数)。也就是我们的目标是修改F(x) 中的 w和b逼近 H(x) 。如果我们改变思路，用F(x) 来逼近 H(x)-x ，那么我们最终得到的输出就变为 F(x)+x（这里的加指的是对应位置上的元素相加，也就是element-wise addition），这里将直接从输入连接到输出的结构也称为shortcut，那整个结构就是残差块，ResNet的基础模块。</p><p><img src="/DLNotes/12-1.png" alt="12-1"></p><p>ResNet沿用了VGG全3×33×3卷积层的设计。残差块里首先有2个有相同输出通道数的3×33×3卷积层。每个卷积层后接BN层和ReLU激活函数，然后将输入直接加在最后的ReLU激活函数前，这种结构用于层数较少的神经网络中，比如ResNet34。若输入通道数比较多，就需要引入1×11×1卷积层来调整输入的通道数，这种结构也叫作瓶颈模块，通常用于网络层数较多的结构中。如下图所示：</p><p><img src="/DLNotes/12-2.png" alt="12-2"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">class Residual(tf.keras.Model):    # 定义网络结构    def __init__(self,num_channels,use_1x1conv&#x3D;False,strides&#x3D;1):        super(Residual,self).__init__()        # 卷积层        self.conv1 &#x3D; layers.Conv2D(num_channels,padding&#x3D;&#39;same&#39;,kernel_size&#x3D;3,strides&#x3D;strides)        # 卷积层        self.conv2 &#x3D; layers.Conv2D(num_channels,kernel_size&#x3D;3,padding&#x3D;&#39;same&#39;)        # 是否使用1*1的卷积        if use_1x1conv:            self.conv3 &#x3D; layers.Conv2D(num_channels,kernel_size&#x3D;1,strides&#x3D;strides)        else:            self.conv3 &#x3D; None        # BN层        self.bn1 &#x3D; layers.BatchNormalization()        self.bn2 &#x3D; layers.BatchNormalization()    # 定义前向传播过程      def call(self,x):        Y &#x3D; activations.relu(self.bn1(self.conv1(x)))        Y &#x3D; self.bn2(self.conv2(Y))        if self.conv3:            x &#x3D; self.conv3(x)        outputs &#x3D; activations.relu(Y+x)        return outputs</code></pre><p>1*1卷积用来调整通道数。</p><h2 id="残差模块"><a href="#残差模块" class="headerlink" title="残差模块"></a>残差模块</h2><p><img src="/DLNotes/12-3.png" alt="12-3"></p><p>ResNet网络中按照残差块的通道数分为不同的模块。第一个模块前使用了步幅为2的最大池化层，所以无须减小高和宽。之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">class ResnetBlock(tf.keras.layers.Layer):    # 定义所需的网络结构    def __init__(self,num_channels,num_res,first_block&#x3D;False):        super(ResnetBlock,self).__init__()        # 存储残差块        self.listLayers&#x3D;[]        # 遍历残差数目生成模块        for i in range(num_res):            # 如果是第一个残差块而且不是第一个模块时            if i &#x3D;&#x3D;0 and not first_block:                self.listLayers.append(Residual(num_channels,use_1x1conv&#x3D;True,strides&#x3D;2))            else:                self.listLayers.append(Residual(num_channels))    # 定义前向传播    def call(self,X):        for layer in self.listLayers.layers:            X &#x3D; layer(X)        return X</code></pre><h2 id="构建resNet网络"><a href="#构建resNet网络" class="headerlink" title="构建resNet网络"></a>构建resNet网络</h2><p>ResNet的前两层跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7×77×7卷积层后接步幅为2的3×33×3的最大池化层。不同之处在于ResNet每个卷积层后增加了BN层,接着是所有残差模块，最后，与GoogLeNet一样，加入全局平均池化层（GAP）后接上全连接层输出。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">class ResNet(tf.keras.Model):    # 定义网络的构成    def __init__(self, num_blocks):        super(ResNet, self).__init__()        # 输入层        self.conv &#x3D; layers.Conv2D(64, kernel_size&#x3D;7, strides&#x3D;2, padding&#x3D;&#39;same&#39;)        # BN 层        self.bn &#x3D; layers.BatchNormalization()        # 激活层        self.relu &#x3D; layers.Activation(&#39;relu&#39;)        # 池化        self.mp &#x3D; layers.MaxPool2D(pool_size&#x3D;3, strides&#x3D;2, padding&#x3D;&quot;same&quot;)        # 残差模块        self.res_block1 &#x3D; ResnetBlock(64, num_blocks[0], first_block&#x3D;True)        self.res_block2 &#x3D; ResnetBlock(128, num_blocks[1])        self.res_block3 &#x3D; ResnetBlock(256, num_blocks[2])        self.res_block4 &#x3D; ResnetBlock(512, num_blocks[3])        # GAP        self.gap &#x3D; layers.GlobalAvgPool2D()        # 全连接层        self.fc &#x3D; layers.Dense(            units&#x3D;10, activation&#x3D;tf.keras.activations.softmax)    # 定义前向传播过程    def call(self, x):        # 输入部分的传输过程        x &#x3D; self.conv(x)        x &#x3D; self.bn(x)        x &#x3D; self.relu(x)        x &#x3D; self.mp(x)        # block        x &#x3D; self.res_block1(x)        x &#x3D; self.res_block2(x)        x &#x3D; self.res_block3(x)        x &#x3D; self.res_block4(x)        # 输出部分的传输        x &#x3D; self.gap(x)        x &#x3D; self.fc(x)        return x</code></pre><p>这里每个模块里有4个卷积层（不计算 1×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型被称为ResNet-18。通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。 在训练ResNet之前，我们来观察一下输入形状在ResNe的架构：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化mynet &#x3D; ResNet([2,2,2,2])X &#x3D; tf.random.uniform((1,224,224,1))y &#x3D; mynet(X)mynet.summary()</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Model: &quot;res_net_5&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;conv2d_62 (Conv2D)           multiple                  3200      _________________________________________________________________batch_normalization_53 (Batc multiple                  256       _________________________________________________________________activation_5 (Activation)    multiple                  0         _________________________________________________________________max_pooling2d_5 (MaxPooling2 multiple                  0         _________________________________________________________________resnet_block_14 (ResnetBlock multiple                  148736    _________________________________________________________________resnet_block_15 (ResnetBlock multiple                  526976    _________________________________________________________________resnet_block_16 (ResnetBlock multiple                  2102528   _________________________________________________________________resnet_block_17 (ResnetBlock multiple                  8399360   _________________________________________________________________global_average_pooling2d_3 ( multiple                  0         _________________________________________________________________dense_3 (Dense)              multiple                  5130      &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 11,186,186Trainable params: 11,178,378Non-trainable params: 7,808_________________________________________________________________</code></pre><h2 id="数据读取-3"><a href="#数据读取-3" class="headerlink" title="数据读取"></a>数据读取</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import numpy as npfrom tensorflow.keras.datasets import mnist# 获取手写数字数据集(train_images, train_labels), (test_images, test_labels) &#x3D; mnist.load_data()# 训练集数据维度的调整：N H W Ctrain_images &#x3D; np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))# 测试集数据维度的调整：N H W Ctest_images &#x3D; np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 定义两个方法随机抽取部分样本演示# 获取训练集数据def get_train(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(train_images)[0], size)    # 将这些数据resize成22*227大小    resized_images &#x3D; tf.image.resize_with_pad(train_images[index],224,224,)    # 返回抽取的    return resized_images.numpy(), train_labels[index]# 获取测试集数据 def get_test(size):    # 随机生成要抽样的样本的索引    index &#x3D; np.random.randint(0, np.shape(test_images)[0], size)    # 将这些数据resize成224*224大小    resized_images &#x3D; tf.image.resize_with_pad(test_images[index],224,224,)    # 返回抽样的测试样本    return resized_images.numpy(), test_labels[index]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获取训练样本和测试样本train_images,train_labels &#x3D; get_train(256)test_images,test_labels &#x3D; get_test(128)</code></pre><h2 id="模型编译-5"><a href="#模型编译-5" class="headerlink" title="模型编译"></a>模型编译</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定优化器，损失函数和评价指标optimizer &#x3D; tf.keras.optimizers.SGD(learning_rate&#x3D;0.01, momentum&#x3D;0.0)mynet.compile(optimizer&#x3D;optimizer,              loss&#x3D;&#39;sparse_categorical_crossentropy&#39;,              metrics&#x3D;[&#39;accuracy&#39;])</code></pre><h2 id="模型训练-5"><a href="#模型训练-5" class="headerlink" title="模型训练"></a>模型训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 模型训练：指定训练数据，batchsize,epoch,验证集mynet.fit(train_images,train_labels,batch_size&#x3D;128,epochs&#x3D;3,verbose&#x3D;1,validation_split&#x3D;0.1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 4s&#x2F;step - loss: 2.7646 - accuracy: 0.1348 - val_loss: 4.4041 - val_accuracy: 0.0769Epoch 2&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 2.1875 - accuracy: 0.2826 - val_loss: 5.0271 - val_accuracy: 0.0769Epoch 3&#x2F;32&#x2F;2 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 4s&#x2F;step - loss: 1.9738 - accuracy: 0.3435 - val_loss: 3.6854 - val_accuracy: 0.3077</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">&lt;tensorflow.python.keras.callbacks.History at 0x13e4ef438&gt;</code></pre><h2 id="模型评估-5"><a href="#模型评估-5" class="headerlink" title="模型评估"></a>模型评估</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 指定测试数据mynet.evaluate(test_images,test_labels,verbose&#x3D;1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">4&#x2F;4 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 1s 342ms&#x2F;step - loss: 4.9585 - accuracy: 0.1094</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">[4.958542823791504, 0.109375]</code></pre><h1 id="imageAUG-图像增强"><a href="#imageAUG-图像增强" class="headerlink" title="imageAUG 图像增强"></a>imageAUG 图像增强</h1><p>大规模数据集是成功应用深度神经网络的前提。例如，我们可以对图像进行不同方式的裁剪，使感兴趣的物体出现在不同位置，从而减轻模型对物体出现位置的依赖性。我们也可以调整亮度、色彩等因素来降低模型对色彩的敏感度。可以说，在当年AlexNet的成功中，图像增强技术功不可没</p><h2 id="1-常用的图像增强方法"><a href="#1-常用的图像增强方法" class="headerlink" title="1.常用的图像增强方法"></a>1.常用的图像增强方法</h2><p>图像增强（image augmentation）指通过剪切、旋转&#x2F;反射&#x2F;翻转变换、缩放变换、平移变换、尺度变换、对比度变换、噪声扰动、颜色变换等一种或多种组合数据增强变换的方式来增加数据集的大小。图像增强的意义是通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模，而且随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。</p><p>常见的图像增强方式可以分为两类：几何变换类和颜色变换类</p><ul><li><p>几何变换类，主要是对图像进行几何变换操作，包括<strong>翻转，旋转，裁剪，变形，缩放</strong>等。</p><p><img src="/DLNotes/13-1.png" alt="13-1"></p></li><li><p>颜色变换类，指通过模糊、颜色变换、擦除、填充等方式对图像进行处理</p><p><img src="/DLNotes/13-2.png" alt="13-2"></p></li></ul><h2 id="tf-image进行增强"><a href="#tf-image进行增强" class="headerlink" title="tf.image进行增强"></a>tf.image进行增强</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">import tensorflow as tfimport matplotlib.pyplot as pltimport numpy as np</code></pre><pre><code>/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject  return f(*args, **kwds)/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject  return f(*args, **kwds)/opt/anaconda3/envs/dlcv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject  return f(*args, **kwds)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">cat &#x3D; plt.imread(&#39;.&#x2F;cat.jpg&#39;)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt.imshow(cat)</code></pre><p><img src="/DLNotes/13-3.png" alt="13-3"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 左右翻转并显示cat1 &#x3D; tf.image.random_flip_left_right(cat)plt.imshow(cat1)</code></pre><p><img src="/DLNotes/13-4.png" alt="13-4"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 上下翻转cat2 &#x3D; tf.image.random_flip_up_down(cat)plt.imshow(cat2)</code></pre><p><img src="/DLNotes/13-5.png" alt="13-5"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 随机裁剪cat3 &#x3D; tf.image.random_crop(cat,(200,200,3))plt.imshow(cat3)</code></pre><p><img src="/DLNotes/13-6.png" alt="13-6"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 颜色变换cat4 &#x3D; tf.image.random_brightness(cat,0.5)plt.imshow(cat4)</code></pre><p><img src="/DLNotes/13-7.png" alt="13-7"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 随机变化图像cat5 &#x3D; tf.image.random_hue(cat,0.5)plt.imshow(cat5)</code></pre><p><img src="/DLNotes/13-8.png" alt="13-8"></p><h2 id="使用imagedataGenerator进行增强"><a href="#使用imagedataGenerator进行增强" class="headerlink" title="使用imagedataGenerator进行增强"></a>使用imagedataGenerator进行增强</h2><p>ImageDataGenerator()是keras.preprocessing.image模块中的DLNotes生成器，可以在batch中对数据进行增强，扩充数据集大小，增强模型的泛化能力。比如旋转，变形等，如下所示：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">from tensorflow.keras.datasets import mnist</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获取数据集(x_train, y_train), (x_test, y_test) &#x3D; tf.keras.datasets.mnist.load_data()# 将数据转换为4维的形式x_train &#x3D; x_train.reshape(x_train.shape[0],28,28,1)x_test &#x3D; x_test.reshape(x_test.shape[0],28,28,1)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 实例化datagen &#x3D; tf.keras.preprocessing.image.ImageDataGenerator(shear_range&#x3D;10)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">for x,y in datagen.flow(x_train,y_train,batch_size&#x3D;9):    plt.figure(figsize&#x3D;(8,8))    for i in range(0,9):        plt.subplot(330+1+i)        plt.imshow(x[i].reshape(28,28),cmap&#x3D;&#39;gray&#39;)        plt.title(y[i])    plt.show()    break</code></pre><p><img src="/DLNotes/13-9.png" alt="13-9"></p><h1 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h1><p>如何在只有6万张图像的MNIST训练数据集上训练模型。学术界当下使用最广泛的大规模图像数据集ImageNet，它有超过1,000万的图像和1,000类的物体。然而，我们平常接触到数据集的规模通常在这两者之间。假设我们想从图像中识别出不同种类的椅子，然后将购买链接推荐给用户。一种可能的方法是先找出100种常见的椅子，为每种椅子拍摄1,000张不同角度的图像，然后在收集到的图像数据集上训练一个分类模型。另外一种解决办法是应用迁移学习（transfer learning），将从源数据集学到的知识迁移到目标数据集上。例如，虽然ImageNet数据集的图像大多跟椅子无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成等。这些类似的特征对于识别椅子也可能同样有效。</p><p>微调由以下4步构成。</p><ol><li>在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。</li><li>创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。</li><li>为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。</li><li>在目标数据集（如椅子数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。</li></ol><p><img src="/DLNotes/14.png" alt="14"></p><p>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</p><p>例如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 热狗识别。将基于一个小数据集对在ImageNet数据集上训练好的ResNet模型进行微调。该小数据集含有数千张热狗或者其他事物的图像。我们将使用微调得到的模型来识别一张图像中是否包含热狗。import tensorflow as tfimport numpy as np# 通过以下方法读取图像文件，该方法以文件夹路径为参数,生成经过图像增强后的结果，并产生batch数据：flow_from_directory(self, directory,                            target_size&#x3D;(256, 256), color_mode&#x3D;&#39;rgb&#39;,                            classes&#x3D;None, class_mode&#x3D;&#39;categorical&#39;,                            batch_size&#x3D;32, shuffle&#x3D;True, seed&#x3D;None,                            save_to_dir&#x3D;None）</code></pre><p>主要参数：</p><ul><li>directory: 目标文件夹路径，对于每一个类对应一个子文件夹，该子文件夹中任何JPG、PNG、BNP、PPM的DLNotes都可以读取。</li><li>target_size: 默认为(256, 256)，图像将被resize成该尺寸。</li><li>batch_size: batch数据的大小，默认32。</li><li>shuffle: 是否打乱数据，默认为True。</li></ul><p>我们创建两个<code>tf.keras.preprocessing.image.ImageDataGenerator</code>实例来分别读取训练数据集和测试数据集中的所有图像文件。将训练集DLNotes全部处理为高和宽均为224像素的输入。此外，我们对RGB（红、绿、蓝）三个颜色通道的数值做标准化。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 获取数据集import pathlibtrain_dir &#x3D; &#39;transferdata&#x2F;train&#39;test_dir &#x3D; &#39;transferdata&#x2F;test&#39;# 获取训练集数据train_dir &#x3D; pathlib.Path(train_dir)train_count &#x3D; len(list(train_dir.glob(&#39;*&#x2F;*.jpg&#39;)))# 获取测试集数据test_dir &#x3D; pathlib.Path(test_dir)test_count &#x3D; len(list(test_dir.glob(&#39;*&#x2F;*.jpg&#39;)))# 创建imageDataGenerator进行图像处理image_generator &#x3D; tf.keras.preprocessing.image.ImageDataGenerator(rescale&#x3D;1.&#x2F;255)# 设置参数BATCH_SIZE &#x3D; 32IMG_HEIGHT &#x3D; 224IMG_WIDTH &#x3D; 224# 获取训练数据train_data_gen &#x3D; image_generator.flow_from_directory(directory&#x3D;str(train_dir),                                                    batch_size&#x3D;BATCH_SIZE,                                                    target_size&#x3D;(IMG_HEIGHT, IMG_WIDTH),                                                    shuffle&#x3D;True)# 获取测试数据test_data_gen &#x3D; image_generator.flow_from_directory(directory&#x3D;str(test_dir),                                                    batch_size&#x3D;BATCH_SIZE,                                                    target_size&#x3D;(IMG_HEIGHT, IMG_WIDTH),                                                    shuffle&#x3D;True)</code></pre><p>随机取1个batch的DLNotes然后绘制出来。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import matplotlib.pyplot as plt# 显示图像def show_batch(image_batch, label_batch):    plt.figure(figsize&#x3D;(10,10))    for n in range(15):        ax &#x3D; plt.subplot(5,5,n+1)        plt.imshow(image_batch[n]）        plt.axis(&#39;off&#39;)# 随机选择一个batch的图像        image_batch, label_batch &#x3D; next(train_data_gen)# 图像显示show_batch(image_batch, label_batch)</code></pre><p><img src="/DLNotes/14-1.png" alt="14-1"></p><p>我们使用在ImageNet数据集上预训练的ResNet-50作为源模型。这里指定<code>weights=&#39;imagenet&#39;</code>来自动下载并加载预训练的模型参数。在第一次使用时需要联网下载模型参数。</p><p>Keras应用程序（keras.applications）是具有预先训练权值的固定架构，该类封装了很多重量级的网络架构，如下图所示：</p><p><img src="/DLNotes/14-2.png" alt="14-2"></p><p>实现时实例化模型架构：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tf.keras.applications.ResNet50(    include_top&#x3D;True, weights&#x3D;&#39;imagenet&#39;, input_tensor&#x3D;None, input_shape&#x3D;None,    pooling&#x3D;None, classes&#x3D;1000, **kwargs)</code></pre><p>主要参数：</p><ul><li>include_top: 是否包括顶层的全连接层。</li><li>weights: None 代表随机初始化， ‘imagenet’ 代表加载在 ImageNet 上预训练的权值。</li><li>input_shape: 可选，输入尺寸元组，仅当 include_top&#x3D;False 时有效，否则输入形状必须是 (224, 224, 3)（channels_last 格式）或 (3, 224, 224)（channels_first 格式）。它必须为 3 个输入通道，且宽高必须不小于 32，比如 (200, 200, 3) 是一个合法的输入尺寸。</li></ul><p>在该案例中我们使用resNet50预训练模型构建模型：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"># 加载预训练模型ResNet50 &#x3D; tf.keras.applications.ResNet50(weights&#x3D;&#39;imagenet&#39;, input_shape&#x3D;(224,224,3))# 设置所有层不可训练for layer in ResNet50.layers:    layer.trainable &#x3D; False# 设置模型net &#x3D; tf.keras.models.Sequential()# 预训练模型net.add(ResNet50)# 展开net.add(tf.keras.layers.Flatten())# 二分类的全连接层net.add(tf.keras.layers.Dense(2, activation&#x3D;&#39;softmax&#39;))# 模型编译：指定优化器，损失函数和评价指标net.compile(optimizer&#x3D;&#39;adam&#39;,            loss&#x3D;&#39;categorical_crossentropy&#39;,            metrics&#x3D;[&#39;accuracy&#39;])# 模型训练：指定数据，每一个epoch中只运行10个迭代，指定验证数据集history &#x3D; net.fit(                    train_data_gen,                    steps_per_epoch&#x3D;10,                    epochs&#x3D;3,                    validation_data&#x3D;test_data_gen,                    validation_steps&#x3D;10                    )</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Epoch 1&#x2F;310&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 28s 3s&#x2F;step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6930 - val_accuracy: 0.5094Epoch 2&#x2F;310&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 29s 3s&#x2F;step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6935 - val_accuracy: 0.4812Epoch 3&#x2F;310&#x2F;10 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 31s 3s&#x2F;step - loss: 0.6935 - accuracy: 0.4844 - val_loss: 0.6933 - val_accuracy: 0.4875</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;iris-鸢尾花&quot;&gt;&lt;a href=&quot;#iris-鸢尾花&quot; class=&quot;headerlink&quot; title=&quot;iris-鸢尾花&quot;&gt;&lt;/a&gt;iris-鸢尾花&lt;/h1&gt;&lt;pre class=&quot;line-numbers language-python&quot; data-la</summary>
      
    
    
    
    <category term="Deep Learning" scheme="http://quanzhang.top/categories/Deep-Learning/"/>
    
    
    <category term="深度学习" scheme="http://quanzhang.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="DLNotes分类" scheme="http://quanzhang.top/tags/DLNotes%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>基于R推荐系统搭建</title>
    <link href="http://quanzhang.top/post/%E5%9F%BA%E4%BA%8ER%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA.html"/>
    <id>http://quanzhang.top/post/%E5%9F%BA%E4%BA%8ER%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA.html</id>
    <published>2022-03-21T14:23:39.000Z</published>
    <updated>2024-11-06T02:24:29.752Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>首先，R语言牛皮之处就不过多阐述，总之很方便很方便。R语言就是为了数据处理而生的，可以轻松链接数据库，可以轻松对数据进行处理和分析。</p><p>这篇博客主要归纳一下如何使用R语言搭建一个简单的推荐系统。首先导入包：</p><pre class="line-numbers language-none"><code class="language-none">#install.packages(&quot;RJDBC&quot;) 如果第一次使用，要下载所需要的包，然后使用。library(RJDBC)#以下是一些画图使用的包，还有一些机器学习算法。library(rvest)library(ggplot2)library(dplyr)library(scales)library(maps)library(mapproj)library(plotly)library(rpart)library(rpart.plot)library(C50)library(tree)library(ROCR)library(randomForest)library(e1071)library(naivebayes)library(nnet)library(kknn)</code></pre><h2 id="链接Oracle数据库"><a href="#链接Oracle数据库" class="headerlink" title="链接Oracle数据库"></a>链接Oracle数据库</h2><p>如果有小伙伴想复现这个项目，可以直接去我的github下载csv数据文件，用R导入csv数据也是一样的效果(Imm..表只给出了前几百条数据，因为数据文件太大，无法上传仓库)：</p><p><a href="https://github.com/1250681923/DataAnalyseMBDS.git">项目仓库</a></p><p>虽然有些公司可能节约成本选择使用Mysql，但是学习Oracle还是非常有必要的。在顶端DBA大师眼中，能在PDB中进行协作的Oracle有着无可取代的天然优势。更别提我们可以通过Hive工具创建Oracle内外表后使用Oracle sql, Oracle Nosql, Hadoop HDFS, MongDB搭建数据湖。这对企业的大数据架构的整合有着巨大的价值。</p><p>在此之前需要下载jdbc的jar包：<a href="https://github.com/1250681923/picture.git">点击链接进行下载drives文件</a></p><p>链接配置规则： </p><pre class="line-numbers language-none"><code class="language-none">conn&lt;-dbConnect(drv,“jdbc:oracle:thin:@主机IP:1521:数据库名称”,“用户名称”,“密码”)</code></pre><p>远程链接：</p><pre class="line-numbers language-none"><code class="language-none">drv &lt;- RJDBC::JDBC(driverClass &#x3D; &quot;oracle.jdbc.OracleDriver&quot;, classPath &#x3D;  Sys.glob(&quot;C:&#x2F;Users&#x2F;12506&#x2F;OneDrive&#x2F;Desktop&#x2F;ESTIA3A&#x2F;R&#x2F;Oracle&#x2F;drivers&#x2F;*&quot;))conn &lt;- dbConnect(drv, &quot;jdbc:oracle:thin:@(DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;TCP)(HOST&#x3D;144.21.67.201)(PORT&#x3D;1521))(CONNECT_DATA&#x3D;(SERVICE_NAME&#x3D;pdbest21.631174089.oraclecloud.internal)))&quot;, &quot;ZHANG2B20&quot;, &quot;ZHANG2B2001&quot;)allTables &lt;- dbGetQuery(conn, &quot;SELECT owner, table_name FROM all_tables where owner &#x3D; &#39;ZHANG2B20&#39;&quot;)</code></pre><p>本地链接(我没有试过，你们可以参考如下例子)：</p><pre class="line-numbers language-none"><code class="language-none">drv&lt;-JDBC(&quot;oracle.jdbc.driver.OracleDriver&quot;,&quot;ojdbc6_g.jar&quot;, identifier.quote&#x3D;&quot;\&quot;&quot;)  ##java中JDBC的套路conn&lt;-dbConnect(drv,&quot;jdbc:oracle:thin:@10.0.0.214:1521:zlhis&quot;,&quot;zlhis1234&quot;,&quot;his123&quot;) ##建立一个连接EMP&lt;-dbReadTable(conn,&#39;EMP&#39;) ##根据连接和表名获取Oracle中的表table1&lt;-dbGetQuery(conn,&quot;select * from user_tables&quot;)  ##根据sql记录获取Oracle中表的数据————————————————版权声明：本文为CSDN博主「dltan」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;tandelin&#x2F;article&#x2F;details&#x2F;99300248</code></pre><p>如果数据有乱码：</p><pre class="line-numbers language-none"><code class="language-none">names(table1)&#x3D;iconv(names(table1),&quot;UTF-8&quot;,&quot;GBK&quot;) ##若是表中列名为中文，读取时出现乱码，可用这句来搞定乱码情况</code></pre><p>所以按着我的例子来吧~ </p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>接下来介绍下数据(这里可以用view函数直接看出来各个表的数据)：</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableCatalogue &lt;- dbGetQuery(conn, &quot;select * from Catalogue&quot;)tableClients &lt;- dbGetQuery(conn, &quot;select * from Clients&quot;)tableIm &lt;- dbGetQuery(conn, &quot;select * from IMMATRICULATION&quot;)tableMar &lt;- dbGetQuery(conn, &quot;select * from MARKETING&quot;)</code></pre><p>因为这是一个之前做过的项目，我直接读取之前产生的数据就好了</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">load(&quot;C:&#x2F;Users&#x2F;12506&#x2F;OneDrive&#x2F;Desktop&#x2F;ESTIA3A&#x2F;R&#x2F;Projet&#x2F;.RData&quot;)</code></pre><p>一共有四个表:</p><ul><li>Catalogue 记录着一共270种汽车型号，不同的颜色，品牌，马力等等。该列表的270种是该公司向外出售的车类总类</li></ul><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tableCatalogue[1,])</code></pre><pre><code>  MARQUE NOM PUISSANCE    LONGUEUR NBPLACES NBPORTES COULEUR OCCASION PRIX1    BMW  M5       507 tres longue        5        5    gris     TRUE    2  CATALOGUEID1         238</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableCatalogue)</code></pre><pre><code>    MARQUE              NOM              PUISSANCE       LONGUEUR         Length:270         Length:270         Min.   : 55.0   Length:270         Class :character   Class :character   1st Qu.:109.0   Class :character   Mode  :character   Mode  :character   Median :147.0   Mode  :character                                         Mean   :157.6                                                            3rd Qu.:170.0                                                            Max.   :507.0                         NBPLACES        NBPORTES       COULEUR            OCCASION         Min.   :5.000   Min.   :3.000   Length:270         Length:270         1st Qu.:5.000   1st Qu.:5.000   Class :character   Class :character   Median :5.000   Median :5.000   Mode  :character   Mode  :character   Mean   :5.222   Mean   :4.815                                         3rd Qu.:5.000   3rd Qu.:5.000                                         Max.   :7.000   Max.   :5.000                                              PRIX        CATALOGUEID     Min.   :1.000   Min.   :  1.00   1st Qu.:1.000   1st Qu.: 68.25   Median :2.000   Median :135.50   Mean   :1.685   Mean   :135.50   3rd Qu.:2.000   3rd Qu.:202.75   Max.   :3.000   Max.   :270.00  </code></pre><ul><li>Client 记录着以往的购买记录，客户的信息对应所购买的车牌号。记录着用户的年龄，性别，年税（可以推断大致固定收入），家庭状态，正在照顾的孩子个数，是否是名下第二台车以及车牌号。数据已脱敏，无法根据数据来确定用户身份</li></ul><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tableClients[1,])</code></pre><pre><code>  AGE SEXE TAUX SITUATIONFAMILIALE NBENFANTSACHARGE DEUXIEMEVOITURE1  55    M  561          En Couple                2            TRUE  IMMATRICULATION1      1889 KV 55</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableClients)</code></pre><pre><code>      AGE           SEXE               TAUX           SITUATIONFAMILIALE Min.   :18.0   Length:11065       Length:11065       Length:11065       1st Qu.:28.0   Class :character   Class :character   Class :character   Median :41.0   Mode  :character   Mode  :character   Mode  :character   Mean   :43.7                                                            3rd Qu.:56.0                                                            Max.   :84.0                                                            NBENFANTSACHARGE DEUXIEMEVOITURE    IMMATRICULATION    Min.   :0.000    Length:11065       Length:11065       1st Qu.:0.000    Class :character   Class :character   Median :1.000    Mode  :character   Mode  :character   Mean   :1.247                                          3rd Qu.:2.000                                          Max.   :4.000                                         </code></pre><ul><li>Immatriculation 记录着车牌号对应的汽车信息，这些汽车的种类包含于上述270种。该数据为法国车管所提供，敏感数据已经剔除。从表中可以看出车牌号对应的车的品牌，型号，功率，长短，座位数，门数，颜色，是否是二手车以及价格。</li></ul><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tableIm[1,])  </code></pre><pre><code>  IMMATRICULATION MARQUE       NOM PUISSANCE LONGUEUR NBPLACES NBPORTES COULEUR1      5407 HD 88   Fiat Croma 2.2       147   longue        5        5   rouge  OCCASION PRIX1     TRUE    1</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableIm)</code></pre><pre><code> IMMATRICULATION       MARQUE              NOM              PUISSANCE     Length:1048575     Length:1048575     Length:1048575     Min.   : 55.0   Class :character   Class :character   Class :character   1st Qu.: 75.0   Mode  :character   Mode  :character   Mode  :character   Median :150.0                                                            Mean   :198.9                                                            3rd Qu.:245.0                                                            Max.   :507.0     LONGUEUR            NBPLACES    NBPORTES       COULEUR          Length:1048575     Min.   :5   Min.   :3.000   Length:1048575     Class :character   1st Qu.:5   1st Qu.:5.000   Class :character   Mode  :character   Median :5   Median :5.000   Mode  :character                      Mean   :5   Mean   :4.868                                         3rd Qu.:5   3rd Qu.:5.000                                         Max.   :5   Max.   :5.000                        OCCASION              PRIX       Length:1048575     Min.   :1.000   Class :character   1st Qu.:1.000   Mode  :character   Median :2.000                      Mean   :1.796                      3rd Qu.:2.000                      Max.   :3.000  </code></pre><ul><li>Marketing 9个新客户，为他们提供一个车型的推荐，最终交付成果是给他们</li></ul><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tableMar[1,])  </code></pre><pre><code>  AGE SEXE TAUX SITUATIONFAMILIALE NBENFANTSACHARGE DEUXIEMEVOITURE1  21    F 1396        celibataire                0           FALSE</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableMar)</code></pre><pre><code>      AGE            SEXE                TAUX        SITUATIONFAMILIALE Min.   :21.00   Length:9           Min.   : 559.0   Length:9           1st Qu.:35.00   Class :character   1st Qu.: 588.0   Class :character   Median :58.00   Mode  :character   Median : 748.0   Mode  :character   Mean   :51.56                      Mean   : 859.7                      3rd Qu.:59.00                      3rd Qu.:1112.0                      Max.   :79.00                      Max.   :1396.0                      NBENFANTSACHARGE DEUXIEMEVOITURE    Min.   :0.0000   Length:9           1st Qu.:0.0000   Class :character   Median :0.0000   Mode  :character   Mean   :0.4444                      3rd Qu.:0.0000                      Max.   :2.0000                     </code></pre><p>将Immatriculation表与Catalogue表合并，可以标记每条数据对应的种类序号</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableIm_f &lt;- merge(tableIm, tableCatalogue, by &#x3D; c(&quot;MARQUE&quot;,&quot;NOM&quot;, &quot;PUISSANCE&quot;, &quot;LONGUEUR&quot;, &quot;NBPORTES&quot;,&quot;COULEUR&quot;,&quot;OCCASION&quot;,&quot;PRIX&quot;))summary(tableIm_f)</code></pre><pre><code>    MARQUE              NOM              PUISSANCE       LONGUEUR         Length:1048575     Length:1048575     Min.   : 55.0   Length:1048575     Class :character   Class :character   1st Qu.: 75.0   Class :character   Mode  :character   Mode  :character   Median :150.0   Mode  :character                                         Mean   :198.9                                                            3rd Qu.:245.0                                                            Max.   :507.0                         NBPORTES       COULEUR            OCCASION              PRIX       Min.   :3.000   Length:1048575     Length:1048575     Min.   :1.000   1st Qu.:5.000   Class :character   Class :character   1st Qu.:1.000   Median :5.000   Mode  :character   Mode  :character   Median :2.000   Mean   :4.868                                         Mean   :1.796   3rd Qu.:5.000                                         3rd Qu.:2.000   Max.   :5.000                                         Max.   :3.000   IMMATRICULATION      NBPLACES.x   NBPLACES.y  CATALOGUEID    Length:1048575     Min.   :5    Min.   :5    Min.   :  1.0   Class :character   1st Qu.:5    1st Qu.:5    1st Qu.: 78.0   Mode  :character   Median :5    Median :5    Median :165.0                      Mean   :5    Mean   :5    Mean   :154.7                      3rd Qu.:5    3rd Qu.:5    3rd Qu.:234.0                      Max.   :5    Max.   :5    Max.   :270.0  </code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tableIm_f[1,])  </code></pre><pre><code>  MARQUE    NOM PUISSANCE LONGUEUR NBPORTES COULEUR OCCASION PRIX1   Audi A2 1.4        75   courte        5   blanc    FALSE    1  IMMATRICULATION NBPLACES.x NBPLACES.y CATALOGUEID1      5874 MF 21          5          5         270</code></pre><h2 id="确定标签"><a href="#确定标签" class="headerlink" title="确定标签"></a>确定标签</h2><p>这一步还是非常重要的，也是熟悉业务的基础。<br>从标签的角度来讲，我们需要知道哪些参数是未来想要被预测的，并且知道他们值的类型，是离散还是连续，是二分类还是多分类；<br>从特征的角度来讲，我们需要去掉对标签毫无影响的特征。<br>由于算法已经封装完整，默认建模后所有输入特征均为变量，所以我们在运行前需要把不相关列给过滤掉。<br>这个项目变量复杂，只列举其中几个需要预测的标签。</p><ul><li>Prix价格，我们将原本离散的价格分成三段，Economique，Moyen,Luxe，法语对应的意思为，经济，中等，奢侈</li><li>Occasion二手，为二分类变量是或否</li><li>Longueur长度，分成四段，coute, longue, moyenne, tres longue,法语对应的意思为，短，长，中等，特长</li><li>Nbportes车门数量，经过后期可视化观察，一共有两种，3车门和5车门（包括行李箱门）</li><li>Couleur颜色，一共有五种，blanc,bleu,gris,noir,rouge。法语对应的意思为白色，蓝色，灰色，黑色，红色。</li></ul><h2 id="Prix价格"><a href="#Prix价格" class="headerlink" title="Prix价格"></a>Prix价格</h2><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>取Immatriculation第八九列，可以得到车牌号对应车的价格</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableImPrix &lt;- tableIm_f[c(8, 9)]print(tableImPrix[1,]) </code></pre><pre><code>  PRIX IMMATRICULATION1    1      5874 MF 21</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">boxplot(tablePrixFinal$PRIX, data&#x3D;tablePrixFinal, main&#x3D;&quot;Distrubution de Prix&quot;, ylab&#x3D;&quot;Prix&quot;)## 通过这个语句刚开始可以看出价格是离散的，但是我们希望他是三分类标签，因此我们需要对其进行重定义</code></pre><pre><code>Error in x[floor(d)] + x[ceiling(d)]: 二进列运算符中有非数值参数Traceback:1. boxplot(tablePrixFinal$PRIX, data = tablePrixFinal, main = &quot;Distrubution de Prix&quot;,  .     ylab = &quot;Prix&quot;)2. boxplot.default(tablePrixFinal$PRIX, data = tablePrixFinal, main = &quot;Distrubution de Prix&quot;,  .     ylab = &quot;Prix&quot;)3. boxplot.stats(unclass(groups[[i]]), range)4. stats::fivenum(x, na.rm = TRUE)</code></pre><p>赋值，将每段赋予所对应的含义</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">table(tableImPrix$PRIX)##J&#39;ai pas touve une methode qui nous permets de realiser la meme fonction de UpdatetableImPrix &lt;- within(tableImPrix,&#123;  PRIX[PRIX &#x3D;&#x3D; 3] &lt;- &quot;Luxe&quot;  PRIX[PRIX &#x3D;&#x3D; 2] &lt;- &quot;Moyen&quot;  PRIX[PRIX &#x3D;&#x3D; 1] &lt;- &quot;Economique&quot;&#125;)</code></pre><pre><code>     1      2      3 355549 551284 141742 </code></pre><p>将所得结果和Clients表合并，可以得到每个用户的信息和所购买车辆的价格的对应关系</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tablePrixFinal &lt;- merge(tableClients, tableImPrix, by &#x3D; &quot;IMMATRICULATION&quot;, incomparables &#x3D; NA)#requête pour la distribution des données: Prixsummary(tablePrixFinal$PRIX)</code></pre><pre><code>   Length     Class      Mode     11082 character character </code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(tablePrixFinal[1,]) </code></pre><pre><code>  IMMATRICULATION AGE SEXE TAUX SITUATIONFAMILIALE NBENFANTSACHARGE1         1 EF 20  18    F  594        celibataire                0  DEUXIEMEVOITURE  PRIX1           FALSE Moyen</code></pre><h3 id="可视化数据"><a href="#可视化数据" class="headerlink" title="可视化数据"></a>可视化数据</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">## attach()在R语言中表示添加路径存储的索引，相当于绑定一个数据框，如果未绑定路径索引，可能导致数据读取错误。## 简单来说固定之后就可以直接通过 数据框中的变量名 来调用数据了attach(tablePrixFinal)qplot(AGE, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)qplot(SEXE, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)qplot(TAUX, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">tablePrixFinal &lt;- subset(tablePrixFinal, select&#x3D;-IMMATRICULATION)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 年龄，性别，税缴和购买车辆价格的关系qplot(AGE, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)qplot(SEXE, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)qplot(TAUX, data&#x3D;tablePrixFinal, fill&#x3D;PRIX)</code></pre><pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre><p><img src="/source/img/Rprojet/output_34_1.png" alt="png"></p><p><img src="/source/img/Rprojet/output_34_2.png" alt="png"></p><p><img src="/source/img/Rprojet/output_34_3.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 年龄，税缴和购买车辆价格的关系qplot(AGE, TAUX, data&#x3D;tablePrixFinal,color&#x3D;PRIX)</code></pre><p><img src="/source/img/Rprojet/output_35_0.png" alt="png"></p><h3 id="划分训练集和验证集"><a href="#划分训练集和验证集" class="headerlink" title="划分训练集和验证集"></a>划分训练集和验证集</h3><p>通常情况下需要按照数据量的大小选择多次cross-validation（交叉验证）<br>本项目测试集为每个单表104万余条数据，选择了五次的交叉验证<br>接下来就以一次交叉验证为例子</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">Prix_EA &lt;- tablePrixFinal[1:7388,]Prix_ET &lt;- tablePrixFinal[7389:11082,]</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 建模前观察变量的类型，如果有不对的，比如数值为string格式，需要提前变回来str(Prix_EA)</code></pre><pre><code>&#39;data.frame&#39;:    7388 obs. of  7 variables: $ AGE               : num  18 33 26 76 20 27 45 28 28 38 ... $ SEXE              : chr  &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; ... $ TAUX              : chr  &quot;594&quot; &quot;1380&quot; &quot;597&quot; &quot;587&quot; ... $ SITUATIONFAMILIALE: chr  &quot;celibataire&quot; &quot;En Couple&quot; &quot;En Couple&quot; &quot;En Couple&quot; ... $ NBENFANTSACHARGE  : num  0 4 0 1 0 0 0 2 2 0 ... $ DEUXIEMEVOITURE   : chr  &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; ... $ PRIX              : chr  &quot;Moyen&quot; &quot;Luxe&quot; &quot;Moyen&quot; &quot;Luxe&quot; ...</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">Prix_EA$TAUX &lt;- as.integer(Prix_EA$TAUX)Prix_ET$TAUX &lt;- as.integer(Prix_ET$TAUX)</code></pre><h3 id="比较三种决策树的性能"><a href="#比较三种决策树的性能" class="headerlink" title="比较三种决策树的性能"></a>比较三种决策树的性能</h3><ul><li>rpart</li><li>c5.0</li><li>CART分类与回归树</li></ul><pre class="line-numbers language-R" data-language="R"><code class="language-R">Prixtree1 &lt;- rpart(PRIX~., Prix_EA)prp(Prixtree1, type&#x3D;4, extra&#x3D;1, box.col&#x3D;c(&quot;tomato&quot;, &quot;skyblue&quot;)[Prixtree1$frame$yval])</code></pre><p><img src="/source/img/Rprojet/output_41_0.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R">Prix_EA$PRIX &lt;- as.factor(Prix_EA$PRIX)Prixtree2 &lt;- C5.0(PRIX~., Prix_EA)plot(Prixtree2, type&#x3D;&quot;simple&quot;)</code></pre><pre><code>Warning message in partysplit(varid = as.integer(i), breaks = as.numeric(j[1]), :&quot;强制改变过程中产生了NA&quot;Warning message in partysplit(varid = as.integer(i), breaks = as.numeric(j[1]), :&quot;强制改变过程中产生了NA&quot;Warning message in partysplit(varid = as.integer(i), breaks = as.numeric(j[1]), :&quot;强制改变过程中产生了NA&quot;Warning message in .bincode(as.numeric(x), breaks = unique(c(-Inf, breaks_split(split), :&quot;强制改变过程中产生了NA&quot;Warning message in .bincode(as.numeric(x), breaks = unique(c(-Inf, breaks_split(split), :&quot;强制改变过程中产生了NA&quot;Warning message in .bincode(as.numeric(x), breaks = unique(c(-Inf, breaks_split(split), :&quot;强制改变过程中产生了NA&quot;</code></pre><p><img src="/source/img/Rprojet/output_42_1.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R">Prixtree3 &lt;- tree(PRIX~., data&#x3D;Prix_EA)plot(Prixtree3)text(Prixtree3, pretty&#x3D;0)</code></pre><pre><code>Warning message in tree(PRIX ~ ., data = Prix_EA):&quot;强制改变过程中产生了NA&quot;</code></pre><p><img src="/source/img/Rprojet/output_43_1.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 应用验证集predPrix.tree1 &lt;- predict(Prixtree1, Prix_ET, type&#x3D;&quot;class&quot;)predPrix.tree2 &lt;- predict(Prixtree2, Prix_ET, type&#x3D;&quot;class&quot;)predPrix.tree3 &lt;- predict(Prixtree3, Prix_ET, type&#x3D;&quot;class&quot;)# 输出混淆矩阵table(Prix_ET$PRIX, predPrix.tree1)table(Prix_ET$PRIX, predPrix.tree2)table(Prix_ET$PRIX, predPrix.tree3)</code></pre><pre><code>Warning message in pred1.tree(object, tree.matrix(newdata)):&quot;强制改变过程中产生了NA&quot;            predPrix.tree1             Economique Luxe Moyen  Economique       1187    1     1  Luxe                1  541   346  Moyen             250   32  1335            predPrix.tree2             Economique Luxe Moyen  Economique       1074    1   114  Luxe                1  537   350  Moyen             115    1  1501            predPrix.tree3             Economique Luxe Moyen  Economique        739    1   449  Luxe               94  551   243  Moyen             197   32  1388</code></pre><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 学习rfPrix &lt;- randomForest(PRIX~., Prix_EA)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 应用验证集rf_classPrix &lt;- predict(rfPrix,Prix_ET, type&#x3D;&quot;response&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 混淆矩阵table(Prix_ET$PRIX, rf_classPrix)</code></pre><pre><code>            rf_classPrix             Economique Luxe Moyen  Economique       1184    1     4  Luxe                1  544   343  Moyen             247   14  1356</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 将结果以概率的形式展现出来rf_probPrix &lt;- predict(rfPrix, Prix_ET, type&#x3D;&quot;prob&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 输出结果为对应的每条数据，三种结果的百分比可能性print(rf_probPrix[1,])  </code></pre><pre><code>Economique       Luxe      Moyen      0.000      0.218      0.782 </code></pre><h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 学习svmPrix &lt;- svm(PRIX~., Prix_EA, probability&#x3D;TRUE)# 应用验证集svm_classPrix &lt;- predict(svmPrix, Prix_ET, type&#x3D;&quot;response&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 混淆矩阵table(Prix_ET$PRIX, svm_classPrix)</code></pre><pre><code>            svm_classPrix             Economique Luxe Moyen  Economique       1187    1     1  Luxe                1  516   371  Moyen             251    6  1360</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 将结果以概率的形式展现出来svm_prob &lt;- predict(svmPrix, Prix_ET, probability&#x3D;TRUE)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 由于支持向量机必须是二分类标签，所以需要做如下操作svm_prob &lt;- attr(svm_prob, &quot;probabilities&quot;)# 转成 data frame svm_prob &lt;- as.data.frame(svm_prob)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 输出结果为对应的每条数据，三种结果的百分比可能性print(svm_prob[1,])  </code></pre><pre><code>         Moyen      Luxe   Economique7389 0.8062865 0.1936253 8.821378e-05</code></pre><h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 学习nbPrix &lt;- naive_bayes(PRIX~., Prix_EA)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 应用验证集nbPrix_class &lt;- predict(nbPrix, Prix_ET, type&#x3D;&quot;class&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 混淆矩阵table( Prix_ET$PRIX, nbPrix_class)</code></pre><pre><code>            nbPrix_class             Economique Luxe Moyen  Economique       1060  103    26  Luxe               37  584   267  Moyen             301  269  1047</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 输出结果为对应的每条数据，三种结果的百分比可能性nbPrix_prob &lt;- predict(nbPrix, Prix_ET, type&#x3D;&quot;prob&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(nbPrix_prob[1,])  </code></pre><pre><code>Economique       Luxe      Moyen  0.1389895  0.2819994  0.5790110 </code></pre><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 学习nnPrix &lt;- nnet(PRIX~., Prix_EA, size&#x3D;12)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 应用验证集nnPrix_class &lt;- predict(nnPrix, Prix_ET, type&#x3D;&quot;class&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 混淆矩阵table(Prix_ET$PRIX, nnPrix_class)</code></pre><pre><code>            nnPrix_class             Moyen  Economique  1189  Luxe         888  Moyen       1617</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 输出结果为对应的每条数据，三种结果的百分比可能性nnPrix_prob &lt;- predict(nnPrix, Prix_ET, type&#x3D;&quot;raw&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(nnPrix_prob[1,])  </code></pre><pre><code>Economique       Luxe      Moyen  0.3256632  0.2581213  0.4162155 </code></pre><h3 id="K近邻"><a href="#K近邻" class="headerlink" title="K近邻"></a>K近邻</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 学习，直接应用于验证集knnPrix &lt;- kknn(PRIX~., Prix_EA, Prix_ET)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 混淆矩阵table(Prix_ET$PRIX, knnPrix$fitted.values)</code></pre><pre><code>             Economique Luxe Moyen  Economique       1105    1    83  Luxe                3  631   254  Moyen             142  203  1272</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 输出结果为对应的每条数据，三种结果的百分比可能性knnPrix_prob &lt;- as.data.frame(knnPrix$prob)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">print(knnPrix_prob[1,])  </code></pre><pre><code>  Economique      Luxe     Moyen1          0 0.5883995 0.4116005</code></pre><h3 id="将表现最好的模型应用于将要预测的数据集"><a href="#将表现最好的模型应用于将要预测的数据集" class="headerlink" title="将表现最好的模型应用于将要预测的数据集"></a>将表现最好的模型应用于将要预测的数据集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 可视化将要验证的数据集View(tableMar) #&#x3D;&#x3D;&#x3D; C5.0 概率&#x3D;&#x3D;&#x3D;#class.treeC50 &lt;- predict(Prixtree2, tableMar, probability&#x3D;TRUE)prob.treeC50 &lt;- attr(class.treeC50, &quot;probabilities&quot;)prob.treeC50 &lt;- as.data.frame(prob.treeC50)resultatPrix &lt;- data.frame(tableMar$ID, class.treeC50, prob.treeC50)#&#x3D;&#x3D;&#x3D; C5.0分类 &#x3D;&#x3D;&#x3D;#class.treeC50 &lt;- predict(Prixtree2, tableMar, type&#x3D;&quot;class&quot;)prob.treeC50 &lt;- predict(Prixtree2, tableMar, type&#x3D;&quot;prob&quot;)resultatPrix &lt;- data.frame(tableMar, class.treeC50, prob.treeC50)resultatPrix &lt;- data.frame(tableMar, class.treeC50)# 重命名预测列名称names(resultatPrix)[7] &lt;- &quot;PRIX&quot;# 将结果保存到csv文件write.table(resultat1, file&#x3D;&#39;predictions.csv&#39;, sep&#x3D;&quot;\t&quot;, dec&#x3D;&quot;.&quot;, row.names &#x3D; F)</code></pre><h2 id="Occasion二手"><a href="#Occasion二手" class="headerlink" title="Occasion二手"></a>Occasion二手</h2><h3 id="数据准备-1"><a href="#数据准备-1" class="headerlink" title="数据准备"></a>数据准备</h3><p>取Immatriculation第七九列，可以得到车牌号对应车的价格</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableImOCCA &lt;- tableIm_f[c(7, 9)]print(tableImOCCA[1,]) </code></pre><pre><code>  OCCASION IMMATRICULATION1    FALSE      5874 MF 21</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 将所得结果和Clients表合并，可以得到每个用户的信息和所购买车辆的二手情况的对应关系tableOCCAFinal &lt;- merge(tableClients, tableImOCCA, by &#x3D; &quot;IMMATRICULATION&quot;, incomparables &#x3D; NA)## 建模前观察变量的类型，如果有不对的，比如数值为string格式，需要提前变回来str(tableOCCAFinal)tableOCCAFinal$TAUX &lt;- as.integer(tableOCCAFinal$TAUX)</code></pre><pre><code>&#39;data.frame&#39;:    11082 obs. of  8 variables: $ IMMATRICULATION   : chr  &quot;1 EF 20&quot; &quot;10 ZM 12&quot; &quot;100 XL 72&quot; &quot;100 YT 70&quot; ... $ AGE               : num  18 33 26 76 20 27 45 28 28 38 ... $ SEXE              : chr  &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; ... $ TAUX              : chr  &quot;594&quot; &quot;1380&quot; &quot;597&quot; &quot;587&quot; ... $ SITUATIONFAMILIALE: chr  &quot;celibataire&quot; &quot;En Couple&quot; &quot;En Couple&quot; &quot;En Couple&quot; ... $ NBENFANTSACHARGE  : num  0 4 0 1 0 0 0 2 2 0 ... $ DEUXIEMEVOITURE   : chr  &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; ... $ OCCASION          : chr  &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;TRUE&quot; ...</code></pre><h3 id="可视化数据-1"><a href="#可视化数据-1" class="headerlink" title="可视化数据"></a>可视化数据</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">library(ggplot2)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">qplot(OCCASION, data&#x3D;tableOCCAFinal)table(tableOCCAFinal$DEUXIEMEVOITURE,tableOCCAFinal$OCCASION)qplot(DEUXIEMEVOITURE, data&#x3D;tableOCCAFinal, color&#x3D;OCCASION)qplot(TAUX, data&#x3D;tableOCCAFinal, fill&#x3D;OCCASION, bins &#x3D;5)boxplot(AGE~OCCASION, data&#x3D;tableOCCAFinal, col&#x3D;c(&quot;red&quot;,&quot;blue&quot;))qplot(SEXE, data&#x3D;tableOCCAFinal, color&#x3D;OCCASION)</code></pre><pre><code>        FALSE TRUE  FALSE  8408 1276  TRUE   1234  164</code></pre><p><img src="/source/img/Rprojet/output_82_1.png" alt="png"></p><p><img src="/source/img/Rprojet/output_82_2.png" alt="png"></p><p><img src="/source/img/Rprojet/output_82_3.png" alt="png"></p><p><img src="/source/img/Rprojet/output_82_4.png" alt="png"></p><p><img src="/source/img/Rprojet/output_82_5.png" alt="png"></p><h3 id="划分训练集和验证集-1"><a href="#划分训练集和验证集-1" class="headerlink" title="划分训练集和验证集"></a>划分训练集和验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableOCCAFinal &lt;- subset(tableOCCAFinal, select&#x3D;-IMMATRICULATION)OCCA_EA &lt;- tableOCCAFinal[1:7388,]OCCA_ET &lt;- tableOCCAFinal[7389:11082,]</code></pre><h3 id="应用三种决策树和五种机器学习算法"><a href="#应用三种决策树和五种机器学习算法" class="headerlink" title="应用三种决策树和五种机器学习算法"></a>应用三种决策树和五种机器学习算法</h3><p>和之前价格的例子一样，我们对该训练集应用三种决策树和五种机器学习算法</p><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 3种决策树OCCAtree1 &lt;- rpart(OCCASION~., OCCA_EA)OCCA_EA$OCCASION &lt;- as.factor(OCCA_EA$OCCASION)OCCAtree2 &lt;- C5.0(OCCASION~., OCCA_EA)OCCAtree3 &lt;- tree(OCCASION~., data&#x3D;OCCA_EA)# 随机森林rfOCCA &lt;- randomForest(OCCASION~., OCCA_EA)# 支持向量机svmOCCA &lt;- svm(OCCASION~., OCCA_EA, probability&#x3D;TRUE)# 朴素贝叶斯nbOCCA &lt;- naive_bayes(OCCASION~., OCCA_EA)# 神经网络nnOCCA &lt;- nnet(OCCASION~., OCCA_EA, size&#x3D;12)# K近邻knnOCCA &lt;- kknn(OCCASION~., OCCA_EA, OCCA_ET)</code></pre><h3 id="将学习好的模型应用于验证集"><a href="#将学习好的模型应用于验证集" class="headerlink" title="将学习好的模型应用于验证集"></a>将学习好的模型应用于验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 应用于验证集，k近邻算法在训练时已经得到了结果predOCCA.tree1 &lt;- predict(OCCAtree1, OCCA_ET, type&#x3D;&quot;class&quot;)predOCCA.tree2 &lt;- predict(OCCAtree2, OCCA_ET, type&#x3D;&quot;class&quot;)predOCCA.tree3 &lt;- predict(OCCAtree3, OCCA_ET, type&#x3D;&quot;class&quot;)result.rfOCCA &lt;- predict(rfOCCA,OCCA_ET, type&#x3D;&quot;response&quot;)result.svmOCCA &lt;- predict(svmOCCA,OCCA_ET, type&#x3D;&quot;response&quot;)result.treeNaiveOCCA &lt;- predict(nbOCCA,OCCA_ET, type&#x3D;&quot;class&quot;)result.treeNnetOCCA &lt;- predict(nnOCCA, OCCA_ET,type&#x3D;&quot;class&quot;)</code></pre><h3 id="混淆矩阵对比"><a href="#混淆矩阵对比" class="headerlink" title="混淆矩阵对比"></a>混淆矩阵对比</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">table(OCCA_ET$OCCASION, predOCCA.tree1)table(OCCA_ET$OCCASION, predOCCA.tree2)table(OCCA_ET$OCCASION, predOCCA.tree3)table(OCCA_ET$OCCASION, result.rfOCCA)table(OCCA_ET$OCCASION, result.svmOCCA)table(OCCA_ET$OCCASION, result.treeNaiveOCCA)table(OCCA_ET$OCCASION, result.treeNnetOCCA)table(OCCA_ET$OCCASION, knnOCCA$fitted.values)</code></pre><pre><code>       predOCCA.tree1        FALSE TRUE  FALSE  3189   37  TRUE    290  178       predOCCA.tree2        FALSE TRUE  FALSE  3189   37  TRUE    290  178       predOCCA.tree3        FALSE TRUE  FALSE  3189   37  TRUE    290  178       result.rfOCCA        FALSE TRUE  FALSE  3181   45  TRUE    290  178       result.svmOCCA        FALSE TRUE  FALSE  3186   40  TRUE    307  161       result.treeNaiveOCCA        FALSE TRUE  FALSE  2518  708  TRUE      2  466       result.treeNnetOCCA        FALSE  FALSE  3226  TRUE    468               FALSE TRUE  FALSE  3020  206  TRUE    228  240</code></pre><h3 id="ROC曲线和AUC对比"><a href="#ROC曲线和AUC对比" class="headerlink" title="ROC曲线和AUC对比"></a>ROC曲线和AUC对比</h3><p>在画出ROC曲线前，我们需要把所有的模型转成概率形式</p><pre class="line-numbers language-R" data-language="R"><code class="language-R"># Test du classifieur : probabilites pour chaque predictionp.treeRpartOCCA &lt;- predict(OCCAtree1, OCCA_ET, type&#x3D;&quot;prob&quot;)roc.predOCCA1 &lt;- prediction(p.treeRpartOCCA[,2], OCCA_ET$OCCASION)p.treec50OCCA &lt;- predict(OCCAtree2, OCCA_ET, type&#x3D;&quot;prob&quot;)roc.predOCCA2 &lt;- prediction(p.treec50OCCA[,2], OCCA_ET$OCCASION)p.treeTreeOCCA &lt;- predict(OCCAtree3, OCCA_ET, type&#x3D;&quot;vector&quot;)roc.predOCCA3 &lt;- prediction(p.treeTreeOCCA[,2], OCCA_ET$OCCASION)rf_probOCCA &lt;- predict(rfOCCA, OCCA_ET, type&#x3D;&quot;prob&quot;)roc.predOCCA4 &lt;- prediction(rf_probOCCA[,2], OCCA_ET$OCCASION)svm_probOCCA &lt;- predict(svmOCCA, OCCA_ET, probability&#x3D;TRUE)svm_probOCCA &lt;- attr(svm_probOCCA, &quot;probabilities&quot;)svm_probOCCA &lt;- as.data.frame(svm_probOCCA)roc.predOCCA5 &lt;- prediction(svm_probOCCA[,2], OCCA_ET$OCCASION)nb_probOCCA &lt;- predict(nbOCCA, OCCA_ET, type&#x3D;&quot;prob&quot;)roc.predOCCA6 &lt;- prediction(nb_probOCCA[,2], OCCA_ET$OCCASION)nn_probOCCA &lt;- predict(nnOCCA, OCCA_ET, type&#x3D;&quot;raw&quot;)roc.predOCCA7 &lt;- prediction(nn_probOCCA[,1], OCCA_ET$OCCASION)knn_probOCCA &lt;- as.data.frame(knnOCCA$prob)roc.predOCCA8 &lt;- prediction(knn_probOCCA[,2], OCCA_ET$OCCASION)</code></pre><pre><code>Warning message in pred1.tree(object, tree.matrix(newdata)):&quot;强制改变过程中产生了NA&quot;Warning message:&quot;predict.naive_bayes(): more features in the newdata are provided as there are probability tables in the object. Calculation is performed based on features to be found in the tables.&quot;</code></pre><p>然后计算出AUC指数</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">auc.treeOCCA1 &lt;- performance(roc.predOCCA1, &quot;auc&quot;)auc.treeOCCA2 &lt;- performance(roc.predOCCA2, &quot;auc&quot;)auc.treeOCCA3 &lt;- performance(roc.predOCCA3, &quot;auc&quot;)auc.treeOCCA4 &lt;- performance(roc.predOCCA4, &quot;auc&quot;)auc.treeOCCA5 &lt;- performance(roc.predOCCA5, &quot;auc&quot;)auc.treeOCCA6 &lt;- performance(roc.predOCCA6, &quot;auc&quot;)auc.treeOCCA7 &lt;- performance(roc.predOCCA7, &quot;auc&quot;)auc.treeOCCA8 &lt;- performance(roc.predOCCA8, &quot;auc&quot;)attr(auc.treeOCCA1, &quot;y.values&quot;)attr(auc.treeOCCA2, &quot;y.values&quot;)attr(auc.treeOCCA3, &quot;y.values&quot;)attr(auc.treeOCCA4, &quot;y.values&quot;)attr(auc.treeOCCA5, &quot;y.values&quot;)attr(auc.treeOCCA6, &quot;y.values&quot;)attr(auc.treeOCCA7, &quot;y.values&quot;)attr(auc.treeOCCA8, &quot;y.values&quot;)</code></pre><ol>    <li>0.924155896800038</li></ol><ol>    <li>0.924155896800038</li></ol><ol>    <li>0.924155896800038</li></ol><ol>    <li>0.9247705607749</li></ol><ol>    <li>0.920831213802376</li></ol><ol>    <li>0.924622524785262</li></ol><ol>    <li>0.5</li></ol><ol>    <li>0.903374558210268</li></ol><h3 id="画出ROC曲线，根据AUC指数选择该标签最适合的算法"><a href="#画出ROC曲线，根据AUC指数选择该标签最适合的算法" class="headerlink" title="画出ROC曲线，根据AUC指数选择该标签最适合的算法"></a>画出ROC曲线，根据AUC指数选择该标签最适合的算法</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">roc.perfOCCA1 &lt;- performance(roc.predOCCA1,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA2 &lt;- performance(roc.predOCCA2,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA3 &lt;- performance(roc.predOCCA3,&quot;tpr&quot;,&quot;fpr&quot;)roc_perfOCCA4 &lt;- performance(roc.predOCCA4,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA5 &lt;- performance(roc.predOCCA5,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA6 &lt;- performance(roc.predOCCA6,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA7 &lt;- performance(roc.predOCCA7,&quot;tpr&quot;,&quot;fpr&quot;)roc.perfOCCA8 &lt;- performance(roc.predOCCA8,&quot;tpr&quot;,&quot;fpr&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># Courbe ROCplot(roc.perfOCCA1, col &#x3D; &quot;green&quot;)plot(roc.perfOCCA2, col &#x3D; &quot;red&quot;, add&#x3D;TRUE)plot(roc.perfOCCA3, col &#x3D; &quot;blue&quot;, add&#x3D;TRUE)plot(roc_perfOCCA4, add &#x3D; TRUE, col &#x3D; &quot;magenta&quot;)plot(roc.perfOCCA5, add &#x3D; TRUE, col &#x3D; &quot;darkorange&quot;)plot(roc.perfOCCA6, add &#x3D; TRUE, col &#x3D; &quot;darkgreen&quot;)plot(roc.perfOCCA7, add &#x3D; TRUE, col &#x3D; &quot;black&quot;)plot(roc.perfOCCA8, add &#x3D; TRUE, col &#x3D; &quot;darkmagenta&quot;)</code></pre><p><img src="/source/img/Rprojet/output_98_0.png" alt="png"></p><h3 id="将表现最好的模型应用于将要预测的数据集-1"><a href="#将表现最好的模型应用于将要预测的数据集-1" class="headerlink" title="将表现最好的模型应用于将要预测的数据集"></a>将表现最好的模型应用于将要预测的数据集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">#&#x3D;&#x3D;&#x3D; RANDOM FORESTS &#x3D;&#x3D;&#x3D;#class.treerfOCCA &lt;- predict(rfOCCA, tableMar, probability&#x3D;TRUE)resultatOCCA &lt;- data.frame(tableMar, class.treerfOCCA)# Renommage de la colonne des classes preditesnames(resultatOCCA)[7] &lt;- &quot;OCCASION&quot;</code></pre><h2 id="NBPortes车门数量"><a href="#NBPortes车门数量" class="headerlink" title="NBPortes车门数量"></a>NBPortes车门数量</h2><h3 id="数据准备-2"><a href="#数据准备-2" class="headerlink" title="数据准备"></a>数据准备</h3><p>取Immatriculation第五九列，可以得到车牌号对应车的车门数</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableImNP&lt;- tableIm_f[c(5,9)]print(tableImNP[1,]) </code></pre><pre><code>  NBPORTES IMMATRICULATION1        5      5874 MF 21</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 将所得结果和Clients表合并，可以得到每个用户的信息和所购买车辆的车门数量的对应关系tableFinal_np&lt;- merge(tableClients, tableImNP,by&#x3D; &quot;IMMATRICULATION&quot;, incomparables &#x3D;NA)print(tableFinal_np[1,]) </code></pre><pre><code>  IMMATRICULATION AGE SEXE TAUX SITUATIONFAMILIALE NBENFANTSACHARGE1         1 EF 20  18    F  594        celibataire                0  DEUXIEMEVOITURE NBPORTES1           FALSE        5</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableFinal_np$NBPORTES)</code></pre><pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.   3.000   5.000   5.000   4.951   5.000   5.000 </code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 建模前观察变量的类型，如果有不对的，比如数值为string格式，需要提前变回来NBPORTES_EA$TAUX &lt;- as.integer(NBPORTES_EA$TAUX)NBPORTES_ET$TAUX &lt;- as.integer(NBPORTES_ET$TAUX)</code></pre><h3 id="可视化数据-2"><a href="#可视化数据-2" class="headerlink" title="可视化数据"></a>可视化数据</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">attach(tableFinal_np)tableFinal_np&lt;-subset(tableFinal_np, select &#x3D; -IMMATRICULATION)qplot(NBPORTES, data&#x3D;tableFinal_np)qplot(SEXE,data&#x3D;tableFinal_np, fill&#x3D;NBPORTES)qplot(NBENFANTSACHARGE,data&#x3D;tableFinal_np, fill&#x3D;NBPORTES)qplot(TAUX,data&#x3D;tableFinal_np, fill&#x3D;NBPORTES, bins&#x3D;5)qplot(DEUXIEMEVOITURE, data&#x3D;tableFinal_np, fill&#x3D;NBPORTES)qplot(SITUATIONFAMILIALE, data&#x3D;tableFinal_np, fill&#x3D;NBPORTES)boxplot(AGE~NBPORTES, data&#x3D;tableFinal_np, col&#x3D;c(&quot;red&quot;,&quot;blue&quot;))</code></pre><p><img src="/source/img/Rprojet/output_108_0.png" alt="png"></p><pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre><p><img src="/source/img/Rprojet/output_108_2.png" alt="png"></p><pre><code>Warning message:&quot;Ignoring unknown parameters: bins&quot;</code></pre><p><img src="/source/img/Rprojet/output_108_4.png" alt="png"></p><p><img src="/source/img/Rprojet/output_108_5.png" alt="png"></p><p><img src="/source/img/Rprojet/output_108_6.png" alt="png"></p><p><img src="/source/img/Rprojet/output_108_7.png" alt="png"></p><p><img src="/source/img/Rprojet/output_108_8.png" alt="png"></p><h3 id="划分训练集和验证集-2"><a href="#划分训练集和验证集-2" class="headerlink" title="划分训练集和验证集"></a>划分训练集和验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">NBPORTES_EA &lt;- tableFinal_np[1:7388,]NBPORTES_ET &lt;- tableFinal_np[7389:11082,]</code></pre><h3 id="应用三种决策树和五种机器学习算法-1"><a href="#应用三种决策树和五种机器学习算法-1" class="headerlink" title="应用三种决策树和五种机器学习算法"></a>应用三种决策树和五种机器学习算法</h3><p>和之前价格的例子一样，我们对该训练集应用三种决策树和五种机器学习算法</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">NBPORTESTree1&lt;-rpart(NBPORTES~., NBPORTES_EA)NBPORTESTree2&lt;-C5.0(NBPORTES~., NBPORTES_EA)NBPORTESTree3&lt;-tree(NBPORTES~., data&#x3D;NBPORTES_EA)rfNP&lt;-randomForest(NBPORTES~., NBPORTES_EA)svmNP&lt;-svm(NBPORTES~., NBPORTES_EA,probability&#x3D;TRUE)nbNP&lt;-naive_bayes(NBPORTES~., NBPORTES_EA)nnNP&lt;-nnet(NBPORTES~., NBPORTES_EA,size&#x3D;12)knnNP&lt;-kknn(NBPORTES~., NBPORTES_EA,NBPORTES_ET)</code></pre><h3 id="将学习好的模型应用于验证集-1"><a href="#将学习好的模型应用于验证集-1" class="headerlink" title="将学习好的模型应用于验证集"></a>将学习好的模型应用于验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 应用于验证集，k近邻算法在训练时已经得到了结果predNBPORTES.tree1 &lt;- predict(NBPORTESTree1, NBPORTES_ET, type&#x3D;&quot;vector&quot;)predNBPORTES.tree2 &lt;- predict(NBPORTESTree2, NBPORTES_ET, type&#x3D;&quot;class&quot;)predNBPORTES.tree3 &lt;- predict(NBPORTESTree3, NBPORTES_ET, type&#x3D;&quot;class&quot;)rf_classNP&lt;-predict(rfNP,NBPORTES_EA,type &#x3D; &quot;response&quot;)svm_classNP&lt;-predict(svmNP,NBPORTES_ET,type &#x3D; &quot;response&quot;)nbNP_class&lt;-predict(nbNP,NBPORTES_ET,type &#x3D; &quot;class&quot;)nnNP_class&lt;-predict(nnNP,NBPORTES_ET, TYPE&#x3D;&quot;class&quot;)</code></pre><h3 id="混淆矩阵对比-1"><a href="#混淆矩阵对比-1" class="headerlink" title="混淆矩阵对比"></a>混淆矩阵对比</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">table(NBPORTES_ET$NBPORTES,predNBPORTES.tree1)table(NBPORTES_ET$NBPORTES,predNBPORTES.tree2)table(NBPORTES_ET$NBPORTES,predNBPORTES.tree3)table(NBPORTES_EA$NBPORTES,rf_classNP)table(NBPORTES_ET$NBPORTES,svm_classNP)table(NBPORTES_ET$NBPORTES,nbNP_class)table(NBPORTES_ET$NBPORTES,nnNP_class)table(NBPORTES_ET$NBPORTES,knnNP$fitted.values)</code></pre><pre><code>   predNBPORTES.tree1    1.63414634146341 1.8323782234957 1.99980525803311    2  3               31              58                2    0  5               65             275             2518  745   predNBPORTES.tree2       1    2  3    0   91  5    0 3603   predNBPORTES.tree3       1    2  3    0   91  5    0 3603   rf_classNP       1    2  1   24  154  2    0 7210   svm_classNP       1    2  3    0   91  5    0 3603   nbNP_class       1    2  3   64   27  5  268 3335   nnNP_class    0.975906842537507  3                91  5              3603          1    2  3    9   82  5   34 3569</code></pre><h3 id="ROC曲线和AUC对比-1"><a href="#ROC曲线和AUC对比-1" class="headerlink" title="ROC曲线和AUC对比"></a>ROC曲线和AUC对比</h3><p>在画出ROC曲线前，我们需要把所有的模型转成概率形式</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">pNP.tree1&lt;-predict(NBPORTESTree1,NBPORTES_ET,type &#x3D; &quot;vector&quot;)rocNP.pred1&lt;-prediction(pNP.tree1,NBPORTES_ET$NBPORTES)pNP.tree2&lt;-predict(NBPORTESTree2,NBPORTES_ET,type &#x3D; &quot;prob&quot;)rocNP.pred2&lt;-prediction(pNP.tree2[,2],NBPORTES_ET$NBPORTES)pNP.tree3&lt;-predict(NBPORTESTree3,NBPORTES_ET,type &#x3D; &quot;vector&quot;)rocNP.pred3&lt;-prediction(pNP.tree3[,2],NBPORTES_ET$NBPORTES)rf_probNP&lt;-predict(rfNP,NBPORTES_ET, type &#x3D; &quot;prob&quot; )rf_predNP&lt;-prediction(rf_probNP[,2],NBPORTES_ET$NBPORTES)svm_prob&lt;-predict(svmNP,NBPORTES_ET,probability&#x3D;TRUE)svm_prob&lt;-attr(svm_prob,&quot;probabilities&quot;)svm_prob&lt;-as.data.frame(svm_prob)svm_pred&lt;-prediction(svm_prob[,2],NBPORTES_ET$NBPORTES)nbNP_prob&lt;-predict(nbNP,NBPORTES_ET,type&#x3D;&quot;prob&quot;)nbNP_pred&lt;-prediction(nbNP_prob[,2],NBPORTES_ET$NBPORTES)nnNP_prob&lt;-predict(nnNP,NBPORTES_ET,type &#x3D; &quot;raw&quot;)nnNP_pred&lt;-prediction(nnNP_prob,NBPORTES_ET$NBPORTES)knnNP_prob&lt;-as.data.frame(knnNP$prob)knnNP_pred&lt;-prediction(knnNP_prob[,2],NBPORTES_ET$NBPORTES)</code></pre><p>然后计算出AUC指数</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">aucNP.tree1&lt;-performance(rocNP.pred1,&quot;auc&quot;)aucNP.tree2&lt;-performance(rocNP.pred2,&quot;auc&quot;)aucNP.tree3&lt;-performance(rocNP.pred3,&quot;auc&quot;)rf_aucNP&lt;-performance(rf_predNP,&quot;auc&quot;)svm_aucNP&lt;-performance(svm_pred,&quot;auc&quot;)nbNP_aucNP&lt;-performance(nbNP_pred,&quot;auc&quot;)nnNP_aucNP&lt;-performance(nnNP_pred,&quot;auc&quot;)knnNP_aucNP&lt;-performance(knnNP_pred,&quot;auc&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">attr(aucNP.tree1,&quot;y.values&quot;)attr(aucNP.tree2,&quot;y.values&quot;)attr(aucNP.tree3,&quot;y.values&quot;)attr(rf_aucNP,&quot;y.values&quot;)attr(svm_aucNP,&quot;y.values&quot;)attr(nbNP_aucNP,&quot;y.values&quot;)attr(nnNP_aucNP,&quot;y.values&quot;)attr(knnNP_aucNP,&quot;y.values&quot;)</code></pre><ol>    <li>0.951351590402381</li></ol><ol>    <li>0.5</li></ol><ol>    <li>0.903157625056043</li></ol><ol>    <li>0.891982566420535</li></ol><ol>    <li>0.0633049991917602</li></ol><ol>    <li>0.93451122843296</li></ol><ol>    <li>0.5</li></ol><ol>    <li>0.85450006557417</li></ol><h3 id="画出ROC曲线，根据AUC指数选择该标签最适合的算法-1"><a href="#画出ROC曲线，根据AUC指数选择该标签最适合的算法-1" class="headerlink" title="画出ROC曲线，根据AUC指数选择该标签最适合的算法"></a>画出ROC曲线，根据AUC指数选择该标签最适合的算法</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">rocNP.pref1&lt;-performance(rocNP.pred1,&quot;tpr&quot;,&quot;fpr&quot;)rocNP.pref2&lt;-performance(rocNP.pred2,&quot;tpr&quot;,&quot;fpr&quot;)  rocNP.pref3&lt;-performance(rocNP.pred3,&quot;tpr&quot;,&quot;fpr&quot;) rf_prefNP&lt;-performance(rf_predNP,&quot;tpr&quot;,&quot;fpr&quot;)svm_pref&lt;-performance(rf_predNP,&quot;tpr&quot;,&quot;fpr&quot;)nbNP_pref&lt;-performance(nbNP_pred,&quot;tpr&quot;,&quot;fpr&quot;)nnNP_pref&lt;-performance(nnNP_pred,&quot;tpr&quot;,&quot;fpr&quot;)knnNP_pref&lt;-performance(knnNP_pred,&quot;tpr&quot;,&quot;fpr&quot;)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">plot(rocNP.pref1,col&#x3D;&quot;green&quot;)plot(rocNP.pref2,add &#x3D; TRUE,col&#x3D;&quot;blue&quot;)plot(rocNP.pref3,add &#x3D; TRUE,col&#x3D;&quot;red&quot;)plot(rf_prefNP,add &#x3D; TRUE, col&#x3D;&quot;yellow&quot;)plot(svm_pref,add &#x3D; TRUE, col&#x3D;&quot;black&quot;)plot(nbNP_pref,add &#x3D; TRUE, col&#x3D;&quot;purple&quot;)plot(nnNP_pref,add &#x3D; TRUE, col&#x3D;&quot;orange&quot;)plot(nnNP_pref,add &#x3D; TRUE, col&#x3D;&quot;black&quot;)</code></pre><p><img src="/source/img/Rprojet/output_124_0.png" alt="png"></p><h3 id="将表现最好的模型应用于将要预测的数据集-2"><a href="#将表现最好的模型应用于将要预测的数据集-2" class="headerlink" title="将表现最好的模型应用于将要预测的数据集"></a>将表现最好的模型应用于将要预测的数据集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">class.treerpartNB &lt;- predict(nbNP, tableMar, probability&#x3D;TRUE)resultatNB &lt;- data.frame(tableMar, class.treerpartNB)# Renommage de la colonne des classes preditesnames(resultatNB)[7] &lt;- &quot;NBPORTES&quot;</code></pre><h2 id="Longueur车长"><a href="#Longueur车长" class="headerlink" title="Longueur车长"></a>Longueur车长</h2><h3 id="数据准备-3"><a href="#数据准备-3" class="headerlink" title="数据准备"></a>数据准备</h3><p>取Immatriculation第四九列，可以得到车牌号对应车的车长</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableImLG &lt;- tableIm_f[c(4, 9)]tableLGFinal &lt;- merge(tableClients, tableImLG, by &#x3D; &quot;IMMATRICULATION&quot;, incomparables &#x3D; NA)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">## 更改变量类型str(tableLGFinal)tableLGFinal$TAUX &lt;- as.integer(tableLGFinal$TAUX)## 剔除不需要的列tableLGFinal &lt;- subset(tableLGFinal, select&#x3D;-IMMATRICULATION)</code></pre><pre><code>&#39;data.frame&#39;:    11082 obs. of  8 variables: $ IMMATRICULATION   : chr  &quot;1 EF 20&quot; &quot;10 ZM 12&quot; &quot;100 XL 72&quot; &quot;100 YT 70&quot; ... $ AGE               : num  18 33 26 76 20 27 45 28 28 38 ... $ SEXE              : chr  &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; ... $ TAUX              : chr  &quot;594&quot; &quot;1380&quot; &quot;597&quot; &quot;587&quot; ... $ SITUATIONFAMILIALE: chr  &quot;celibataire&quot; &quot;En Couple&quot; &quot;En Couple&quot; &quot;En Couple&quot; ... $ NBENFANTSACHARGE  : num  0 4 0 1 0 0 0 2 2 0 ... $ DEUXIEMEVOITURE   : chr  &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; ... $ LONGUEUR          : chr  &quot;moyenne&quot; &quot;tres longue&quot; &quot;tres longue&quot; &quot;tres longue&quot; ...</code></pre><h3 id="可视化数据-3"><a href="#可视化数据-3" class="headerlink" title="可视化数据"></a>可视化数据</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 从可视化可以大致看出相关性，如果变量相关性很好，那么出来的模型准确率越高library(ggplot2)qplot(LONGUEUR, data&#x3D;tableLGFinal)table(tableLGFinal$DEUXIEMEVOITURE,tableLGFinal$LONGUEUR)qplot(DEUXIEMEVOITURE, data&#x3D;tableLGFinal, color&#x3D;LONGUEUR)</code></pre><pre><code>        courte longue moyenne tres longue  FALSE   2569   3009     777        3329  TRUE     944      0       0         454</code></pre><p><img src="/source/img/Rprojet/output_132_1.png" alt="png"></p><p><img src="/source/img/Rprojet/output_132_2.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R">qplot(TAUX, data&#x3D;tableLGFinal, fill&#x3D;LONGUEUR, bins &#x3D;5)boxplot(AGE~LONGUEUR, data&#x3D;tableLGFinal, col&#x3D;c(&quot;red&quot;,&quot;blue&quot;))</code></pre><p><img src="/source/img/Rprojet/output_133_0.png" alt="png"></p><p><img src="/source/img/Rprojet/output_133_1.png" alt="png"></p><pre class="line-numbers language-R" data-language="R"><code class="language-R">qplot(SEXE, data&#x3D;tableLGFinal, color&#x3D;LONGUEUR)</code></pre><p><img src="/source/img/Rprojet/output_134_0.png" alt="png"></p><h3 id="划分训练集和验证集-3"><a href="#划分训练集和验证集-3" class="headerlink" title="划分训练集和验证集"></a>划分训练集和验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">LG_EA &lt;- tableLGFinal[1:7388,]LG_ET &lt;- tableLGFinal[7389:11082,]LG_EA$LONGUEUR &lt;- as.factor(LG_EA$LONGUEUR)</code></pre><h3 id="应用三种决策树和五种机器学习算法-2"><a href="#应用三种决策树和五种机器学习算法-2" class="headerlink" title="应用三种决策树和五种机器学习算法"></a>应用三种决策树和五种机器学习算法</h3><p>和之前价格的例子一样，我们对该训练集应用三种决策树和五种机器学习算法</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">LGtree1 &lt;- rpart(LONGUEUR~., LG_EA)LGtree2 &lt;- C5.0(LONGUEUR~., LG_EA)LGtree3 &lt;- tree(LONGUEUR~., data&#x3D;LG_EA)rfLG &lt;- randomForest(LONGUEUR~., LG_EA)svmLG &lt;- svm(LONGUEUR~., LG_EA, probability&#x3D;TRUE)nbLG &lt;- naive_bayes(LONGUEUR~., LG_EA)nnLG &lt;- nnet(LONGUEUR~., LG_EA, size&#x3D;12)knnLG &lt;- kknn(LONGUEUR~., LG_EA, LG_ET)</code></pre><pre><code>Warning message in tree(LONGUEUR ~ ., data = LG_EA):&quot;强制改变过程中产生了NA&quot;Warning message:&quot;naive_bayes(): Feature SITUATIONFAMILIALE - zero probabilities are present. Consider Laplace smoothing.&quot;Warning message:&quot;naive_bayes(): Feature DEUXIEMEVOITURE - zero probabilities are present. Consider Laplace smoothing.&quot;# weights:  184initial  value 12969.213412 iter  10 value 9469.911371iter  20 value 9305.689396iter  30 value 8970.449826iter  40 value 8689.100430iter  50 value 8419.405933iter  60 value 8266.730127iter  70 value 8167.329971iter  80 value 7592.378033iter  90 value 7546.309856iter 100 value 7458.459896final  value 7458.459896 stopped after 100 iterations</code></pre><h3 id="将学习好的模型应用于验证集-2"><a href="#将学习好的模型应用于验证集-2" class="headerlink" title="将学习好的模型应用于验证集"></a>将学习好的模型应用于验证集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">predLG.tree1 &lt;- predict(LGtree1, LG_ET, type&#x3D;&quot;class&quot;)predLG.tree2 &lt;- predict(LGtree2, LG_ET, type&#x3D;&quot;class&quot;)predLG.tree3 &lt;- predict(LGtree3, LG_ET, type&#x3D;&quot;class&quot;)result.rfLG &lt;- predict(rfLG,LG_ET, type&#x3D;&quot;response&quot;)result.svmLG &lt;- predict(svmLG,LG_ET, type&#x3D;&quot;response&quot;)result.treeNaiveLG &lt;- predict(nbLG,LG_ET, type&#x3D;&quot;class&quot;)result.treeNnetLG &lt;- predict(nnLG, LG_ET,type&#x3D;&quot;class&quot;)</code></pre><pre><code>Warning message in pred1.tree(object, tree.matrix(newdata)):&quot;强制改变过程中产生了NA&quot;Warning message:&quot;predict.naive_bayes(): more features in the newdata are provided as there are probability tables in the object. Calculation is performed based on features to be found in the tables.&quot;</code></pre><h3 id="混淆矩阵对比-2"><a href="#混淆矩阵对比-2" class="headerlink" title="混淆矩阵对比"></a>混淆矩阵对比</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">table(LG_ET$LONGUEUR, predLG.tree1)table(LG_ET$LONGUEUR, predLG.tree2)table(LG_ET$LONGUEUR, predLG.tree3)table(LG_ET$LONGUEUR, result.rfLG)table(LG_ET$LONGUEUR, result.svmLG)table(LG_ET$LONGUEUR, result.treeNaiveLG)table(LG_ET$LONGUEUR, result.treeNnetLG)table(LG_ET$LONGUEUR, knnLG$fitted.values)</code></pre><pre><code>             predLG.tree1              courte longue moyenne tres longue  courte        1166      1       0           1  longue           1   1021       0           0  moyenne        270      0       0           0  tres longue      1    493       0         740             predLG.tree2              courte longue moyenne tres longue  courte        1166      1       0           1  longue           1   1021       0           0  moyenne        270      0       0           0  tres longue      1    493       0         740             predLG.tree3              courte longue moyenne tres longue  courte         940    227       0           1  longue         304    675       0          43  moyenne        270      0       0           0  tres longue    163    310       0         761             result.rfLG              courte longue moyenne tres longue  courte        1156      1      10           1  longue           1   1015       0           6  moyenne        261      0       9           0  tres longue      1    493       0         740             result.svmLG              courte longue moyenne tres longue  courte        1166      1       0           1  longue           2   1020       0           0  moyenne        270      0       0           0  tres longue      1    493       0         740             result.treeNaiveLG              courte longue moyenne tres longue  courte         332      0     684         152  longue          12    661       2         347  moyenne          5      0     265           0  tres longue      7    320       0         907             result.treeNnetLG              courte tres longue  courte        1043         125  longue         406         616  moyenne        270           0  tres longue    209        1025                           courte longue moyenne tres longue  courte        1063      1     103           1  longue           1    744       0         277  moyenne        154      0     116           0  tres longue      2    355       0         877</code></pre><h3 id="可视化决策树结构"><a href="#可视化决策树结构" class="headerlink" title="可视化决策树结构"></a>可视化决策树结构</h3><p>其实其他五种结构都能查看，这里我就不去运行了</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">prp(LGtree1, type&#x3D;4, extra&#x3D;1, box.col&#x3D;c(&quot;tomato&quot;, &quot;skyblue&quot;)[LGtree1$frame$yval])plot(LGtree2, type&#x3D;&quot;simple&quot;)plot(LGtree3)text(LGtree3, pretty&#x3D;0)</code></pre><h3 id="将表现最好的模型应用于将要预测的数据集-3"><a href="#将表现最好的模型应用于将要预测的数据集-3" class="headerlink" title="将表现最好的模型应用于将要预测的数据集"></a>将表现最好的模型应用于将要预测的数据集</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">#&#x3D;&#x3D;&#x3D; rpart &#x3D;&#x3D;&#x3D;#class.treerpLG &lt;- predict(LGtree1, tableMar, type&#x3D;&quot;class&quot;)resultatLG &lt;- data.frame(tableMar, class.treerpLG)# Renommage de la colonne des classes preditesnames(resultatLG)[7] &lt;- &quot;LONGUEUR&quot;</code></pre><h2 id="Couleur颜色"><a href="#Couleur颜色" class="headerlink" title="Couleur颜色"></a>Couleur颜色</h2><h3 id="数据准备-4"><a href="#数据准备-4" class="headerlink" title="数据准备"></a>数据准备</h3><p>取Immatriculation第六九列，可以得到车牌号对应车的车长</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">tableImCL &lt;- tableIm_f[c(6, 9)]tableCLFinal &lt;- merge(tableClients, tableImCL, by &#x3D; &quot;IMMATRICULATION&quot;, incomparables &#x3D; NA)</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">summary(tableCLFinal$COULEUR)</code></pre><pre><code>   Length     Class      Mode     11082 character character </code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R">str(tableCLFinal)tableCLFinal$TAUX &lt;- as.integer(tableCLFinal$TAUX)tableCLFinal &lt;- subset(tableCLFinal, select&#x3D;-IMMATRICULATION)</code></pre><pre><code>&#39;data.frame&#39;:    11082 obs. of  8 variables: $ IMMATRICULATION   : chr  &quot;1 EF 20&quot; &quot;10 ZM 12&quot; &quot;100 XL 72&quot; &quot;100 YT 70&quot; ... $ AGE               : num  18 33 26 76 20 27 45 28 28 38 ... $ SEXE              : chr  &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; ... $ TAUX              : chr  &quot;594&quot; &quot;1380&quot; &quot;597&quot; &quot;587&quot; ... $ SITUATIONFAMILIALE: chr  &quot;celibataire&quot; &quot;En Couple&quot; &quot;En Couple&quot; &quot;En Couple&quot; ... $ NBENFANTSACHARGE  : num  0 4 0 1 0 0 0 2 2 0 ... $ DEUXIEMEVOITURE   : chr  &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; &quot;FALSE&quot; ... $ COULEUR           : chr  &quot;bleu&quot; &quot;gris&quot; &quot;bleu&quot; &quot;gris&quot; ...</code></pre><h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><pre class="line-numbers language-R" data-language="R"><code class="language-R">table(tableOCCAFinal$DEUXIEMEVOITURE,tableOCCAFinal$OCCASION)</code></pre><pre><code>        FALSE TRUE  FALSE  8408 1276  TRUE   1234  164</code></pre><p>可视化后发现该变量和各参数没有太大的相关性，故而不做分析。<br><img src="/source/img/Rprojet/63.png" alt="png"><br><img src="/source/img/Rprojet/64.png" alt="png"><br><img src="/source/img/Rprojet/65.png" alt="png"><br><img src="/source/img/Rprojet/66.png" alt="png"></p><h2 id="整合模型应用于将要预测的数据集"><a href="#整合模型应用于将要预测的数据集" class="headerlink" title="整合模型应用于将要预测的数据集"></a>整合模型应用于将要预测的数据集</h2><pre class="line-numbers language-R" data-language="R"><code class="language-R">resultatTOTAL &lt;- data.frame(tableMar, resultatLG[7],resultatNB[7],resultatOCCA[7],resultatPrix[7])</code></pre><pre class="line-numbers language-R" data-language="R"><code class="language-R"># 将结果整合到xlsx格式文件中install.packages(&quot;openxlsx&quot;) library(openxlsx)write.xlsx(resultatTOTAL,&quot;predictions.xlsx&quot;)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;首先，R语言牛皮之处就不过多阐述，总之很方便很方便。R语言就是为了数据处理而生的，可以轻松链接数据库，可以轻松对数据进行处理和分析。&lt;/p&gt;</summary>
      
    
    
    
    <category term="机器学习Machine Learning" scheme="http://quanzhang.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Machine-Learning/"/>
    
    
    <category term="机器学习" scheme="http://quanzhang.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐系统" scheme="http://quanzhang.top/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="R语言" scheme="http://quanzhang.top/tags/R%E8%AF%AD%E8%A8%80/"/>
    
  </entry>
  
  <entry>
    <title>pdf提取关键词-词频统计</title>
    <link href="http://quanzhang.top/post/pdf%E6%8F%90%E5%8F%96%E5%85%B3%E9%94%AE%E8%AF%8D-%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1.html"/>
    <id>http://quanzhang.top/post/pdf%E6%8F%90%E5%8F%96%E5%85%B3%E9%94%AE%E8%AF%8D-%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1.html</id>
    <published>2022-03-17T16:39:10.000Z</published>
    <updated>2024-11-06T02:24:29.746Z</updated>
    
    <content type="html"><![CDATA[<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>这个算是之前帮助同事解决的一个小问题。<br>因为所在公司为外企，有大量没有归类的英文pdf文档。<br>所以需求就是给所有的pdf生成关键词，放在txt文件或者excel文件中，方便后续的查找。</p><p><a href="https://github.com/1250681923/Keyword-extraction.git">项目仓库地址</a></p><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>生成关键词的话，需要对词频有一个统计，然后过滤掉没有意义且频率较大的常用词。<br>寻找合适的算法是解决问题的关键。<br>最后要有一个文档的输出。<br>所以我们要做的事情有以下几个：</p><ul><li>python读取pdf文字部分</li><li>自然语言处理分词方法</li><li>设定停用词，后期要根据实际情况调整</li><li>应用词频统计算法，输出前n频率的关键词</li><li>将结果写入txt文件或者excel</li></ul><h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><h3 id="读取pdf文字部分"><a href="#读取pdf文字部分" class="headerlink" title="读取pdf文字部分"></a>读取pdf文字部分</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">import globimport os#pdf文件的路径#我们先放四个英文pdf文件方便测试pdf_path &#x3D; &quot;pdf&#x2F;&quot;pdfs &#x3D; glob.glob(&quot;&#123;&#125;&#x2F;*.pdf&quot;.format(pdf_path))pdfs</code></pre><pre><code>[&#39;pdf/NASA UAM market Study 2018.pdf&#39;, &#39;pdf/Innovation Driving Sustainable Aviation - November 2021.pdf&#39;, &#39;pdf/roland_berger_urban_air_mobility_1.pdf&#39;, &#39;pdf/Roland_Berger_Urban_Air_Mobility 2018.pdf&#39;]</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreterfrom pdfminer.converter import TextConverterfrom pdfminer.layout import LAParamsfrom pdfminer.pdfpage import PDFPagefrom io import StringIO#平时我们用的是hanlp，在这里我们使用nltk的分词包# 因为是英文文档，所以直接使用hanlp的英文包#import hanlp#tokenizer &#x3D; hanlp.utils.rules.tokenize_english #from hanlp.utils.lang.en.english_tokenizer import tokenize_english#tokenizer &#x3D; tokenize_english#平时我们用的是hanlp，在这里我们使用nltk的分词包from nltk.corpus import stopwords from nltk.tokenize import word_tokenize from nltk.tokenize import WhitespaceTokenizer from collections import defaultdict# 首先要下载停用词，nltk自然语言处理包具有16种不同语言存储的停用词列表。# 当然，我们下载之后在&#x2F;Users&#x2F;zhangquan&#x2F;nltk_data&#x2F;corpora&#x2F;stopwords&#x2F;中可以找到16种不同语言的停用词库，自己根据业务添加需要过滤的标点符号和单词import nltknltk.download(&#39;stopwords&#39;)def extract_pdf_content(pdf):    rsrcmgr &#x3D; PDFResourceManager()    codec &#x3D; &#39;utf-8&#39;    outfp &#x3D; StringIO()    laparams &#x3D; LAParams()    device &#x3D; TextConverter(rsrcmgr&#x3D;rsrcmgr, outfp&#x3D;outfp, laparams&#x3D;laparams)    with open(pdf, &#39;rb&#39;) as fp:        interpreter &#x3D; PDFPageInterpreter(rsrcmgr, device)        password &#x3D; &quot;&quot;        maxpages &#x3D; 0        caching &#x3D; True        pagenos&#x3D;set()        for page in PDFPage.get_pages(fp, pagenos, maxpages&#x3D;maxpages, password&#x3D;password,caching&#x3D;caching, check_extractable&#x3D;True):            interpreter.process_page(page)    stop_words &#x3D; set(stopwords.words(&#39;english&#39;))     #word_tokens &#x3D; word_tokenize(outfp.getvalue())     word_tokens &#x3D; WhitespaceTokenizer().tokenize(outfp.getvalue())     mystr &#x3D; [w for w in word_tokens if not w in stop_words]    device.close()    outfp.close()    return mystr</code></pre><h3 id="TF-IDF算法词频统计"><a href="#TF-IDF算法词频统计" class="headerlink" title="TF-IDF算法词频统计"></a>TF-IDF算法词频统计</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">import mathimport operatorimport pandas as pdimport xlwtdef feature_select(list_words):    #总词频统计    doc_frequency&#x3D;defaultdict(int)    for word_list in list_words:        for i in word_list:            doc_frequency[i]+&#x3D;1     #计算每个词的TF值    word_tf&#x3D;&#123;&#125;  #存储没个词的tf值    for i in doc_frequency:        word_tf[i]&#x3D;doc_frequency[i]&#x2F;sum(doc_frequency.values())     #计算每个词的IDF值    doc_num&#x3D;len(list_words)    word_idf&#x3D;&#123;&#125; #存储每个词的idf值    word_doc&#x3D;defaultdict(int) #存储包含该词的文档数    for i in doc_frequency:        for j in list_words:            if i in j:                word_doc[i]+&#x3D;1    for i in doc_frequency:        word_idf[i]&#x3D;math.log(doc_num&#x2F;(word_doc[i]+1))     #计算每个词的TF*IDF的值    word_tf_idf&#x3D;&#123;&#125;    for i in doc_frequency:        word_tf_idf[i]&#x3D;word_tf[i]*word_idf[i]     # 对字典按值由大到小排序    # 这里可以调整输出关键词的个数    dict_feature_select&#x3D;sorted(word_tf_idf.items(),key&#x3D;operator.itemgetter(1),reverse&#x3D;True)    return dict_feature_select[-10:]</code></pre><h3 id="保存结果"><a href="#保存结果" class="headerlink" title="保存结果"></a>保存结果</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">#  将数据写入新文件def data_write(file_path, datas, pdf):    f &#x3D; xlwt.Workbook()    sheet1 &#x3D; f.add_sheet(u&#39;sheet1&#39;,cell_overwrite_ok&#x3D;True) #创建sheet        #将数据写入第 i 行，第 j 列    i &#x3D; 0    for data in datas:        for j in range(len(data)):                sheet1.write(i,j,data[j])        i &#x3D; i + 1            f.save(file_path) #保存文件</code></pre><h3 id="总函数调用运行"><a href="#总函数调用运行" class="headerlink" title="总函数调用运行"></a>总函数调用运行</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">mydict &#x3D; &#123;&#125;datas &#x3D; []j &#x3D; 0for pdf in pdfs:        key &#x3D; pdf.split(&#39;&#x2F;&#39;)[-1]        if not key in mydict:                print(&quot;Extracting content from &#123;&#125; ...&quot;.format(pdf))          mydict[key] &#x3D; extract_pdf_content(pdf)        features&#x3D;feature_select([mydict[key]])        #print(features[0])        data&#x3D;[pdf,features[9][0],features[8][0],features[7][0],features[6][0],features[5][0],features[4][0],features[3][0],features[2][0],features[1][0],features[0][0]]        for i in range (0, len(data)):            data[i] &#x3D; str (data[i])        str1 &#x3D; &quot; \n&quot;        str1 &#x3D; str1.join(data)        with open(&quot;test.txt&quot;,&quot;a&quot;) as f:                f.write(str1)                f.write(&quot;\n&quot;)</code></pre><p>Extracting content from pdf&#x2F;NASA UAM market Study 2018.pdf …<br>Extracting content from pdf&#x2F;Innovation Driving Sustainable Aviation - November 2021.pdf …<br>Extracting content from pdf&#x2F;roland_berger_urban_air_mobility_1.pdf …<br>Extracting content from pdf&#x2F;Roland_Berger_Urban_Air_Mobility 2018.pdf …</p><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>完美！</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">pdf&#x2F;NASA UAM market Study 2018.pdf solely Air UAM addressed. client intended confidential document market aircraftpdf&#x2F;Innovation Driving Sustainable Aviation - November 2021.pdf aviation aircraft SAF ICAO emissions sustainable Aviation fuel presented technologypdf&#x2F;roland_berger_urban_air_mobility_1.pdf UAM passenger market industry business model eVTOL value drone Airpdf&#x2F;Roland_Berger_Urban_Air_Mobility 2018.pdf air mobility urban aircraft Roland Urban landing Berger UAM use</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;项目背景&quot;&gt;&lt;a href=&quot;#项目背景&quot; class=&quot;headerlink&quot; title=&quot;项目背景&quot;&gt;&lt;/a&gt;项目背景&lt;/h2&gt;&lt;p&gt;这个算是之前帮助同事解决的一个小问题。&lt;br&gt;因为所在公司为外企，有大量没有归类的英文pdf文档。&lt;br&gt;所以需求就是给所有</summary>
      
    
    
    
    <category term="自然语言处理NLP" scheme="http://quanzhang.top/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/"/>
    
    
    <category term="自然语言处理" scheme="http://quanzhang.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    <category term="词频统计" scheme="http://quanzhang.top/tags/%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1/"/>
    
    <category term="关键词" scheme="http://quanzhang.top/tags/%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
    
    <category term="NLP" scheme="http://quanzhang.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Markdown使用手册</title>
    <link href="http://quanzhang.top/post/Markdown.html"/>
    <id>http://quanzhang.top/post/Markdown.html</id>
    <published>2021-12-10T07:39:10.000Z</published>
    <updated>2024-11-05T09:23:33.275Z</updated>
    
    <content type="html"><![CDATA[<p><strong>注意：本博客搭建使用的框架是基于Node.js的hexo，主题是Aurora。所以无法兼容Markdown的某些功能，比如流程图，Latex公式，注脚，还有一部分HTML原生代码😊</strong></p><p>为了提高我自己的开发效率，我打算从头写一边Markdown开发笔记。并且加入一些个人的看法和备注。</p><p>因为之前有过Latex和前端的基础。对于这种新接触到的排版类型的语言接受能力还是很高的。在此非常感谢Latex陪伴我走过很多年，写过大大小小的报告和论文，有机会我会把我常用的latex模板放上来！！！</p><p>废话不多说，步入正题！</p><hr><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><pre class="line-numbers language-none"><code class="language-none">*斜体*或_斜体_**粗体*****加粗斜体***~~删除线~~</code></pre><p>效果：<br><em>斜体</em>或_斜体_<br><strong>粗体</strong><br><em><strong>加粗斜体</strong></em><br><del>删除线</del></p><h2 id="分级标题"><a href="#分级标题" class="headerlink" title="分级标题"></a>分级标题</h2><p><strong>注意空格！！！</strong></p><pre class="line-numbers language-none"><code class="language-none"># 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题</code></pre><p>效果就不展示了，导航栏会乱。</p><h2 id="超链接"><a href="#超链接" class="headerlink" title="超链接"></a>超链接</h2><p>有很多种写法，只列出我自己喜欢的行内式。如果在文本中多次引用可以使用参考式。但是我个人觉得参考式虽然代码清爽了那么一丢丢，后期如果出错会很麻烦！！因为IDEA对markdown文件中的对象不支持跳转，所以更改的时候要先看看改哪里，然后记住代号，然后去文件末尾找一堆堆的链接。。。。</p><p>[]里写链接文字，()里写链接地址, ()中的”“中可以为链接指定title属性，title属性可加可不加。title属性的效果是鼠标悬停在链接上会出现指定的 title文字。[链接文字](链接地址 “链接标题”)’这样的形式。<strong>链接地址与链接标题前有一个空格</strong>。</p><pre class="line-numbers language-none"><code class="language-none">欢迎来到[梵居闹市](http:&#x2F;&#x2F;blog.leanote.com&#x2F;freewalk)欢迎来到[梵居闹市](http:&#x2F;&#x2F;blog.leanote.com&#x2F;freewalk &quot;梵居闹市&quot;)&lt;http:&#x2F;&#x2F;example.com&#x2F;&gt;&lt;address@example.com&gt;</code></pre><p>效果：<br>欢迎来到<a href="http://blog.leanote.com/freewalk">梵居闹市</a><br>欢迎来到<a href="http://blog.leanote.com/freewalk" title="梵居闹市">梵居闹市</a><br><a href="http://example.com/">http://example.com/</a><br><a href="mailto:&#x61;&#100;&#x64;&#x72;&#x65;&#x73;&#115;&#x40;&#101;&#x78;&#x61;&#x6d;&#112;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;">&#x61;&#100;&#x64;&#x72;&#x65;&#x73;&#115;&#x40;&#101;&#x78;&#x61;&#x6d;&#112;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;</a></p><h2 id="页内跳转超链接"><a href="#页内跳转超链接" class="headerlink" title="页内跳转超链接"></a>页内跳转超链接</h2><pre class="line-numbers language-none"><code class="language-none">## 0. 目录&#123;#index&#125;跳转到[目录](#index)</code></pre><p>效果就不展示了。。。</p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><p><strong>注意空格！！！</strong></p><pre class="line-numbers language-none"><code class="language-none">- 无序列表项 一- 无序列表项 二- 无序列表项 三</code></pre><p>效果：</p><ul><li>无序列表项 一</li><li>无序列表项 二</li><li>无序列表项 三<h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3>感觉智商有被侮辱到 -.-…<pre class="line-numbers language-none"><code class="language-none">1. 有序列表项 一2. 有序列表项 二3. 有序列表项 三</code></pre>效果：</li></ul><ol><li>有序列表项 一</li><li>有序列表项 二</li><li>有序列表项 三</li></ol><p>至于定义型列表。。。个人感觉和这个有序列表一样没必要。不就是代码块中列定义，纯属脱裤子放屁多此一举。</p><h3 id="列表缩进"><a href="#列表缩进" class="headerlink" title="列表缩进"></a>列表缩进</h3><p>这个可以让列表下方跟第一行缩进一致，效果还挺好看的。</p><pre class="line-numbers language-none"><code class="language-none">*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！     那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ *    悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。</code></pre><ul><li>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。<br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！<br> 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。<br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。<br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ </li><li>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。</li></ul><p><strong>大概有用的就是这些，其他的设计代码排版还不如直接截图</strong></p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><h3 id="普通引用"><a href="#普通引用" class="headerlink" title="普通引用"></a>普通引用</h3><p>Markdown 允许你只在整个段落的第一行最前面加上 &gt; ，效果如下：</p><blockquote><span class="custom-blockquote-svg"><svg width="24" height="24" viewBox="0 0 24 24" fill="" xmlns="http://www.w3.org/2000/svg" data-reactroot=""><path fill="" d="M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z" undefined="1"></path><path fill="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z" undefined="1"></path><path fill="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z" undefined="1"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z"></path></svg></span><p>这是一个有两段文字的引用,<br>无意义的占行文字1.<br>无意义的占行文字2.</p><p>无意义的占行文字3.<br>无意义的占行文字4.</p></blockquote><h3 id="多层引用"><a href="#多层引用" class="headerlink" title="多层引用"></a>多层引用</h3><pre class="line-numbers language-none"><code class="language-none">&gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白&gt;&gt;&gt;&gt;&gt; 自己看教程！ - 愤青&gt;&gt;&gt; 教程在哪？ - 小白&gt;</code></pre><blockquote><span class="custom-blockquote-svg"><svg width="24" height="24" viewBox="0 0 24 24" fill="" xmlns="http://www.w3.org/2000/svg" data-reactroot=""><path fill="" d="M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z" undefined="1"></path><path fill="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z" undefined="1"></path><path fill="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z" undefined="1"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z"></path></svg></span><blockquote><blockquote><p>请问 Markdwon 怎么用？ - 小白</p></blockquote><p>自己看教程！ - 愤青</p></blockquote><p>教程在哪？ - 小白</p></blockquote><h3 id="引用中添加代码"><a href="#引用中添加代码" class="headerlink" title="引用中添加代码"></a>引用中添加代码</h3><pre class="line-numbers language-none"><code class="language-none">&gt; 1.   这是第一行列表项。&gt; 2.   这是第二行列表项。&gt; &gt; 给出一些例子代码：&gt; &gt;     return shell_exec(&quot;echo $input | $markdown_script&quot;);</code></pre><p>效果：</p><blockquote><span class="custom-blockquote-svg"><svg width="24" height="24" viewBox="0 0 24 24" fill="" xmlns="http://www.w3.org/2000/svg" data-reactroot=""><path fill="" d="M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z" undefined="1"></path><path fill="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z" undefined="1"></path><path fill="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z" undefined="1"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z"></path><path stroke-linejoin="round" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" stroke="" d="M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z"></path></svg></span><ol><li>这是第一行列表项。</li><li>这是第二行列表项。</li></ol><p>给出一些例子代码：</p><pre><code>return shell_exec(&quot;echo $input | $markdown_script&quot;);</code></pre></blockquote><h2 id="插入图像"><a href="#插入图像" class="headerlink" title="插入图像"></a>插入图像</h2><p>我只使用行内式，参考式虽然代码看起来清爽一丢丢，但是后期有问题的话维护成本太高。</p><pre class="line-numbers language-none"><code class="language-none">![波尔多](https:&#x2F;&#x2F;user-images.githubusercontent.com&#x2F;59725125&#x2F;145532785-07737376-50bd-4754-8fe2-2aa7ed01fa4d.jpg &quot;波尔多&quot;)</code></pre><p><img src="https://user-images.githubusercontent.com/59725125/145532785-07737376-50bd-4754-8fe2-2aa7ed01fa4d.jpg" alt="波尔多" title="波尔多"><br>这个时候有一个问题，Markdown只会把图片原尺寸原封不动的展示，无法调节图片大小。<br>幸运的是Markdown可以直接写HTML！！！然后就没问题了是不。</p><pre class="line-numbers language-none"><code class="language-none">&lt;p style&#x3D;&quot;text-align:center&quot;&gt;&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;user-images.githubusercontent.com&#x2F;59725125&#x2F;145532785-07737376-50bd-4754-8fe2-2aa7ed01fa4d.jpg&quot;  height&#x3D;&quot;330&quot; width&#x3D;&quot;495&quot;&gt;&lt;&#x2F;p&gt;</code></pre><p style="text-align:center"><img src="https://user-images.githubusercontent.com/59725125/145532785-07737376-50bd-4754-8fe2-2aa7ed01fa4d.jpg"  height="330" width="495"></p><h2 id="注脚"><a href="#注脚" class="headerlink" title="注脚"></a>注脚</h2><pre class="line-numbers language-none"><code class="language-none">使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。[^1]:Markdown是一种纯文本标记语言[^2]:HyperText Markup Language 超文本标记语言[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文</code></pre><p>效果：<br>使用 Markdown<a href="Markdown%E6%98%AF%E4%B8%80%E7%A7%8D%E7%BA%AF%E6%96%87%E6%9C%AC%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80">^1</a>可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。</p><p>[^2]:HyperText Markup Language 超文本标记语言<br>[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文</p><h2 id="Latex-公式"><a href="#Latex-公式" class="headerlink" title="Latex 公式"></a>Latex 公式</h2><p>这是我万万没有想到的。有了Latex支持，岂不是数学公式什么的轻轻松松搞定。直接用美元符号$框起来就行，两个美元是整行公式。懂Latex的朋友就知道多简单了。</p><pre class="line-numbers language-none"><code class="language-none">质能守恒方程可以用一个很简洁的方程式 $E&#x3D;mc^2$ 来表达。$$f(x_1,x_x,\ldots,x_n) &#x3D; x_1^2 + x_2^2 + \cdots + x_n^2 $$$$\sum^&#123;j-1&#125;_&#123;k&#x3D;0&#125;&#123;\widehat&#123;\gamma&#125;_&#123;kj&#125; z_k&#125;$$</code></pre><p>质能守恒方程可以用一个很简洁的方程式 $E&#x3D;mc^2$ 来表达。<br>$$f(x_1,x_x,\ldots,x_n) &#x3D; x_1^2 + x_2^2 + \cdots + x_n^2 $$<br>$$\sum^{j-1}<em>{k&#x3D;0}{\widehat{\gamma}</em>{kj} z_k}$$</p><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p>暂时没找到案例，网上给的以往的代码都实现不了。</p><pre class="line-numbers language-none"><code class="language-none">flowst&#x3D;&gt;start: Start:&gt;https:&#x2F;&#x2F;www.zybuluo.comio&#x3D;&gt;inputoutput: verificationop&#x3D;&gt;operation: Your Operationcond&#x3D;&gt;condition: Yes or No?sub&#x3D;&gt;subroutine: Your Subroutinee&#x3D;&gt;endst-&gt;io-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;sub-&gt;io</code></pre><p>如果有人知道怎么做，欢迎留言板告诉我哟~</p><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><pre class="line-numbers language-none"><code class="language-none">|学号|姓名|分数||-|-|-||小明|男|75||小红|女|79||小陆|男|92|</code></pre><table><thead><tr><th>学号</th><th>姓名</th><th>分数</th></tr></thead><tbody><tr><td>小明</td><td>男</td><td>75</td></tr><tr><td>小红</td><td>女</td><td>79</td></tr><tr><td>小陆</td><td>男</td><td>92</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;注意：本博客搭建使用的框架是基于Node.js的hexo，主题是Aurora。所以无法兼容Markdown的某些功能，比如流程图，Latex公式，注脚，还有一部分HTML原生代码😊&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了提高我自己的开发效率，我打算从头写一边</summary>
      
    
    
    
    <category term="Web development" scheme="http://quanzhang.top/categories/Web-development/"/>
    
    
    <category term="Markdown" scheme="http://quanzhang.top/tags/Markdown/"/>
    
  </entry>
  
</feed>
